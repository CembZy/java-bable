写代码第一标准：可维护和可读性。


一，集合?
1，Vector和ArrayList的区别？
	1）Vector的方法都是同步的(Synchronized),是线程安全的（thread-safe），而ArrayList的方法不是，由于线程的同步必然要影响性能	，因此,ArrayList的性能比Vector好。 
	2）当Vector或ArrayList中的元素超过它的初始大小时,Vector会将它的容量翻倍,而ArrayList只增加大约1.5的大小，这样ArrayList就	   有利于节约内存空间。
	3）Vector可以设置capacityIncrement（容量增长的参数），而ArrayList不可以。
	4）List<Map<String,Object>> data=Collections.synchronizedList(new ArrayList<Map<String,Object>>());
	   可以解决ArrayList的线程安全问题，或者使用ThreadLocal。

2，ArrayrList和LinkedList的区别？
	 1.ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。 
     2.对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。 
     3.对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。

3，ArrayList的动态扩容？
	1，在JKD1.6中，如果通过无参构造的话，初始数组容量为10.每次通过copeOf的方式扩容后容量为原来的1.5倍加1。
	2，在JDK1.7中，如果通过无参构造的话，初始数组容量为0，当真正对数组进行添加时，才真正分配容量，每次按照大约1.5倍（位运算）的比率通过copeOf的方式扩容。 
	3，在JKD1.8中，arraylist这个类中，扩容调用的是grow（）方法，通过grow（）方法中调用的Arrays.copyof（）方法进行对原数组的复制，在通过调用System.arraycopy()方法进行复制，达到扩容的目的。

4，HashMap和TreeMap的区别？
	1、实现 
		TreeMap：实现了SortMap接口，基于红黑树 
		HashMap：基于哈希散列表实现，内部是一个数组，每个数组内是一个链表，链表可以扩展为红黑树
	2、存储 
		TreeMap：默认按键的升序排序
		HashMap：随机存
	3、遍历 
		TreeMap：Iterator遍历是排序的
		HashMap：Iterator遍历是随机的
	4、性能损耗 
		TreeMap：插入、删除速度慢，需要维护树的平衡
		HashMap：基本无损耗
	5、键值对 
		TreeMap：键、值都不能为null
		HashMap：键、值均可为null
	6、安全 
		TreeMap：非并发安全Map
		HashMap：非并发安全Map
	7、效率 
		TreeMap：低
		HashMap：高

5，HashMap和Hashtable有什么区别？
	1、HashMap是非线程安全的，HashTable是线程安全的。 
	2、HashMap的键和值都允许有null值存在，而HashTable则不行。 
	3、因为线程安全的问题，HashMap效率比HashTable的要高。 
	4、Hashtable是同步的，而HashMap不是。因此，HashMap更适合于单线程环境，而Hashtable适合于多线程环境。 
	一般现在不建议用HashTable,因为：
	1，是HashTable是遗留类，内部实现很多没优化和冗余。
	2，HashTable内部是全部加了Syn锁，重量级锁，效率会很低。
	3，即使在多线程环境下，现在也有同步的ConcurrentHashMap替代，没有必要因为是多线程而用HashTable。

6，HashMap和LinkedHashMap有什么区别？
	LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比HashMap慢，不过有种情况例外，当HashMap容量很大，实际数据较少时，遍历起来可能会比LinkedHashMap慢，因为LinkedHashMap的遍历速度只和实际数据有关，和容量无关，而HashMap的遍历速度和他的容量有关，如果需要输出的顺序和输入的相同,那么用LinkedHashMap 可以实现,它还可以按读取顺序来排列。

7，HashMap的实现？
	hashmap底层：链表数组，初始容量16.扩容阀值数组长度乘以0.75，到这个阀值，扩容两倍，如果当前map大小大于64，并且同一hash链表长度大于8，同一哈希值冲突部分自动转换为红黑树，如果小于64就不能转红黑树，直接扩容。根据key的哈希值计算出存放数组的索引位置。同一哈希值用链表形式向下存储，不同的key有可能哈希值一样。链表是单向链表。若链表元素个数小于等于6时，树结构还原成链表。
	HashMap在多线程的环境下的put操作容易引起死循环，HahsMap里面的Entry链表会产生环形的数据结构，链表成了一个环，会一直在循环，是不安全的，但是HashTable效率太低了，所以多线程下一般使用ConCurrentHashMap。
	注意：构造函数不会初始化数组，在put的时候进行初始化。

	hashmap在多线程下形成死循环：
	因为在hashmap扩容的过程中，会发生链表上的元素的位置发生改变，当hashmap在多线程的情况下，put元素，可能会发生扩容，当扩容的时候，如果一个链表上有A和B两个元素，线程1将A和B的位置改变还没执行完的时候，这时候线程2也将A和B的位置改变，当线程2还没执行完的时候线程1执行完了，将A和B的位置彻底改变了，这时候线程2就会出现B.next=A; A.next=B的情况，形成死循环。

8，为什么HashMap链表长度超过8会转成树结构？
	1，纯链表的平均查找长度为(n+1)/2，红黑树平均查找长度则为log2n。长度为8的时候，红黑树平均查找长度为3，链表平均查找长度为8/2=4，这才有转换为树的必要。链表长度如果是小于等于6，6/2=3，速度已经很快，并且转化为树结构和生成树的时间不会很短，所以没必要转成红黑树。
	2，选择6和8，中间有个差值7可以有效防止链表和树频繁转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。

9,为什么默认初始化桶数组大小为16，为什么加载因子的大小为0.75,这两个值的选取有什么特点?
	如果桶初始化桶数组设置太大，就会浪费内存空间，16是一个折中的大小，既不会像1，2，3那样放几个元素就扩容，也不会像几千几万那样可以只会利用一点点空间从而造成大量的浪费。
	加载因子设置为0.75而不是1，是因为设置过大，桶中键值对碰撞的几率就会越大，同一个桶位置可能会存放好几个value值，这样就会增加搜索的时间，性能下降，设置过小也不合适，如果是0.1，那么10个桶，threshold为1，你放两个键值对就要扩容，太浪费空间了。

10，HashSet和TreeSet的区别？
	1、TreeSet是二叉树实现的（内部基于TreeMap，数据结构和TreeMap一致）,Treeset中的数据是自动排好序的，不允许放入null值。
	2、HashSet是哈希表实现的（内部基于HashMap，数据结构和HashMap一致）,HashSet中的数据是无序的，可以放入null，但只能放入一	   个null。 
	3、HashSet要求放入的对象必须实现HashCode()方法，放入的对象，是以hashcode码作为标识的，而具有相同内容的对象，hashcode一	样，所以放入的内容不能重复。但是同一个类的对象可以放入不同的实例。
	4、TreeSet为基本操作（add、remove和contains）的时间复杂度是log（n）。另外，TreeSet是非同步的。它的iterator方法返回的迭代器是fail-fast的。

11，哈希？
	哈希，又称为散列。是一个任意长度的输入，通过散列算法，得到一个固定长度的输出的值，也叫作压缩映射，容易产生哈希碰撞，即是可能出现同一个哈希值。比如：直接取余法就是一种hash算法。
	解决哈希冲突，通常是：
	1，开放寻址
	2，再散列
	3，链地址法（解决hashmap的hash冲突的时候采用这种方式）
	注意：MD4,MD5，sha之类的所谓的加密算法，不是加密算法而是哈希算法，而且是不可逆的，网上那些可以逆的网站，是因为他们把常见的一些加密出来的密码统计起来了，然后做成了一张彩虹表。

12，位运算？
	Java实际保存int型时，正数  第31位 =0 	负数：第31位=1
	int类型四个字节，一个字节8位，一共32位。
	常用位运算有：
		位与  &  (1&1=1 	1&0=0	 0&0=0)
		位或  |   (1|1=1		 1|0=1 	0|0=0)
		位非  ~  （ ~1=0 	 ~0=1）
		位异或  ^   (1^1=0	 1^0=1	 0^0=0) 
		<<有符号左移     >>有符号的右移    >>>无符号右移  例如：8 << 2 = 32	8>>2 = 2
		取模的操作 a % (Math.pow(2,n)) 等价于 a&( Math.pow(2,n)-1) -----》 a%(x) 等价于  a&(x-1)


13，ConcurrentHashMap（弱一致的）？
	1.7及以前：
	一个ConcurrentHashMap里包含一个Segment数组，每个Segment里包含一个HashEntry数组，我们称之为table，每个HashEntry是一个链表结构的元素，每个key和value最后会计算出一个hash值，hash值如果相同的key，value会封装成一个对象，然后放入到HashEntity的相同链表中，不同则放在其他链表中，其实总结就是，Segment数组就是一个加锁的数组，每个线程对应一个Segment，每个Segment中包含一个hashmap。
	注意：ConcurrentHashMap采用了二次hash的方式，第一次hash将key映射到对应的segment，而第二次hash则是映射到segment的不同桶(bucket)中。
	保证线程安全性的原因：
	ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术，对segment进行加锁，segment本身也是一个锁（继承了ReentrantLock），就保证了线程安全，初始化是根据并发数的大小和数组的大小来确定segment的大小，同时为了快速定位，通过算法保证segment的大小为2的指数，初始化的时候只初始化segment的第一个元素。
	concurrencyLevel并发度:
	默认16。并发度可以理解为程序运行时能够同时更新ConccurentHashMap且不产生锁竞争的最大线程数，实际上就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度。如果并发度设置的过小，会带来严重的锁竞争问题；如果并发度设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，CPU cache命中率会下降，从而引起程序性能下降。

	扩容：
	concurrencyLevel（并发度）一经指定，不可改变，后续如果ConcurrentHashMap的元素数量增加导致ConrruentHashMap需要扩容，ConcurrentHashMap不会增加Segment的数量，而只会增加Segment中链表数组的容量大小，这样的好处是扩容过程不需要对整个ConcurrentHashMap做rehash，而只需要对Segment里面的元素做一次rehash就可以了。table中的元素位置变化，是根据扩容多大，比如扩大n，则元素下标不变化的就位置把持不变，变化的就在原来下标的基础上+n即可，可以快速定位和减少重排次数。
	这边需要特别注意一下两个变量，分别是segmentShift和segmentMask,这两个变量在后面将会起到很大的作用，假设构造函数确定了Segment的数量是2的n次方，那么segmentShift就等于32减去n，而segmentMask就等于2的n次方减一。

	get：
	1，定位segment：先通过获取key的hashCode方法获取到哈希值，然后再通过WangJenkins哈希算法再进行散列，通过偏移量获取到一个高位哈希串再取模，然后寻找到具体所在的segment位置。
	2，定位table：先通过获取key的hashCode方法获取到哈希值，然后再通过WangJenkins哈希算法再进行散列，再和table的长度进行取模，然后寻找到具体所在的table位置。
	3，再在table中寻找对应的链表，去循环链表中的元素。
	在高并发下的情况下如何保证取得的元素是最新的？
	答：用于存储键值对数据的HashEntry，在设计上它的成员变量value等都是volatile类型的，这样就保证别的线程对value值的修改，get方法可以马上看到。

	put：
	1、首先定位segment，当这个segment在map初始化后，还为null，由ensureSegment方法负责填充这个segment。
	2、对Segment加锁。
	3、定位所在的table元素，hash（key）得到hash值，并扫描table下的链表，如果有相同的hash值，再判断key是否相同，如果相同就覆盖，不同就将这个值挂在链表尾部。
	 

	size：首次会进行两次不加锁的统计，如果一致就返回，不一致就加锁之后再统计。因为可能会存在把segment所有的都加锁，所以尽量避免使用size方法。
	弱一致性：
	get方法和containsKey方法没有加锁，他们都是通过对链表遍历判断是否存在key相同的节点以及获得该节点的value。但由于遍历过程中其他线程可能对链表结构做了调整，因此get和containsKey返回的可能是过时的数据，这一点是ConcurrentHashMap在弱一致性上的体现。


	1.8以后：

	与1.7相比的重大变化：
		1、	取消了segment数组，直接用table保存数据，锁的粒度更小，减少并发冲突的概率。
		2、	存储数据时采用了链表+红黑树的形式，纯链表的形式时间复杂度为O（n），红黑树则为O（log2n），性能提升很大。什么时候链表转红黑树？当key值相等的元素形成的链表中元素个数超过8个并且容量大于64的时候，如果容量小于64就先扩容。

	主要数据结构和关键变量：
		Node类存放实际的key和value值。
		sizeCtl：
			负数：表示进行初始化或者扩容,-1表示正在初始化，-N表示有N-1个线程正在进行扩容
			正数：0 表示还没有被初始化，>0的数，初始化或者是下一次进行扩容的阈值
		TreeNode用在红黑树，表示树的节点, TreeBin是实际放在table数组中的，代表了这个红黑树的根，将TreeNode进行了封装。

	初始化过程：
		在put的时候，会调用initTable方法，
			 if ((sc = sizeCtl) < 0)
                Thread.yield();
        会判断当sizeCtl小于0的时候，表示有其他线程正在初始化，当前线程就会进行yield，让出cpu的执行权。否则：
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) ，会用一个CAS操作设置sizeCtl的值，并初始化Node数组，然后：
        sc = n - (n >>> 2); sc =0.75n。将sizeCtl设置为0.75n的阈值。

	扩容操作：
		transfer()方法进行实际的扩容操作，table大小也是翻倍的形式，有一个并发扩容的机制。同时检测到某个table链表元素小于6个了的红黑树，就会自动把红黑树又转为链表结构。
		同时，在put的时候，判断如果有线程正在进行扩容，当前线程会帮助扩容，tab=helpTransfer（tab,f）;，这个其实是put和hashmap最大不同之处，可以并发扩容，帮助移动数组中的Node的位置。

	链表转为红黑树：
		if (binCount != 0) {
                    if (binCount >= TREEIFY_THRESHOLD)
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
        其中，if (binCount >= TREEIFY_THRESHOLD)表示当链表长度大于8的时候，通过treeifyBin(tab, i);转为红黑树。

	put操作：
		1，根据key进行两次hash算法得到hash值。
		2，判断Node数组是否为空，如果为空进行初始化。
		3，根据hash值得出所在的数组的位置，并判断当前数组里有没有链表存在，没有就通过CAS操作将元素加入到当前位置中。
		4，else if ((fh = f.hash) == MOVED)，判断是否有线程正在进行扩容，当前线程会帮助扩容，tab = helpTransfer(tab, 	f);，这个其实是put和hashmap最大不同之处。
		5，如果当前数组位置已经存在元素了，就先用synchronized加锁，然后再判断当前位置是链表，还是红黑树，再对比hash值和equl	  s，hash值相同的，如果key相同就覆盖，key不相同就挂在当前链表后面，hash值不同，就挂在新节点上。

	get操作：
		1，首先判断当前node数组的位置的元素是否就是当前key，并且就是一个元素，没有链表，如果是就直接返回。
		2，如果不是，再判断是否是红黑树，是就去红黑树中查找。
		3，如果不是，就去链表中查找。
		4，如果当前table为空，还没初始化，就直接返回null。

	size方法：
		估计的大概数量，不是精确数量，因为没有加锁，所以是弱一致性的。


	putIfAbsent()：
		如果没有对应好的key就放入map，有这个值则返回key原来对应的值。



14，ConcurrentSkipListMap和ConcurrentSkipListSet？
	是TreeMap和TreeSet有序的容器的并发版本，内部加入了跳表。

	1，为什么选择跳表？
		目前经常使用的平衡数据结构有：B树，红黑树，AVL树，SplayTree,Treep等，想象一下，给你一张草稿纸，一只笔，一个编辑器，你能立即实现一颗红黑树，或者AVL树出来吗？很难吧，这需要时间，要考虑很多细节，要参考一堆算法与数据结构之类的树，还要参考网上的代码，相当麻烦。
		用跳表吧，跳表是一种随机化的数据结构，目前开源软件Redis和LevelDB（全文搜索引擎）都有用到它，它的效率和红黑树以及AVL树不相上下，但跳表的原理相当简单，时间复杂度非常趋近于红黑树。

	2，ConcurrentHashMap中为什么不使用跳表？
		因为ConcurrentHashMap，因为用了分段锁，本身的空间利用率很低，如果再使用跳表用空间换取时间，就会使得ConcurrentHashMap的空间利用率更低，所以不使用跳表。

	2，跳表（可以提高普通链表查询的速度，是扩展空间负责度）？
		SkipList，以空间换时间，在原链表的基础上形成多层索引，当某个节点在插入时，随机决定这个节点是否成为上层索引，所以跳表又称为概率数据结构，这样有了索引之后，在查找的时候提高了效率。

		跳表的高度：
			n个元素的跳表，每个元素插入的时候都要做一次实验，用来决定元素占据的层数K，跳表的高度等于这n次实验中产生的最大k

		跳表具有如下性质：
			(1) 由很多层结构组成。
			(2) 每一层都是一个有序的链表。
			(3) 最底层(Level 1)的链表包含所有元素。
			(4) 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。
			(5) 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。


15，ConcurrentLinkedQueue？
	是LinkedList的并发版本，无界非阻塞队列，底层是个链表，遵循先进先出FIFO原则。
	其中的方法：
		add,offer：将元素插入到尾部
		peek：拿头部的数据，但是不移除
		poll：拿头部的数据，但是移除


16，写时复制容器？
	CopeOnWriteArrayList，CopeOnWriteArraySet
	写时复制的容器，通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以写时复制容器也是一种读写分离的思想，读和写不同的容器。如果读的时候有多个线程正在向容器添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的，只能保证最终一致性。
	适用读多写少的并发场景，常见应用：白名单/黑名单，商品类目的访问和更新场景。
	注意：存在内存占用问题。

	和读写锁的区别？
	写时复制容器是读写可以同时进行的，而读写锁是一个线程写的时候，其他线程不能读，是互斥的。


17，Java集合框架的基础接口有哪些？
	Collection：
		为集合层级的根接口，一个集合代表一组对象。这些对象即为它的元素，Java平台不提供这个接口不论什么直接的实现。
	Set：
		是一个不能包括反复元素的集合，这个接口对数学集合抽象进行建模。被用来代表集合，就如一副牌。
	List：
		是一个有序集合。能够包括反复元素，你能够通过它的索引来訪问不论什么元素。List更像长度动态变换的数组。
	Map：
		是一个将key映射到value的对象.一个Map不能包括反复的key：每一个key最多仅仅能映射一个value。


18.Iterator？
	Iterator接口提供遍历不论什么Collection的接口，我们能够从一个Collection中使用迭代器方法来获取迭代器实例。迭代器代替了Java集合框架中的Enumeration。迭代器同意调用者在迭代过程中移除元素。
	1，原理：
		用到了Iterator设计模式，又叫做游标（Cursor）模式。迭代器模式：提供一种方法访问一个容器（container）对象中各个元素，而又不需暴露该对象的内部细节。
	　　从定义可见，迭代器模式是为容器而生。很明显，对容器对象的访问必然涉及到遍历算法。你可以一股脑的将遍历方法塞到容器对	  象中去；或者根本不去提供什么遍历算法，让使用容器的人自己去实现。这两种情况好像都能够解决问题。
　　    然而在前一种情况，容器承受了过多的功能，它不仅要负责自己“容器”内的元素维护（添加、删除等等），而且还要提供遍历自身		  的接口；而且由于遍历状态保存的问题，不能对同一个容器对象同时进行多个遍历。第二种方式倒是省事，却又将容器的内部细节	    暴露无遗。所以，这时候在内部定义一个迭代器去控制元素的遍历。
	注意：对于自身不是线程安全的容器，modCount也只是用来保证快速失败，因此不要在多线程的环境下使用iterator进行并行遍历操作。如果需要并行遍历可以使用Spliterator进行并行遍历。

	2，Enumeration和Iterator接口的区别：
		Enumeration的速度是Iterator的两倍，也使用更少的内存，Enumeration是非常基础的，也满足了基础的须要。但是，与Enumeration相比：
		1，Iterator更加安全，由于当一个集合正在被遍历的时候。它会阻止其他线程去改动集合（就是快速失败）。
		2，迭代器可以从集合中移除元素，而Enumeration不能做到。
		
	3，为何没有像Iterator.add()这种方法：
		因为Iterator的协议不能确保迭代的次序，所以ListIterator没有提供一个add操作，它要确保迭代的顺序。

	4，为何迭代器在不需要移动游标的情况下，直接获取下一个元素：
		它可以在当前Iterator的顶层实现，但是它用得很少，如果将它加到接口中，每个继承都要去实现它，这没有意义。

	5，Iterater和ListIterator之间有什么区别：
		（1）我们可以使用Iterator来遍历Set和List集合，而ListIterator只能遍历List。
		（2）Iterator只可以向前遍历，而LIstIterator可以双向遍历。
		（3）ListIterator从Iterator接口继承，然后添加了一些额外的功能，比如添加一个元素、替换一个元素、获取前面或后面元素的		索引位置。

	6，为何Iterator接口没有详细的实现？
		Iterator接口定义了遍历集合的方法。但它的实现则是集合实现类的责任。每一个能够返回用于遍历的Iterator的集合类都有它自己的Iterator实现内部类。
		这就同意集合类去选择迭代器是fail-fast还是fail-safe的。比方，ArrayList迭代器是fail-fast的。而CopyOnWriteArrayList迭代器是fail-safe的。

	7，快速失败(fail-fast)和安全失败(fail-safe)的区别：
		一：快速失败（fail—fast）
		     在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception。
			 原理：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。
		     注意：这里异常的抛出条件是检测到 modCount！=expectedmodCount 这个条件。如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的bug。
		     场景：java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。

		二：安全失败（fail—safe）
		    采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。
		    原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。
		    缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。
		    场景：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。



19，EnumSet是什么？
java.util.EnumSet是使用枚举类型的集合实现。当集合创建时，枚举集合中的全部元素必须来自单个指定的枚举类型，能够是显示的或隐示的。EnumSet是不同步的，不同意值为null的元素。它也提供了一些实用的方法，比方copyOf(Collection c)、of(E first,E…rest)和complementOf(EnumSet s)。


20，哪些集合类是线程安全的？
Vector、HashTable、Properties和Stack是同步类，所以它们是线程安全的，能够在多线程环境下使用。


21，Comparable和Comparator接口的区别：
	Comparable：
		Comparable可以认为是一个内比较器，实现了Comparable接口的类有一个特点，就是这些类是可以和自己比较的，至于具体和另一个实现了Comparable接口的类如何比较，则依赖compareTo方法的实现，compareTo方法也被称为自然比较方法。如果开发者add进入一个Collection的对象想要Collections的sort方法帮你自动进行排序的话，那么这个对象必须实现Comparable接口。compareTo方法的返回值是int，有三种情况：
		1、比较者大于被比较者（也就是compareTo方法里面的对象），那么返回正整数
		2、比较者等于被比较者，那么返回0
		3、比较者小于被比较者，那么返回负整数

	Comparator：
		Comparator可以认为是是一个外比较器，有两种情况可以使用实现Comparator接口的方式：
		1、一个对象不支持自己和自己比较（没有实现Comparable接口），但是又想对两个对象进行比较
		2、一个对象实现了Comparable接口，但是开发者认为compareTo方法中的比较方式并不是自己想要的那种比较方式
		Comparator接口里面有一个compare方法，方法有两个参数To1和To2，是泛型的表示方式，分别表示待比较的两个对象，方法返回值和Comparable接口一样是int，有三种情况：
		1、o1大于o2，返回正整数
		2、o1等于o2，返回0
		3、o1小于o3，返回负整数

	两种比较器Comparable和Comparator，后者相比前者有如下优点：
		1、如果实现类没有实现Comparable接口，又想对两个类进行比较（或者实现类实现了Comparable接口，但是对compareTo方法内的比较算法不满意），那么可以实现Comparator接口，自定义一个比较器，写比较算法。
		2、实现Comparable接口的方式比实现Comparator接口的耦合性 要强一些，如果要修改比较算法，要修改Comparable接口的实现类，而实现Comparator的类是在外部进行比较的，不需要对实现类有任何修 改。从这个角度说，其实有些不太好，尤其在我们将实现类的.class文件打成一个.jar文件提供给开发者使用的时候。实际上实现Comparator接口的方式后面会写到就是一种典型的策略模式。
		当然，这不是鼓励用Comparator，意思是开发者还是要在具体场景下选择最合适的那种比较器而已。



---------------------------------------------------------------------------------------------------------------------------------------------------------------


二，并发？
多线程：
进程：正在进行中的程序（直译），程序的一次执行，线程引入之前，进程是资源持有的最小单位，也是程序运行的最小单元。
线程：就是进程中一个负责程序执行的控制单元（执行路径）。
进程间通信方式有: 消息传递 共享内存 管道 套接字 
并行：是物理层面的，是同时发生多个并发事件。
并发：不一定同时间完成多件事情，是CPU切换完成，是逻辑上的同时发生，多线程不能跨系统。
多线程的好处：解决了多部分同时运行的问题。
多线程的弊端：线程太多会导致效率的降低。（即是速度的放慢）
其实应用程序的执行都是cpu在做着快速的切换，这个切换是随机的。
JVM（虚拟机）在启动时候就启动了多个线程，至少有五个线程运行。

线程实现的方式：
1，继承Thread类。
2，实现Runnable接口。
3，实现Callable接口。
其中Callable，的run方法可以有返回值，在开启线程的时候，需要通过FutureTask将Callable封装成一个Runnable才可以执行。

线程安全问题产生的原因：
1，多个线程同时操作一个共享数据。
2，线程之前竞争同一把锁。

解决思路：
就是把多条操作共享数据的代码封装起来，当一个线程在执行这些代码的时候，规定其他线程不能参与运算。
必须要当前线程把这些代码都执行完毕后，其他线程才可以参与运算。
1，用synchronized同步代码块
2，用synchronized同步函数
同步函数和同步代码块的区别：
1，同步函数的锁是对象锁或者类锁。
2，同步代码快的锁是任意对象。
建议使用同步代码快。
注意：同步函数不能由static修饰，一旦修饰了，静态中没有this，同步函数就没有同步锁this了。静态同步函数所使用的同步锁是该函数所属的字节码文件对象。
可以用this.Class()表示，也可以用类名.class表示。


sychronized中的锁机制：
JVM规范规定JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。
代码块同步是使用monitorenter和monitorexit指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。
monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。
任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。
Monitor：
什么是Monitor？我们可以把它理解为一个同步工具，也可以描述为一种同步机制，它通常被描述为一个对象。与一切皆对象一样，所有的Java对象是天生的Monitor，每一个Java对象都有成为Monitor的潜质，因为在Java的设计中，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。

锁优化：
在jdk1.6中对锁的实现引入了大量的优化，如锁粗化（Lock Coarsening）、锁消除（Lock Elimination）、轻量级锁（Lightweight Locking）、 偏向锁（Biased Locking）、适应性自旋（Adaptive Spinning）等技术来减少锁操作的开销。锁主要存在四中状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。



对象锁（synchronized method{}）和类锁（static sychronized method{}）的区别：
对象锁也叫实例锁，对应synchronized关键字，当多个线程访问多个实例时，它们互不干扰，每个对象都拥有自己的锁，如果是单例模式下，那么就是变成和类锁一样的功能。对象锁防止在同一个时刻多个线程访问同一个对象的synchronized块。如果不是同一个对象就没有这样子的限制。对象锁锁的是当前对象的实例。
类锁对应的关键字是static sychronized，是一个全局锁，无论多少个对象否共享同一个锁（也可以锁定在该类的class上或者是classloader对象上），同样是保障同一个时刻多个线程同时访问同一个synchronized块，当一个线程在访问时，其他的线程等待。类锁锁的是当前对象的Class对象，只有一个Class对象。

总结：
1.类锁是对静态方法使用synchronized关键字后，无论是多线程访问单个对象还是多个对象的sychronized块，都是同步的。
2.对象锁是实例方法使用synchronized关键字后，如果是多个线程访问同个对象的sychronized块，才是同步的，但是访问不同对象的话就是不同步的。
3.类锁和对象锁是两种不同的锁，可以同时使用，但是注意类锁不要嵌套使用，这样子容易发生死锁。
4，对象锁，锁的是类的对象实例。类锁，锁的是每个类的的Class对象，每个类的的Class对象在一个虚拟机中只有一个，所以类锁也只有一个。
线程同步之后，会影响效率。



使变量可见的关键字：
volatile：
适合于只有一个线程写，多个线程读的场景，因为它只能确保可见性。原理：缓存一致性协议，如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了（类似于乐观锁），当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。
注意：volatile保证可见性，是保证所有指令执行完了之后的值是可见的，指令执行的过程中是没有其他线程来修改这个值，但是如果多个线程在对这个变量进行写操作的时候，在A线程将主内存中的变量值修改的过程中（指令执行的过程中），B线程又修改了主内存中的值，这时候等A线程将修改后的值放回主内存的时候，主内存中就有两个变量的值，这时候就混乱了，这种情况就不能保证数据的原子性。
使用场景：一个线程写，多个线程读的情况。
并发专家建议我们远离volatile是有道理的，这里再总结一下：
1，volatile是在synchronized性能低下的时候提出的。如今synchronized的效率已经大幅提升，所以volatile存在的意义不大。
2，如今非volatile的共享变量，在访问不是超级频繁的情况下，已经和volatile修饰的变量有同样的效果了。
3，volatile不能保证原子性。
4，volatile会禁止指令重排序。
	JMM对volatile的内存屏障插入策略：
		1，在每个volatile写操作的前面插入一个StoreStore屏障，后面插入一个StoreLoad屏障。
		2，在每个volatile读操作的后面插入两个个LoadLoad屏障。






ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储，其实意思差不多。
ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量。
ThreadLocal内部就是一个ThreadLocalMap。
ThreadLocal是如何为每个线程创建变量的副本的：
1，首先，在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，
这个threadLocals就是用来存储实际的变量副本的，键值为当前ThreadLocal变量（即是对应着当前线程），value为变量副本（即Entry类型的变量）。
2，初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，
就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，
存到threadLocals。
3，然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。
总结一下：
　　1）实际的通过ThreadLocal创建的副本是存储在每个线程自己的threadLocals中的；
　　2）为何threadLocals的类型ThreadLocalMap的键值为ThreadLocal对象，因为每个线程中可有多个threadLocal变量，
	就像上面代码中的longLocal和stringLocal；
　　3）在进行get之前，必须先set，否则会报空指针异常；
　　   如果想在get之前不需要调用set就能正常访问的话，必须重写initialValue()方法。
　　　 因为我们发现如果没有先set的话，即在map中查找不到对应的存储，
	   则会通过调用setInitialValue方法返回i，而在setInitialValue方法中，有一个语句是T value = initialValue()， 
	   而默认情况下，initialValue方法返回的是null。
	4）因为会为每个线程分配一个副本，所以不宜存储比较大的对象，消耗内存空间。
	5）ThreadLocal遇上线程池的问题及解决办法：
      	线程池中的线程在任务执行完成后会被复用，所以在线程执行完成时，要对ThreadLocal进行清理（清除掉与本线程相关联的value 对象）。不然，被复用的线程去执行新的任务时会使用被上一个线程操作过的value对象，从而产生不符合预期的结果，会产生内存泄漏。




中断：interrupt（只是告诉线程要中断了，但是线程并不会马上中断）   在发生中断异常的时候，会自动将中断状态变成false
start（进入就绪状态）
wait（进入阻塞状态，会释放锁）--需要被唤醒（一般使用notifyALL，而不使用notify，因为notify并不能唤醒指定的线程，一般唤醒等待队列中的第一个线程，如果唤醒错了线程，容易造成死锁。）
线程进入等待队列，是一个单向链表。
notify，notifyAll（不立即释放锁，必须等到所在同步块执行完之后才释放锁。）
sleep（释放执行权，不会释放锁，由执行变为阻塞）sleep()方法不考虑线程优先级，所有的线程都有机会执行。
yield（释放执行权，不会释放锁，由执行变为就绪）yield()方法只能使同优先级或者高优先级的线程得到执行机会。
join，是当前线程释放执行权，将执行权交给被调用join的线程，当被调用join的线程执行完了之后，当前线程才获取到执行权。
线程挂起：
挂起：一般是主动的，由系统或程序发出，甚至于辅存中去。（不释放CPU，可能释放内存，放在外存，可以理解为，当前线程正在运行中，突然被CPU切换出去，等会再由CPU切换回来运行。）
阻塞：一般是被动的，在抢占资源中得不到资源，被动的挂起在内存，等待某种资源或信号量（即有了资源）将他唤醒。（释放CPU，不释放内存）



Fork/Join：
是一个分而治之的任务框架，如一个任务需要多线程执行，分割成很多块计算的时候，可以采用这种方法。
动态规范：和分而治之不同的是，每个小任务之间互相联系。
工作密取：分而治之分割了每个任务之后，某个线程提前完成了任务，就会去其他线程偷取任务来完成，加快执行效率。同时，第一个分配的线程是从队列中的头部拿任务，当完成任务的线程去其他队列拿任务的时候是从尾部拿任务，所以这样就避免了竞争。
在Java的Fork/Join框架中，使用两个类完成上述操作:
　　1.ForkJoinTask:我们要使用Fork/Join框架，首先需要创建一个ForkJoin任务。该类提供了在任务中执行fork和join的机制。通常情况下我们不需要直接集成ForkJoinTask类，只需要继承它的子类，Fork/Join框架提供了两个子类：
　　　　a.RecursiveAction：用于没有返回结果的任务
　　　　b.RecursiveTask:用于有返回结果的任务
　　2.ForkJoinPool:ForkJoinTask需要通过ForkJoinPool来执行.他其实也是一个线程池。它使用了一个无限队列来保存需要执行的任务，而线程的数量则是通过构造函数传入，如果没有向构造函数中传入希望的线程数量，那么当前计算机可用的CPU数量会被设置为线程数量作为默认值。
	注意：ForkJoinPool的invoke方法是同步阻塞的，excute方法是异步的。
Fork/Join框架的实现原理:
　　ForkJoinPool由ForkJoinTask数组和ForkJoinWorkerThread数组组成，ForkJoinTask数组负责将存放程序提交给ForkJoinPool，而ForkJoinWorkerThread负责执行这些任务。
使用场景：
Fork/Join框架适合能够进行拆分再合并的计算密集型（CPU密集型）任务。ForkJoin框架是一个并行框架，因此要求服务器拥有多CPU、多核，用以提高计算能力。
如果是单核、单CPU，不建议使用该框架，会带来额外的性能开销，反而比单线程的执行效率低。当然不是因为并行的任务会进行频繁的线程切换，因为Fork/Join框架在进行线程池初始化的时候默认线程数量为Runtime.getRuntime().availableProcessors（），单CPU单核的情况下只会产生一个线程，并不会造成线程切换，而是会增加Fork/Join框架的一些队列、池化的开销。
比如：数据迁移到数据库，解析excel等等可以拆分完成的任务都可以使用到forkjoin。



常用的并发工具类：
CountDownLatch：
作用：是一组线程等待其他的线程完成工作以后在执行，加强版join，await用来等待，countDown负责计数器的减一
CyclicBarrier：
让一组线程达到某个屏障，被阻塞，一直到组内最后一个线程达到屏障时，屏障开放，所有被阻塞的线程会继续运行CyclicBarrier(int parties)，CyclicBarrier(int parties, Runnable barrierAction)，屏障开放，barrierAction定义的任务会执行
CountDownLatch和CyclicBarrier辨析：
1、countdownlatch放行由第三者控制，CyclicBarrier放行由一组线程本身控制
2、countdownlatch放行条件》=线程数，CyclicBarrier放行条件=线程数
3、CountDownLatch会阻塞主线程，CyclicBarrier不会阻塞主线程，只会阻塞子线程。
4、CountDownLatch的计数器只能使用一次。而CyclicBarrier的计数器可以使用reset()方法重置。所以CyclicBarrier能处理更为复杂的业务场景，比如如果计算发生错误，可以重置计数器，并让线程们重新执行一次。

Semaphore：
控制同时访问某个特定资源的线程数量，用在流量控制，一个线程要访问共享资源，先获得信号量，如果信号量的计数器值大于1，意味着有共享资源可以访问，则使其计数器值减去1，再访问共享资源。如果计数器值为0,线程进入休眠。当某个线程使用完共享资源后，释放信号量，并将信号量内部的计数器加1，之前进入休眠的线程将被唤醒并再次试图获得信号量。
Exchange：
两个线程间的数据交换。


Future：
	对于多线程，如果线程A要等待线程B的结果，那么线程A没必要等待B，直到B有结果，可以先拿到一个未来的Future，等B有结果是再取真实的结果。
Future的核心思想是：
	一个方法f，计算过程可能非常耗时，等待f返回，显然不明智。可以在调用f的时候，立马返回一个Future，可以通过Future这个数据结构去控制方法f的计算过程。
FutureTask是Future的实现类，内部的get阻塞和run方法的阻塞和唤醒的方式是使用的LockSupport来实现的。
当线程数量不确定的时候，就使用Future，因为future的get方法会等待线程执行之后，其他线程才会继续执行。

让一个线程等待另一个线程执行完之后再执行：
1，CountDownLatch
2，join方法
3，使用Callable，调用FutureTask的get方法


CAS：
CAS有3个操作数，内存地址值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时（比较的是地址引用），将内存值V修改为B，否则返回V。
CAS是实现自旋锁的基础，CAS 利用 CPU 指令保证了操作的原子性，以达到锁的效果，循环这个指令，直到成功为止。
原子操作类：AtomicInteger等，核心就是CAS（CompareAndSwap）
原子操作类的使用，当高并发的情况下，对于基本数据类型或者引用数据类型的操作，避免多线程问题的处理方式一般有
加锁，但是加锁会影响性能，所以这个时候可以考虑使用原子操作类。CAS由于是在硬件方面保证的原子性，不会锁住当前线程，所以执行效率是很高的。
注意：原子操作和锁是一样的一种可以保证线程安全的方式，如何让线程安全就看如何使用锁或者如何使用原子操作CAS使用了正确的原子操作，所以保证了线程安全。
Atomic原子类CAS操作比较的是内存偏移量，即内存地址。

好处：保证了数据的原子性
坏处：
1，ABA问题（并发1在修改数据时，虽然还是A，但已经不是初始条件的A了，中间发生了A变B，B又变A的变化，此A已经非彼A，数据却成功修改，可能导致错误，这就是CAS引发的所谓的ABA问题。     可以使用乐观锁的方式解决。）
2，循环时间长开销大（自旋）
3，只能保证一个共享变量的原子操作（可以使用AtomicRefrence原子操作类将多个变量合并成一个对象来解决）
解决ABA问题：
AtomicMarkableReference，内部是一个boolean类型的版本号，可以记录是否被更改过。
AtomicStampedReference，内部是一个int类型的版本号，可以记录被更改的次数。



显示锁：Lock
Lock接口和synchronized的比较：
1，synchronized代码更简洁
2，Lock，效率比隐士锁更高
3，Lock可以在获取锁可以被中断，超时获取锁，尝试获取锁
Lock接口有三个实现类：一个是ReentrantLock,另两个是ReentrantReadWriteLock类中的两个静态内部类ReadLock和WriteLock。
ReentrantReadWriteLock类实现了ReadWriteLock接口。

锁的公平和非公平：
如果在时间上，先对锁进行获取的请求，一定先被满足，这个锁就是公平的，不满足，就是非公平的，意思就是，线程等待队列中的优先级高的线程先获取到锁，就是公平锁，没有获取到锁，就是非公平锁，非公平的效率一般来讲更高，因为非公平锁减少了线程挂起的几率，后来的线程有一定几率逃离被挂起的开销。

ReentrantLock（可重入锁，构造函数可以指定是否是公平锁，默认是非公平锁）：
可重入锁：一个同步方法可以调用另外一个同步方法，一个线程已经拥有某个对象的锁，再次申请的时候仍然会得到该对象的锁。
不可重入锁：即当前线程获取这把锁后，要想再拿到这把锁，必须释放当前持有的锁，这时我们称这个锁是不可重入的。
ReentrantLock内部实现了一个非公平锁和公平锁：
非公平锁（NonfairSync）：继承Sync（内部实现了AQS的锁），其中在tryAcquire方法中，判断如果是当前线程，就会将state状态值一直累加，实现锁的可重入，同时，在释放的时候依次递减状态值。
公平锁（fairSync）：继承Sync（内部实现了AQS的锁），在获取锁的时候，首先根据hasQueuedPredecessors方法判断当前节点有没有前驱节点，如果有的话，就将当前线程设置为挂起状态，其他跟非公平锁实现一致。

ReentrantLock和Syn关键字：都是排他锁，同一时刻只允许一个线程访问。
ReentrantReadWriteLock读写锁：读写锁实际是一种特殊的自旋锁，同一时刻允许多个读线程同时访问，但是写线程访问的时候，所有的读和写都被阻塞，最适宜与读多写少的情况。读写锁在内部有两个实现了Lock接口的静态内部类，读锁和写锁。
同步状态state：
	同步状态由一个整型变量表示，因为这个变量需要表示多个线程的读和写的状态，因此读写锁在实现上将该变量的高16位表示读，低16位表示写，其中每位的读线程重入的次数是由HoldCounter对象包装之后放入到ThreadLocal中。
注意：
	1，在读多写少的情况下，性能比一般的排他锁和Syn关键字要高。
	2，当有读锁时，写锁就不能获得，而当有写锁时，当前线程还可以获取读锁，其他线程不能获取读锁，同一线程可以保证数据可见性。	  如果持有读锁的时候去获取写锁，这就是所谓锁的升级，这是不允许的，因为读锁可能有多个线程获取了，如果允许获得写锁，那就	 真正可能产生可见性性问题。注意：（可见性是针对不同线程而言）
	3，锁降级：
		锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。
		原理：
			锁降级存在争议，在很多本书里面出现过，锁降级中，读锁的获取的目的是“为了保证数据的可见性”。而得到这个结论的依据是 “如果当前线程不获取读锁而是直接释放写锁，假设此刻另一个线程（记作线程T）获取了写锁并修改了数据，那么当前线程无法感知线程 T 的数据更新”。这里貌似有个漏洞：如果另一个线程获取了写锁（并修改了数据），那么这个锁就被独占了，没有任何其他线程可以读到数据，更不用谈 “感知数据更新”。
			所以，主要是性能上的优化，如果先释放写锁，再获取读锁，势必引起锁的争抢和线程上下文切换，影响性能，所以通过锁降级，可以避免锁的竞争。
	4，锁升级：
		在没有释放读锁的情况下，就去申请写锁，这属于锁升级，ReentrantReadWriteLock是不支持的。
	5，读锁本质上是个共享锁。但读锁对锁的获取做了很多优化，比如：
		1，使用firstReader和cachedHoldCounter对第一个读锁线程和最后一个读锁线程做优化，优化点主要在释放的时候对计数器的获取，其他获取读锁的线程就放在HoldCounter中。
		2，同时，如果在获取读锁的过程中写锁被持有,JUC并没有让所有线程痴痴的等待，而是判断入如果获取读锁的线程是正巧是持有写锁的线程，那么当前线程就可以降级获取写锁，否则就会死锁了（为什么死锁，当持有写锁的线程想获取读锁，但却无法降级，进入了等待队列，肯定会死锁）。
		3，还有一点就是性能上的优化，如果先释放写锁	，再获取读锁，势必引起锁的争抢和线程上下文切换，影响性能。
	6，在读锁和写锁的获取过程中支持中断。
	7，提供确定锁是否被持有等辅助方法。


显示锁中的条件接口Condition，包含如等待和唤醒之类的方法，Condition对象是由Lock对象（调用Lock对象的newCondition（）方法）创建出来的，换句话说，Condition是依赖Lock对象的。
在显示锁中，唤醒是用signal，而最好不用signalAll，因为signal可以精准唤醒指定的线程，而在隐士锁中用notifyAll，而不用notify，因为notify不能精准唤醒，可能导致死锁。signalAll只能唤醒指定Condition上的等待的线程，其他线程也不能被唤醒，和notifyAll不同。



LockSupport：
 LockSupport提供park()和unpark()方法实现阻塞线程和解除线程阻塞,实现的阻塞和解除阻塞是基于”许可(permit)”作为关联,permit相当于一个信号量(0,1),默认是0. 线程之间不再需要一个Object或者其它变量来存储状态,不再需要关心对方的状态.(和Semaphore有些许区别,许可证不会累加，最多只有一张）。
总结
简而言之:
1.实现机制和wait/notify有所不同,面向的是线程
2.不需要依赖监视器
3.与wait/notify没有交集
4.使用起来方便灵活



AQS：
AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch...,AQS采用的是模板方法模式。
AQS中有独占锁和共享锁，重入锁。
AQS中的模板方法：
	独占式获取：
		accquire
		acquireInterruptibly
		tryAcquireNanos
	共享式获取：
		acquireShared
		acquireSharedInterruptibly
		tryAcquireSharedNanos
	独占式释放锁：
		release
	共享式释放锁：
		releaseShared

需要子类覆盖的流程方法：
	独占式获取：tryAcquire
	独占式释放：tryRelease
	共享式获取：tryAcquireShared
	共享式释放：tryReleaseShared
	这个同步器是否处于独占模式：isHeldExclusively

同步状态state（标志的当前线程是否获取到锁）：
getState：获取当前的同步状态
setState：设置当前同步状态，不能保证原子性
compareAndSetState：使用CAS设置同步状态，保证状态设置的原子性

独占锁（类似于ReentrantLock和ReentrantReadWriteLock里的写锁都是独占锁）：
	定义一个state，如果是1就是拿到了锁，反之则没有，独占锁就是一个排它锁。
共享锁（类似于ReentrantReadWriteLock里的读锁是共享锁）：
	定义state是很多个锁的数量，拿到一个锁就state--，释放一个就state++，Semaphore的实现就是参照共享锁。
重入锁：
	比如一个线程拿到一个锁，在run中又调用了其他同步方法，如果不能重入，一个线程就要拿到两个锁，这样就不行。

AQS的数据结构--双向链表：
	1，节点Node
		竞争失败的线程会打包成Node放到同步队列，Node可能的状态里：
			CANCELLED：线程等待超时或者被中断了，需要从队列中移走
			SIGNAL：后续的节点处于等待状态，当前节点被释放了，通知后面的节点去运行
			CONDITION：当前节点处于等待队列中
			PROPAGATE：共享，表示状态要往后面的节点传播
			0：表示初始状态

	2，FIFO同步队列
AQS的原理就是：
当一个锁线程获取锁失败的时候，会将这个线程封装成一个节点Node，通过addWaiter方法放入到FIFO同步队列中的尾部（这一步是试用CAS操作，保证原子性），然后再通过acquireQueued方法自旋从同步队列的头部依次获取锁，如果其中某个获取锁失败，就继续封装成一个Node放入队列的尾部，直到获取锁返回。
比如：当前有10个线程去竞争锁，有一个拿到了锁，另外9个就会被依次封装成一个Node节点，按照线程优先级依次从尾部放入到同步队列中，用节点的前驱和后驱连接起来行程双向链表，然后当获取锁的线程释放了锁之后，就会依次从头部去唤醒线程。
注意：
	1，在增加尾节点的时候，是采用的CAS，因为在竞争锁的时候可能是多个线程，最后有多个线程失败需要进入到队列中的某个尾节点，所以需要CAS。
	2，在删除头节点的时候，不需要采用CAS，因为头节点的线程就只有一个，不存在竞争。

ConditionObject的数据结构-单向链表：
实现原理：ConditionObject内部实现了一个FIFO（先进先出）等待队列，队列的每个节点都是等待在Condition对象上的线程的引用，在调用Condition的await（）方法之后，线程释放锁，构造成相应的节点进入等待队列等待，其中节点的定义复用AQS的Node定义。插入节点只需要将原有尾节点的nextWaiter指向当前节点，并且更新尾节点。更新节点并没有像AQS更新同步队列使用CAS是因为调用await（）方法的线程必定是获取了锁的线程，锁保证了操作的线程安全。
当调用await方法之后，会将同步队列中的线程放入到等待队列中，当调用single唤醒之后，处于就绪状态，会将等待队列中的线程放入到同步队列中。
为什么不建议用singleAll唤醒？
	因为singleAll会将所有的线程都唤醒，然后全部加入到同步队列中，而同步队列中只有一个线程可以获取到锁，所以对于这种操作是无用功。
注意：AQS实质上拥有一个同步队列和多个等待队列。




阻塞队列：
	1，概念、生产者消费者模式：
		阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。
		1)当队列满的时候，插入元素的线程被阻塞，直达队列不满。
		2)队列为空的时候，获取元素的线程被阻塞，直到队列不空。

	2，生产者和消费者模式：
		生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等 待生产者。为了解决这种生产消费能力不均衡的问题，便有了生产者和消费者模式。生产者和消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通信，而是通过阻塞队列来进行通信，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。

	3，常用方法：
		方法	    抛出异常	返回值	  一直阻塞	  超时退出
		插入方法	add	        offer	     put	  Offer(time)
		移除方法	remove	    poll	     take	  Poll(time)
		检查方法	element	    peek	     N/A	  N/A
		1，抛出异常：当队列满时，如果再往队列里插入元素，会抛出IllegalStateException（"Queuefull"）异常。当队列空时，从队列					里获取元素会抛出NoSuchElementException异常。
		2，返回特殊值：当往队列插入元素时，会返回元素是否插入成功，成功返回true。如果是移除方法，则是从队列里取出一个元素，					如果没有则返回null。
		3，一直阻塞：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到队列可用或者响应中断退出					。当队列空时，如果消费者线程从队列里take元素，队列会阻塞住消费者线程，直到队列不为空。
		4，超时退出：当阻塞队列满时，如果生产者线程往队列里插入元素，队列会阻塞生产者线程一段时间，如果超过了指定的时间，生					产者线程就会退出。

	4，常用阻塞队列：
		1，ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列，按照先进先出原则，要求设定初始大小。
		2，LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列，按照先进先出原则，可以不设定初始大小，默认是Integer.Max_V		alue。
		3，ArrayBlockingQueue和LinkedBlockingQueue不同：
				锁上面：ArrayBlockingQueue只有一个锁，LinkedBlockingQueue用了两个锁。
				实现上：ArrayBlockingQueue直接插入元素，LinkedBlockingQueue需要转换。
		4，PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列，默认情况下，按照自然顺序，要么实现compareTo（）方法，指		定构造参数Comparator。
		5，DelayQueue：一个使用优先级队列实现的无界阻塞队列，支持延时获取的元素的阻塞队列，元素必须要实现Delayed接口。适用	   场景：实现自己的缓存系统，订单到期，限时支付等等。
		6，SynchronousQueue：一个不存储元素的阻塞队列，每一个put操作都要等待一个take操作，所以会产生生产者和消费者能力不匹	   配的问题。
		7，LinkedTransferQueue：一个由链表结构组成的无界阻塞队列，transfer（），必须要消费者消费了以后方法才会返回，tryTran		sfer()无论消费者是否接收，方法都立即返回。
		8，LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列，可以从队列的头和尾都可以插入和移除元素，实现工作密取，方	   法名带了First对头部操作，带了last从尾部操作，另外：add=addLast;	remove=removeFirst;	take=takeFirst。




线程池：
	当并发线程多了之后，每个线程的频繁创建于销毁会导致性能降低，不好管理，为了解决这样的问题，就出现了线程池，线程池就是管理线程，我们不需要关心的创建与销毁，大大增加了我们开发的效率和程序的性能。
	作用：
		1、	降低资源的消耗。降低线程创建和销毁的资源消耗。
		2、	提高响应速度：线程的创建时间为T1，执行时间T2,销毁时间T3，免去T1和T3的时间。
		3、	提高线程的可管理性。

	线程池的创建：
	ThreadPoolExecutor，jdk所有线程池实现的父类。
		其中各个参数含义：
		int corePoolSize：线程池中核心线程数小于corePoolSize（线程池大小），就会创建新线程去执行任务。
						  等于corePoolSize，这个任务就会保存到BlockingQueue。
						  如果调用prestartAllCoreThreads方法就会一次性的启动corePoolSize个数的线程。
		int maximumPoolSize：允许的最大线程数，当BlockingQueue也满了，并且小于maximumPoolSize时候就会再次创建新的线程。
		keepAliveTime：线程空闲下来后存活的时间，这个参数只在大于corePoolSize才有用。
		TimeUnit unit：存活时间的单位值。
		BlockingQueue<Runnable> workQueue：保存任务的阻塞队列。
		ThreadFactory threadFactory；创建线程的工厂，给新建的线程赋予名字.
		RejectedExecutionHandler handler（饱和策略，四种）：
			1，AbortPolicy ：直接抛出异常，默认。
			2，CallerRunsPolicy：用调用者所在的线程来执行任务，不用线程池执行了。
			3，DiscardOldestPolicy：丢弃阻塞队列里最老的任务，队列里最靠前的任务。
			4，DiscardPolicy ：当前任务直接丢弃。
			饱和策略：即是当线程数大于maximumPoolSize的时候，已经饱和的了，提供一个这四种处理的策略。
			实现自己的饱和策略，需要实现RejectedExecutionHandler接口。

	工作机制：
		1）线程池判断核心线程池里的线程是否全都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。
		2）线程池判断任务阻塞队列是否已经满。如果任务阻塞队列没有满，则将新提交的任务存储在这个任务阻塞队列里。如果任务阻塞队列满了，则进入下个流程。
		3）线程池判断线程池中的工作的线程数是否小于最大线程池数。如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。

	方法：
		提交任务：
			execute(Runnable command) ：不需要返回
			Future<T> submit(Callable<T> task) ：需要返回
		关闭线程池：
			shutdown(),shutdownNow();
			shutdownNow()：设置线程池的状态，还会尝试停止正在执行和没有执行任务的线程。
			shutdown()：设置线程池的状态，只会中断所有没有执行任务的线程。


	合理配置线程池:
		根据任务的性质区分：
			计算密集型（CPU密集型），IO密集型，混合型
			计算密集型：加密，大数分解，正则…….，这种类型，在使用线程池的时候，设置线程数适当小一点，最大推荐：机器的Cpu核			  心数+1。（注意：这是逻辑核心数）
						1，为什么+1,？
							为了防止页缺失（页缺失：数据未全部从磁盘读取到内存中，数据丢失了），（机器的Cpu核心=Runtime.getRuntime().availableProcessors();)
						2，为什么不是大于CPU核心数+1？
							因为如果线程数大于太多CPU核心数，就会出现不必要的上下文切换，造成性能消耗。
			IO密集型：读取文件，数据库连接，网络通讯, 线程数适当大一点，机器的Cpu核心数*2,
			混合型：尽量拆分，IO密集型>>计算密集型，拆分意义不大，IO密集型~计算密集型
		注意：队列的选择上，应该尽量使用有界，无界队列可能会导致内存溢出，发生OOM。


	Executor框架：
		1，一个接口，其定义了一个接收Runnable对象的方法executor，其方法签名为executor，是线程池的定级接口，ThreadPoolExecut	  or是它的实现类。
		2，ExecutorService：是一个比Executor使用更广泛的子类接口，其提供了生命周期管理的方法，以及可跟踪一个或多个异步任务	 执行状况返回Future的方法。
		3，可以通过Executors这个工厂类获取到一些其他的预定义线程池，这些线程池都是Executor的实现类。


	预定义的线程池：
		FixedThreadPool：
			创建固定线程数量的，适用于负载较重的服务器，其中使用了无界的阻塞队列（LinkedBliockingQueue）。
		SingleThreadExecutor：
			创建单个线程，可以让任务按顺序执行，不会有多个线程活动，使用了无界队列。
		CachedThreadPool：
			会根据需要来创建新线程的，执行很多短期异步任务的程序，使用了SynchronousQueue。
		WorkStealingPool（JDK7以后）：
			基于ForkJoinPool实现，是一个工作密取的线程池。
		ScheduledThreadPoolExecutor：
			需要定期执行周期任务，Timer不建议使用了。
		newSingleThreadScheduledExecutor：
			只包含一个线程，只需要单个线程执行周期任务，保证顺序的执行各个任务。
		newScheduledThreadPool：
			可以包含多个线程的，线程执行周期任务，适度控制后台线程数量的时候。
			方法说明：
			schedule：只执行一次，任务还可以延时执行
			scheduleAtFixedRate：提交固定时间间隔的任务，间隔是上一次开始的时刻到下一次开始的时刻的间隔。
				scheduleAtFixedRate任务超时：
					假设：规定60s执行一次，第一个任务 时长 80s，第二个任务20s，第三个任务50s，则：
						第一个任务第0秒开始，第80S结束；
						第二个任务第80s开始，在第100秒结束；
						第三个任务第120s秒开始，170秒结束；
						第四个任务从180s开始；
			scheduleWithFixedDelay：提交固定延时间隔执行的任务，间隔是上一次完成的时刻到下一次开始执行的时刻的间隔。
			注意：当任务执行异常，如果直接抛出，会阻塞住当前任务，其他任务不会影响，所以，尽量用try，catch处理整个任务代码块，防止任务异常的时候阻塞。

	CompletionService：
		问题：当线程池中的任务是有返回值的时候，放入线程池的任务是有顺序的，所以当这些任务执行完成之后，从阻塞队列中拿执行的任务的结果的时候，也只能是按照放入的顺序，先进先出的规则拿去结果，这样可能会造成CPU的浪费，比如我只想拿第三个任务执行的结果，这时候我必须得等到前两个任务执行完才能拿到，同时，也不能让先完成的任务先去执行下一个任务，所以这样由此产生了CompletionService来解决。

		CompletionService的实现是维护一个保存Future对象的BlockingQueue。只有当这个Future对象状态是结束的时候，才会加入到这个Queue中，take()方法其实就是Producer-Consumer中的Consumer。它会从Queue中取出Future对象，如果Queue是空的，就会阻塞在那里，直到有完成的Future对象加入到Queue中。



并发安全：
	类的线程安全定义：
		如果多线程下使用这个类，不管多线程如何使用和调度这个类，这个类总是表示出正确的行为，这个类就是线程安全的。
	类的线程安全表现为：
		1，操作的原子性
		2，内存的可见性
	不做正确的同步，在多个线程之间共享状态的时候，就会出现线程不安全。

	怎么才能做到类的线程安全？
	1，栈封闭：
		所有的变量都是在方法内部声明的，这些变量都处于栈封闭状态，都是线程安全的。
	2，无状态：
		没有任何成员变量的类，就叫无状态的类。
	3，让类不可变：
		让状态不可变，两种方式：
			1，加final关键字，对于一个类，所有的成员变量应该是私有的，同样的只要有可能，所有的成员变量应该加上final关键字，但是加上final，要注意如果成员变量又是一个对象时，这个对象所对应的类也要是不可变，才能保证整个类是不可变的。
			2、根本就不提供任何可供修改成员变量的地方，同时成员变量也不作为方法的返回值。
	4，volatile：
		保证类的可见性，最适合一个线程写，多个线程读的情景。
	5，加锁和CAS。
	6，安全的发布：
		类中持有的成员变量，特别是对象的引用，如果这个成员对象不是线程安全的，通过get等方法发布出去，会造成这个成员对象本身持有的数据在多线程下不正确的修改，从而造成整个类线程不安全的问题。


	Servlet：
		不是线程安全的类，为什么我们平时没感觉到：
			1、在需求上，很少有共享的需求。
			2，接收到了请求，返回应答的时候，都是由一个线程来负责的。


	线程安全问题：
		死锁：
			资源一定是多于1个，同时小于等于竞争的线程数，资源只有一个，只会产生激烈的竞争。
			死锁的根本成因：获取锁的顺序不一致导致。
			有n个进程，共享的同类资源数为m，则避免死锁的最少资源数是n（m-1）+1。
			产生死锁的原因：
				1，因为系统资源不足
				2，进程运行推进的顺序不合适
				3，资源分配不当等
			产生死锁的四个必要条件：
				1，互斥条件：一个资源每次只能被一个进程使用
				2，请求与保持条件：一个进程因请求字眼而阻塞时，对已获得的资源保持不放
				3，不可剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺
				4，循环等待条件：若干进程之间形成一种头尾相接的循环等到资源关系
			怀疑发送死锁：
				简单的死锁：
					1，通过jps 查询应用的 id，
					2，再通过jstack id 查看应用的锁的持有情况
					解决办法：保证加锁的顺序性
				动态的死锁：
					动态顺序死锁，在实现时按照某种顺序加锁了，但是因为外部调用的问题，导致无法保证加锁顺序而产生的。
					例如：
						void test(Account fromAccount,Account toAccount){
    						synchronized (fromAccount) {
						        synchronized (toAccount) {
						        }
						    }
						}
					虽然内部固定了加锁的顺序，但是外部传入的锁的顺序不一样，所以可能造成死锁。
					解决：
					1、	通过内在排序，保证加锁的顺序性（调用System.identityHashCode(obj)获取原始的hashcode值，再排序确定顺序，如果hash值一样了，就在外部再定义一个锁，让这两个线程去竞争一次这个锁，谁拿到锁再进入依次获取之前两个锁）
					2、	通过尝试拿锁，也可以，在传入的对象内部定义显示锁，然后自旋，依次调用tryAcquired，尝试拿锁，拿不到就自旋再获取：
							while(true) {
					    		if(from.getLock().tryLock()) {
					    			try {
					    				if(to.getLock().tryLock()) {
					    					try {
					    					}finally {
					    						to.getLock().unlock();
					    					}
					    				}
					    			}finally {
					    				from.getLock().unlock();
					    			}
					    		}
					    		SleepTools.ms(r.nextInt(10));//休眠一个随机数，否则会发生活锁。
					    	}
					    }
					3、 银行家算法是一种最有代表性的避免死锁的算法。又被称为“资源分配拒绝”法。在避免死锁方法中允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配资源的安全性，若分配不会导致系统进入不安全状态，则分配，否则等待。为实现银行家算法，系统必须设置若干数据结构。


		活锁：
			尝试拿锁的机制中，发生多个线程之间互相谦让，不断发生拿锁，释放锁的过程，比如线程1尝试拿到A锁，尝试拿B锁失败，线程2尝试拿到B锁，尝试拿A锁失败，这样线程1和线程2都循环再次尝试获取两个锁，这时候又是之前的情况。
			解决办法：每个线程休眠随机数，错开拿锁的时间。

		线程饥饿：
			低优先级的线程，总是拿不到执行时间。

	性能和思考：
		使用并发的目标是为了提高性能，引入多线程后，其实会引入额外的开销，如线程之间的协调、增加的上下文切换，线程的创建和销毁，线程的调度等等。过度的使用和不恰当的使用，会导致多线程程序甚至比单线程还要低。
		衡量应用的程序的性能：服务时间，延迟时间，吞吐量，可伸缩性等等，其中服务时间，延迟时间（多快），吞吐量（处理能力的指标，完成工作的多少）。多快和多少，完全独立，甚至是相互矛盾的。
		对服务器应用来说：多少（可伸缩性，吞吐量）这个方面比多快更受重视。
		我们做应用的时候：
			1、	先保证程序正确，确实达不到要求的时候，再提高速度。（黄金原则）
			2、	一定要以测试为基准。
		一个应用程序里，串行的部分是永远都有的。
		Amdahl定律  ：  1/(F+(1-N)/N)   F:必须被串行部分,程序最好的结果， 1/F。


		影响性能的因素：
			1，上下文切换：
				是指CPU 从一个进程或线程切换到另一个进程或线程。一次上下文切换花费5000~10000个时钟周期，几微秒。在上下文切换过程中，CPU会停止处理当前运行的程序，并保存当前程序运行的具体位置以便之后继续运行。从这个角度来看，上下文切换有点像我们同时阅读几本书，在来回切换书本的同时我们需要记住每本书当前读到的页码。
				上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。
			2，内存同步：
				一般指加锁，对加锁来说，需要增加额外的指令，这些指令都需要刷新缓存等等操作。
			3，阻塞：
				会导致线程挂起【挂起：挂起进程在操作系统中可以定义为暂时被淘汰出内存的进程，机器的资源是有限的，在资源不足的情况下，操作系统对在内存中的程序进行合理的安排，其中有的进程被暂时调离出内存，当条件允许的时候，会被操作系统再次调回内存，重新进入等待被执行的状态即就绪态，系统在超过一定的时间没有任何动作】。很明显这个操作包括两次额外的上下文切换。

		优化性能：
			1，减少锁的竞争
			2，减少锁的粒度：
				使用锁的时候，锁所保护的对象是多个，当这些多个对象其实是独立变化的时候，不如用多个锁来一一保护这些对象。但是如果有同时要持有多个锁的业务方法，要注意避免发生死锁
				缩小锁的范围
				对锁的持有实现快进快出，尽量缩短持由锁的的时间。将一些与锁无关的代码移出锁的范围，特别是一些耗时，可能阻塞的操作
			3，避免多余的缩减锁的范围：
				两次加锁之间的语句非常简单，导致加锁的时间比执行这些语句还长，这个时候应该进行锁粗化—扩大锁的范围。
			4，锁分段：
				ConcurrrentHashMap就是典型的锁分段。
			5，替换独占锁：
				在业务允许的情况下：
					1、	使用读写锁，
					2、	用自旋CAS
					3、	使用系统的并发容器




JMM：
	Java内存模型（JMM）：
		即Java Memory Model，简称JMM。JMM定义了Java 虚拟机(JVM)在计算机内存(RAM)中的工作方式。JVM是整个计算机虚拟模型，所以JMM是隶属于JVM的。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。

	JVM对Java内存模型的实现：
		所有原始类型(boolean,byte,short,char,int,long,float,double)的局部变量都直接保存在线程栈当中，对于它们的值各个线程之间都是独立的。对于原始类型的局部变量，一个线程可以传递一个副本给另一个线程，当它们之间是无法共享的。
		堆区包含了Java应用创建的所有对象信息，不管对象是哪个线程创建的，其中的对象包括原始类型的封装类（如Byte、Integer、Long等等）。不管对象是属于一个成员变量还是方法中的局部变量，它都会被存储在堆区。
		一个局部变量如果是原始类型，那么它会被完全存储到栈区。 一个局部变量也有可能是一个对象的引用，这种情况下，这个本地引用会被存储到栈中，但是对象本身仍然存储在堆区。
		对于一个对象的成员方法，这些方法中包含局部变量，仍需要存储在栈区，即使它们所属的对象在堆区。 对于一个对象的成员变量，不管它是原始类型还是包装类型，都会被存储到堆区。Static类型的变量以及类本身相关信息都会随着类本身存储在堆区。

	Java内存模型带来的问题:
		1,可见性问题
		2,重排序:
		除了共享内存和工作内存带来的问题，还存在重排序的问题：在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序

	Java内存模型中的重排序:
		重排序类型:
			1）编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
			2）指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
			3）内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。
		
		重排序与依赖性:
			1,数据依赖性:
				如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。
			2，控制依赖性：
				public void use(){
					if(flag){
						int i = a*a;
					}
				}
				flag变量是个标记，用来标识变量a是否已被写入，在use方法中比变量i依赖if（flag）的判断，这里就叫控制依赖，如果发生了重排序，结果就不对了。

		解决重排序问题：
			as-if-serial（单线程下的）:
				不管如何重排序，都必须保证代码在单线程下的运行正确，连单线程下都无法正确，更不用讨论多线程并发的情况，所以就提出了一个as-if-serial的概念。 
				as-if-serial语义的意思是：
					不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。（强调一下，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。）但是，如果操作之间不存在数据依赖关系，这些操作依然可能被编译器和处理器重排序。


	并发下重排序会带来线程安全问题。
	解决在并发下的问题：
		1，内存屏障 
			Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序，从而让程序按我们预想的流程去执行。
				1、保证特定操作的执行顺序。
				2、影响某些数据（或则是某条指令的执行结果）的内存可见性。
			编译器和CPU能够重排序指令，保证最终相同的结果，尝试优化性能。插入一条MemoryBarrier会告诉编译器和CPU：不管什么指令都不能和这条Memory Barrier指令重排序。
			MemoryBarrier所做的另外一件事是强制刷出各种CPUcache，如一个Write-Barrier（写入屏障）将刷出所有在Barrier之前写入 cache 的数据，因此，任何CPU上的线程都能读取到这些数据的最新版本。
			JMM把内存屏障指令分为4类，解释表格，StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。

		2，临界区
			临界区内的代码可以重排序（但JMM不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理，虽然线程A在临界区内做了重排序，但由于监视器互斥执行的特性，这里的线程B根本无法“观察”到线程A在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。
		
		3，Happens-Before（多线程下的）
			定义：
				在Java 规范提案中为让大家理解内存可见性的这个概念，提出了happens-before的概念来阐述操作之间的内存可见性。对应Java程序员来说，理解happens-before是理解JMM的关键。JMM这么做的原因是：程序员对于这两个操作是否真的被重排序并不关心，程序员关心的是程序执行时的语义不能被改变（即执行结果不能被改变）。因此，happens-before关系本质上和as-if-serial语义是一回事。•as-if-serial语义保证单线程内程序的执行结果不被改变。
				happens-before关系保证正确同步的多线程程序的执行结果不被改变。
				
				the first is visible to and ordered before the second
				其实就是，对于程序员而言，以为指令的执行顺序是从上往下的，但是对于CPU而言，为了提高效率，会进行重排序，后一个指令执行顺序在前一个指令之前，但是前一个执行的结果又对后一个指令是可见的，所以结果是不会产生错误的。

			应用：
				1）序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
				2）监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
				3）volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
				4）传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。
				5）start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。
				6）join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 
				7 ）线程中断规则:对线程interrupt方法的调用happens-before于被中断线程的代码检测到中断事件的发生。




---------------------------------------------------------------------------------------------------------------------------------------------------------------



三,spring详解？

1,SpringContext利用无参的构造函数创建一个对象，然后利用setter方法赋值。所以如果无参构造函数不存在，
	Spring上下文创建对象的时候便会报错。
	将bean放入IOC容器的方式：
		1，<bean id="" class="" />
		2，在@Configuration中利用@Bean创建bean
		3，加上@Compent注解标识为一个组件，然后利用@CompentScan扫描组件
		4，@import(value ={Cemb.class，CembSelector.class，CembImportBeanDefinitionRegistrar.class})
				参数有三种方式：
				1，Cemb.class：直接注册Cemb这个bean

				2，CembSelector.class：CembSelector这个对象是实现了Importselector，可以指定一些注册bean的逻辑，在重写方法的时候需要注意不要返回null，否则会报空指针。

				3，CembImportBeanDefinitionRegistrar.class：CembImportBeanDefinitionRegistrar这个类实现了ImportBeanDefinitionRegistrar，重写registerBeanDefinitions方法，可以指定一些注册bean的逻辑，但是必须要将bean封装成RootBeanDefinition对象然后registry.registerBeanDefinition("cemb", beanDefinition);这样注册。

		5，使用FactoryBean进行注册。需要注册的bean需要实现FactoryBean，然后重写其三个方法。

	注意：
		当@Bean和扫描方式对同一个单例bean创建的时候，不会报错，优先级是扫描>@Bean

	

2,bean的创建默认是单例。
	多例：在调用bean的时候才会被创建
	单例：在创建IOC容器的时候就会创建bean,创建bean是先从spring的缓存中去判断是否存在此bean，如果不存在再去创建和初始化。


3，bean的生命周期
	bean的生命周期：创建(通过反射创建)，初始化(初始化之前会先属性赋值，并且初始化的前后可能会进行后置增强)，销毁
		创建：根据无参构造器，通过反射创建，创建后的bean会包装成BeanWrapper这种类型。
		初始化：
			1，自定义初始化方法，然后通过initMethod配置
			2，@PostConstruct实现（JSR250规范，并不是spring的注解，是jdk的），属性赋值完成之后执行
			3，实现InitializingBean接口的afterPropertiesSet方法来完成，dubbo中的中转对象的初始化这里就有使用到。
				注意：底层在初始化的过程中，在调用初始化方法执行的前后，会通过后置处理器来调用一些自定义的方法来对初始化过程进行增强，AOP就是这个原理。

		销毁：
			1，自定义销毁方法，然后通过destoryMethod配置
			2，@PreDestroy实现（JSR250规范，并不是spring的注解，是jdk的）可以在bean被销毁之前执行
			4，实现的InitializingBean接口的destroy方法。
				注意：销毁，其实就是调用IOC容器beanFactory实例然后将缓存map和IOC容器这个map都clear清空。


4,spring5的新特性.
	加入了lamde表达式。
	对于耗时的操作用lambda表达式的for循环，如数据库的IO操作，多线程充分利用CPU资源；对于不太耗时的操作使用普通for循环，比如纯CPU计算类型的操作，单线程性能更高，减少上下文切换的开销。



5,Spring的两种IOC容器。
	1，BeanFactory
	2，ApplicationContext（是BeanFactory的扩展）
	实现CommandLineRunner或ApplicationRunner可以在程序启动的时候执行某些方法，按一定顺序执行的话，可以在实现类上加上@Order注解。@Order(value=整数值)。


6，Spring的几种注入bean的方式。
	1，Autowired（可以搭配@Qualifier和@Primary（@Primary指定bean注入的优先级）使用，按照名称注入），根据类型注入
	2，Resource（JSR-250），根据名称注入
	3，Inject（JSR-330的标准），根据类型注入。当不是spring框架的时候注入可以使用这种
	@Autowired和@Resource的区别：
		1，@Autowired是根据对象类型来自动装配的，是属于spring的注解，默认对象必须存在，如果对象不存在，则需要设置它的required属性为false   
		2，@Autowired(required=false)也可以使用根据名称来装配，需要加上@Qualifier注解，并指定属性名。
		3，@Resource是根据对象名称来装配的，是属于jdk1.6的注解。
		直白的说，就是@Autowired自动注解一个接口，俩个实现类，Autowired就不知道注入哪一个实现类，而@Resource有name属性，可以区分。

	注意（注入原理可以根据）：
		1，构造器注入
		2，属性注入
		3，setter注入


7，BeanPostProcessor
	是一个后置处理器，作用是在bean创建之后的初始化过程执行之前和之后，进行前置处理和后置处理进行对bean的初始化的增强。所有的bean在初始化的前后都会去执行一次前置和后置的处理，在具体的处理里面，会去循环遍历拿到bean对应的后置处理器，然后根据对应的后置处理器去执行一些增强方法，比如bean实现了ApplicationContextAware接口的话，后置处理器会去判断是否实现了这个接口，实现了就将ApplicationContext这个IOC容器作为属性设置进这个bean中，相当于让这个bean拥有了可以调用IOC容器的功能，其他的功能类似
	，所以后置处理器是spring的核心。
	例如：
		@Autowired是通过AutowiredAnnotationBeanPostProcessor这个后置处理器来实现的。

	实现方式：
		实现BeanPostProcessor接口，重写postProcessBeforeInitialization和postProcessAfterInitialization即可。


8，aop
	aop通过动态代理实现的，其中@Around的执行顺序是要高于@Before，@After等。
	动态代理的实现方式有两种：
		1，Cglib
		2，jdk的动态代理（spring默认使用）
		可以通过proxy-target-class属性来指定，false表示使用jdk方式。

	自动创建代理类方式：
		1，AnnotationAwareAspectJAutoProxyCreator，根据Bean中的AspectJ注解自动创建代理，所使用的后置处理器是SmartInstantiationAwareBeanPostProcessor。
			注意：
			1，AnnotationAwareAspectJAutoProxyCreator这个bean的创建是通过AspectJAutoProxyRegistrar实现ImportBeanDefinitionRegistrar，将AnnotationAwareAspectJAutoProxyCreator通过id为internalAutoProxyCreator，key为这个类封装为RootBeanDefinition，在spring中定义，之后再创建和初始化。
			2，然后目标类是先等AnnotationAwareAspectJAutoProxyCreator创建完成之后，再创建，创建的时候会通过动态代理创建一个代理对象，其中代理对象中有对应的后置处理器，在前置处理的时候会去获取对应的通知方法的定义，后置处理才会去创建这个对象，并且创建通知方法，根据通知方法做增强处理。
			3，其中通知方法会转成一个拦截对象MethodInterceptor放入一个拦截链中（List中），放入顺序和执行顺序是相反的，然后根据动态代理的方式执行，其中每个通知方法都有对应的处理方法（invoke）去处理，处理方法都不一样。这里的执行算法是通过递归的压栈和弹栈来实现的，保证了最终弹栈的顺序是按照正确的通知方法的执行顺序来执行的。
			4，切面方法之所以能按照顺序执行，是因为AnnotationAwareAspectJAutoProxyCreator也实现了Ordered接口，指定了执行顺序


		2，BeanNameAutoProxyCreator，匹配Bean的名称自动创建匹配到的Bean的代理
		3，根据Advisor的匹配机制自动创建代理，会对容器中所有的Advisor进行扫描，自动将这些切面应用到匹配的Bean中，实现类DefaultAdvisorAutoProxyCreator


	


8,Spring事务在controller层不起作用的原因？
	因为spring和springmvc的IOC是一个父子容器，先加载spring容器，所以要在controller层添加事务，需要：
	1，只能使用注解事务方式。
	2，在spring中加载除了controller之外的所有的bean，在springmvc中只加载controller注解的bean，只扫描controller包。
	同时开启事务：
		1，开启事务管理器，@EnableTransactionManagement
		2，注册事务管理器的bean，并且绑定数据源

	核心类InfrastructureAdvisorAutoProxyCreator，执行流程：
  		1，注册  2，利用后置处理器机制在创建以后，包装对象，返回一个代理对象（增强），代理对象执行方法时，利用拦截器键进行调用 
  		当执行目标方法时：
	      执行拦截器链：
		      执行其中的事务拦截器：
			      1.先获取事务相关属性
			      2.获取PlatformTransactionManager事务管理器，直接到容器中获取platformTransactionManager bean实例
			      	执行目标方法：
					   	如果异常：completeTransactionAfterThrowing，利用事务管理回滚操作
					    如果正常：利用 事务管理器，提交事务。
  
   AnnotationTransactionAttributeSource：封装了事务增强器要用事务注解的信息，使用这个类解析事务注解
   TransactionInterceptor：保存了事务属性信息，事务管理器，实现了MethodInterceptor。
   注意：当异常捕获了，事务不会生效。




9,BeanFactory和FactoryBean区别？
	BeanFactory：BeanFactory接口的类表明此类事一个工厂,是一个IOC容器，作用就是配置、新建、管理各种容器中的Bean。
	FactoryBean：实现FactoryBean的类表明此类也是一个Bean，类型为工厂Bean（Spring中共有两种bean，一种为普通bean，另一种则为工厂bean）。作用是用来向容器中注册和初始化bean的。
		注意：实现了FactoryBean的类例如叫CembFactoryBean，其中getObject方法是注册bean，在bean在容器中注册之后，通过id为cembFactoryBean去拿是直接拿到的getObject注册的bean，而不能拿到其本身，如果想要拿到其本身必要在id前加一个&符号。



10，BeanFactoryPostProcessor和BeanPostProcessor的区别？ 
	BeanPostProcessor：Bean的后置处理器（处理的对象是Bean）；可以在spring容器实例化bean之后，在执行bean的初始化方法前后，添加一些自己的处理逻辑。
	BeanFactoryPostProcessor：BeanFactory的后置处理器（处理的对象是BeanFactory），是在spring容器加载了bean的定义文件之后，在bean实例化之前执行的，可以从BeanFactory中获取到bean创建之前的定义信息。
	BeanDefinitionRegistryPostProcessor：实现这个接口，可以在BeanFactoryPostProcessor之前执行，bean初始化之前做一些bean定义的处理。

	BeanDefinitionRegistryPostProcessor继承BeanFactoryPostProcessor，底层是先执行BeanDefinitionRegistryPostProcessor的postProcessBeanDefinitionRegistry方法之后，再执行实现BeanFactoryPostProcessor的postProcessBeanFactory方法。



11，spring的aware接口系列？
每个aware接口都有set方法，实现对应的aware可以获取相应的在spring中的属性。这些属性的设置是在bean初始化的前后，通过后置处理器去完成的。


12，spring的设计模式？
单例，工厂，代理，适配器，策略，观察者，装饰，模板，FactoyBean--工厂模式等


13，拦截器和过滤器的区别？
过滤器和拦截器的区别：
　　①拦截器是基于java的反射机制的，而过滤器是基于函数回调。
　　②拦截器不依赖与servlet容器，是spring的组件，过滤器依赖与servlet容器，不是spring的组件。
　　③拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。但过滤器只能在servlet前后起作用，拦截器可以
		深入到方法前后，异常前后。
　　④拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。
　　⑤在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。
　　⑥拦截器可以获取IOC容器中的各个bean，而过滤器就不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。


14,IOC源码主要流程。
synchronized (this.startupShutdownMonitor) {
			// 刷新前的预处理，比如初始化一些属性设置，校验属性的合法性等。
			prepareRefresh();

			// 获取BeanFactory（Bean工厂，IOC容器，内部创建是在构造函数中new出来的）
			ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();

			// 对BeanFactory进行一些预处理，比如设置一些属性值等
			prepareBeanFactory(beanFactory);

			try {
				// 对BeanFactory设置一些后置处理，由子类去实现，可以自定义一些后置处理
				postProcessBeanFactory(beanFactory);

				// 执行BeanFactoryPostProcessors后置处理，对BeanFactory的创建之后进行一些后置处理
				invokeBeanFactoryPostProcessors(beanFactory);

				// 注册BeanPostProcessor（Bean的后置处理器），同时对AOP中的bean的增强处理和bean的创建初始化也是在这里进行的
				registerBeanPostProcessors(beanFactory);

				// 初始化MessageSource组件（做国际化功能；消息绑定，消息解析）
				initMessageSource();

				// 初始化事件派发器
				initApplicationEventMulticaster();

				// 子类重写这个方法，在容器刷新的时候可以自定义逻辑；
				onRefresh();

				// 检查容器中将所有项目里面的ApplicationListener监听器，并注册进来
				registerListeners();

				// 创建，并初始化单例模式的bean，然后并且会在bean初始化方法执行前后进行后置处理
				finishBeanFactoryInitialization(beanFactory);

				// 完成BeanFactory的初始化创建工作；IOC容器就创建完成，并且刷新容器
				finishRefresh();
			}
}

15，Spring 可以是懒加载的，主要针对单实例bean，就是当真正使用到 Bean 的时候才实例化 Bean。使用@Lazy实现


16，bean相互依赖注入问题？
Spring的单例对象的初始化主要分为三步： 
（1）createBeanInstance：实例化，其实也就是调用对象的构造方法实例化对象
（2）populateBean：填充属性，这一步主要是多bean的依赖属性进行填充
（3）initializeBean：调用spring xml中的init 方法。
从上面讲述的单例bean初始化步骤我们可以知道，循环依赖主要发生在第一、第二部。也就是构造器循环依赖和field循环依赖。
那么我们要解决循环引用也应该从初始化过程着手，对于单例来说，在Spring容器整个生命周期内，有且只有一个对象，所以很容易想到这个对象应该存在Cache中，Spring为了解决单例的循环依赖问题，使用了三级缓存。e
这三级缓存分别指： 
singletonFactories ： 单例对象工厂的cache 
earlySingletonObjects ：提前暴光的单例对象的Cache 
singletonObjects：单例对象的cache

Spring首先从一级缓存singletonObjects中获取。如果获取不到，并且对象正在创建中，就再从二级缓存earlySingletonObjects中获取。如果还是获取不到且允许singletonFactories通过getObject()获取，就从三级缓存singletonFactory.getObject()(三级缓存)获取，如果获取到了则：从singletonFactories中移除，并放入earlySingletonObjects中。其实也就是从三级缓存移动到了二级缓存。
从上面三级缓存的分析，我们可以知道，Spring解决循环依赖的诀窍就在于singletonFactories这个三级cache。这个cache的类型是ObjectFactory。
protected void addSingletonFactory(String beanName, ObjectFactory<?> singletonFactory) {
    Assert.notNull(singletonFactory, "Singleton factory must not be null");
    synchronized (this.singletonObjects) {
        if (!this.singletonObjects.containsKey(beanName)) {
            this.singletonFactories.put(beanName, singletonFactory);
            this.earlySingletonObjects.remove(beanName);
            this.registeredSingletons.add(beanName);
        }
    }
}
这里就是解决循环依赖的关键，这段代码发生在createBeanInstance之后，也就是说单例对象此时已经被创建出来(调用了构造器)。这个对象已经被生产出来了，虽然还不完美（还没有进行初始化的第二步和第三步），但是已经能被人认出来了（根据对象引用能定位到堆中的对象），所以Spring此时将这个对象提前曝光出来让大家认识，让大家使用。
这样做有什么好处呢？让我们来分析一下“A的某个field或者setter依赖了B的实例对象，同时B的某个field或者setter依赖了A的实例对象”这种循环依赖的情况。A首先完成了初始化的第一步，并且将自己提前曝光到singletonFactories中，此时进行初始化的第二步，发现自己依赖对象B，此时就尝试去get(B)，发现B还没有被create，所以走create流程，B在初始化第一步的时候发现自己依赖了对象A，于是尝试get(A)，尝试一级缓存singletonObjects(肯定没有，因为A还没初始化完全)，尝试二级缓存earlySingletonObjects（也没有），尝试三级缓存singletonFactories，由于A通过ObjectFactory将自己提前曝光了，所以B能够通过ObjectFactory.getObject拿到A对象（虽然A还没有初始化完全，但是总比没有好呀)，B拿到A对象后顺利完成了初始化阶段1、2、3，完全初始化之后将自己放入到一级缓存singletonObjects中。此时返回A中，A此时能拿到B的对象顺利完成自己的初始化阶段2、3，最终A也完成了初始化，进去了一级缓存singletonObjects中，而且更加幸运的是，由于B拿到了A的对象引用，所以B现在hold住的A对象完成了初始化。

知道了这个原理时候，肯定就知道为啥Spring不能解决“A的构造方法中依赖了B的实例对象，同时B的构造方法中依赖了A的实例对象”这类问题了！因为加入singletonFactories三级缓存的前提是执行了构造器，所以构造器的循环依赖没法解决。


17，为什么要使用spring？
spring是一个开源框架，spring可以有效的控制J2EE各个应用层之间的对象，不管是控制层的Action对象，还是业务层的Service对象，还是持久层的DAO对象， 
都可在Spring的管理下有机地协调、运行。Spring将各层的对象以松耦合的方式组织在一起，Action对象无须关心Service对象的具体实现。
Service对象无须关心持久层对象的具体实现，各层对象的调用完全面向接口。当系统需要重构时，代码的改写量将大大减少。

因为平时我们的开发很复杂，每个对象之间的互相调用关系错综复杂，对象多了之后管理起来就会非常麻烦，spring就为我们解决了这方面的问题。
spring的IOC即是控制反转，为我们管理了所有的bean，本来以前A对象想要调用B对象的时候，我们需要new一个B对象的实例，由我们自己去控制依赖关系，
现在变成了由spring的IOC容器控制，帮助我们创建B实例，并且实现依赖关系，这种设计思想就是控制反转，同时依赖反转又称为DI（依赖注入），自动的
帮助我们把被依赖的bean注入到依赖的bean里面去。这样的好处就是减少了耦合性，使得bean的管理更加方便快捷高效。
同时，IOC是采用反射机制实现的，反射对于工厂模式的区别就是，反射对于对象的编译是动态的，能够更加灵活，缺点是效率低。工厂模式缺点就是不灵活，当
工厂对象需要发生变动的时候，或者需要增加工厂对象的时候，就需要修改工厂方法，或者增加工厂的实现类，这样就不利于解耦。
同时IOC的低侵入性也很好，不需要像Struts2，EJB这样的框架一样，使用需要继承或者实现，IOC的bean都不需要继承或者实现，侵入性很低，可移植性很高。




18，springmvc？
	1，父子容器，继承IOC的容器作为子容器，用来加载controller，modelandview等bean，service，dao等bean用IOC加载。springmvc的IOC可以访问spring的IOC，但是spring的IOC不可以访问springmvc的IOC。

	2，安全机制？
	在容器启动完成之后，不允许再往容器中创建和初始化bean。

	3，WEB-INF下的文件受保护机制。
	通常把那些限制访问的资源（比如说jsp源代码）放到Web应用的WEB-INF目录下，对于/web-INF/及其子目录，不允许直接的公共访问，
	所以就可以起到保护这些代码未经授权的访问和窥视，更好的保护了源代码。为了减少风险，可以把这些页面文件移到WEB-INF 
	目录下。基于Servlet的声明，WEB-INF不作为Web应用的公共文档树的一部分。因此，WEB-INF 
	目录下的资源不是为客户直接服务的。我们仍然可以使用WEB-INF目录下的JSP页面来提供视图给客户，客户却不能直接请求访问JSP。

	4，同步和异步请求。
	tomcat9以下的通信机制中是bio，之上是nio，netty中是nio。
	异步处理：请求之后，主线程会马上将连接释放（tomcat中的线程连接数就不会那么有压力），将真正执行的业务部分放入到异步线程中去执行，
	当异步执行完成之后再返回响应。采用异步，是两个线程（主从），会触发两次拦截器或者过滤器。
	异步相对同步的优点：
	很多个线程同时请求，同步会是这些线程依次排队等待上一个线程处理完，这样最后一个线程是花最多时间拿到结果的    
	如果是异步的话，这很多个线程都是和第一个线程一样的相同时间拿到结果



19,springmvc的工作原理？
	springmvc最新版本是基于servlet3.0开发的。
	入口是springmvc-web这个包下的META-INF/services目录下的javax.servlet.ServletContainerInitializer中配置的是
	SpringServletContainerInitializer这个类，这个类实现ServletContainerInitializer接口，加载WebApplicationInitializer这个类的所有子类实现，并初始化DispatcherServlet和springmvc的IOC容器（Servlet容器，spring的是Root容器），即是WebApplicationContext（WebApplicationContext继承了ApplicationContext）。

	流程：
		1，springmvc的核心控件是DispatchServlet，DispatchServlet是一个中央控制器，用户从客户端向服务器发送http请求，请求首先发送到DispatchServlet，再由DispatchServlet将请求分发给HandlerMapping（处理器映射器）。
		2，HandlerMapping（处理器映射器）根据请求url寻找到对应的处理器（controller），并且寻找是否存在在处理器执行之前的处理器拦截器（HandlerInterceptor），返回给DispatchServlet。
		3，HandelAdapter（处理器适配器）再根据请求，在处理器映射器返回的处理器中寻找具体的执行方法，去执行具体的处理器。
		4，执行具体的方法中之后会返回一个ModelAndView对象给DispatchServlet。
		5，DispatchServlet收到ModelAndView这个对象，但是这是一个逻辑试图，需要用试图解析器进行解析。
		6，ViewResolver（试图解析器）将ModelAndView进行解析，将解析后的结果返回给DispatchServlet。
		7，DispatchServlet将解析之后的视图再返回给客户端。



20，springmvc和Struts2的区别？
	区别1：
	Struts2的核心是基于一个Filter即StrutsPreparedAndExcuteFilter 
	SpringMvc的核心是基于一个Servlet即DispatcherServlet(前端控制器)

	区别2：
	Struts2是基于类开发的，传递的参数是通过类的属性传递(属性驱动和模型驱动),所以只能设计成多例prototype
	SpringMvc是基于类中的方法开发的，也就是一个url对应一个方法，传递参数是传到方法的形参上面，所以既可以是单例模式也可以是多例模式singiton，controller是单例的。

	区别3：
	Struts2采用的是值栈存储请求以及响应数据，OGNL存取数据
	SpringMvc采用request来解析请求内容，然后由其内部的getParameter给方法中形参赋值，再把后台处理过的数据通过ModelAndView对象存储，Model存储数据，
	View存储返回的页面，再把对象通过request传输到页面去。



21, springboot  用的哪种线程池?

22，servlet？
1.forward跳转：
a.服务器端跳转，地址栏不改变；
b.执行到跳转语句后马上无条件跳转，之后的代码不再执行(跳转之前一定要释放全部资源)；
c.request设置的属性在跳转后的页面仍可以使用；
d.使用<jsp:param name="参数名" value="参数值" />传递参数。

2.response跳转：
a.客户端跳转,地址栏改变；
b.所有代码执行完毕后跳转；
c.跳转后的页面不能使用上一个页面的request属性；
d.使用地址重写传递参数（response.sendRedirect("URL?参数名＝参数值")）。


23，如何使用 SpringMVC 完成 JSON 操作：
①. 配置 MappingJacksonHttpMessageConverter
②. 使用 @RequestBody 注解或 ResponseEntity 作为返回值


24，springboot中实现redis：
1，加入spring-boot-start-data-redis依赖。
2，在配置文件中配置redis服务器的IP和端口，账号，密码
3，创建redis配置类组件，用@Bean加入RedisTemplate模板对象和各种数据结构的工具对象。
4，创建redis工具类，注入RedisTemplate模板对象，写出操作redis工具方法。
5，设置redis切面类，设置执行面。


25，七大模块，如下： 
  1. Spring Core： Core封装包是框架的最基础部分，提供IOC和依赖注入特性。这里的基础概念是BeanFactory，它提供对Factory模式的经典实现来消除对程序性单例模式的需要，并真正地允许你从程序逻辑中分离出依赖关系和配置。 
  2.Spring Context: 构建于Core封装包基础上的 Context封装包，提供了一种框架式的对象访问方法，有些象JNDI注册器。Context封装包的特性得自于Beans封装包，并添加了对国际化（I18N）的支持（例如资源绑定），事件传播，资源装载的方式和Context的透明创建，比如说通过Servlet容器。 
  3．Spring DAO:  DAO (Data Access Object)提供了JDBC的抽象层，它可消除冗长的JDBC编码和解析数据库厂商特有的错误代码。 并且，JDBC封装包还提供了一种比编程性更好的声明性事务管理方法，不仅仅是实现了特定接口，而且对所有的POJOs（plain old Java objects）都适用。 
  4.Spring ORM: ORM 封装包提供了常用的“对象/关系”映射APIs的集成层。 其中包括JPA、JDO、Hibernate 和 iBatis 。利用ORM封装包，可以混合使用所有Spring提供的特性进行“对象/关系”映射，如前边提到的简单声明性事务管理。 
  5.Spring AOP: Spring的 AOP 封装包提供了符合AOP Alliance规范的面向方面的编程实现，让你可以定义，例如方法拦截器（method-interceptors）和切点（pointcuts），从逻辑上讲，从而减弱代码的功能耦合，清晰的被分离开。而且，利用source-level的元数据功能，还可以将各种行为信息合并到你的代码中。 
  6.Spring Web:
  Spring中的 Web 包提供了基础的针对Web开发的集成特性，例如多方文件上传，利用Servlet listeners进行IOC容器初始化和针对Web的ApplicationContext。当与WebWork或Struts一起使用Spring时，这个包使Spring可与其他框架结合。 
  7.Spring Web MVC: Spring中的MVC封装包提供了Web应用的Model-View-Controller（MVC）实现。Spring的MVC框架并不是仅仅提供一种传统的实现，它提供了一种清晰的分离模型，在领域模型代码和Web Form之间。并且，还可以借助Spring框架的其他特性。 


26，BeanFactory和ApplicationContext的异同点： 
  相同点：两者都是通过xml配置文件加载bean,ApplicationContext和BeanFacotry相比,提供了更多的扩展功能。 
  不同点：BeanFactory是延迟加载,如果Bean的某一个属性没有注入，BeanFacotry加载后，直至第一次使用调用getBean方法才会抛出异常；而ApplicationContext则在初始化自身是检验，这样有利于检查所依赖属性是否注入；所以通常情况下我们选择使用ApplicationContext 。




---------------------------------------------------------------------------------------------------------------------------------------------------------------

三，网络编程？

1，IO流：
	IO流用来处理设备之间的数据传输。
	java对数据的操作是通过流的方式。
	java用于操作流的对象都在IO包中。
	流按照操作数据分为两种：字节流和字符流。
	流按流向分为：输入流，输出流。
	输入流和输出流是相对于内存设备而言。
	将外设中的数据读取到内存中是输入，将内存的数据写入到外设中，是输出。
	字符流的由来：
	其实就是，字节流读取文字字节数据后，不直接操作而是先查指定的编码表，获取对应的文字，再对这个文字进行
	操作，简单的说：字节流+编码表。

	字节流的抽象基类：
	InputStream(输入)  OutputStream
	字符流的抽象基类：
	Reader(输入)   Writer
	这些体系的子类名都以父类名作为后缀，而子类名的前缀就是该对象的功能。
	注：由这四个类派生出来的子类名称都是以其父类名称作为子类名的后缀。
	如：InputStream的子类FileInputStream......

	字符流的缓冲区：
	缓冲区的出现提高了对数据的读写效率。
	对应类：
	BufferedWriter：中有个方法newline()可以换行。     
	BufferedReader：中有个方法readline()可以读取文字...(换行符)
	缓冲区要结合流才可以使用。
	在流的基础上对流的功能进行了增强，其实就是用到了装饰设计模式。

	序列化：就是将对象转成字节数据存储在内存中。


2，网络编程？
	网络编程就是基于信息传输协议编写一些通信的程序。
	网络模型：
	OSI（Open System Interconnection）开放系统互连。
	：
	应用层（Http，Https，ftp....）
	表示层
	会话层
	传输层（tcp，udp...）
	网络层
	数据链路层
	物理层

	TCP/IP
	：
	应用层
	传输层
	网际层
	主机至网络层


	网络通讯要素：
	IP地址
	端口号
	传输协议

	传输协议常见协议：TCP,UDP
	进程/应用的协议：Telnet，FTP，HTTP，DNS等。
	主机-主机的协议：TCP,UDP。
	Internet协议：IP，ICMP，ARP等。


	TCP和UDP区别：
	TCP：
	1，建立连接，形成传输数据的通道。
	2，在连接中进行大数据量传输。
	3，通过三次握手完成连接，是可靠协议。
	4，必须建立连接，效率会稍低。
	UDP：
	1，将数据及源和目的封装成数据包中，不需要建立连接。
	2，每个数据包的大小都限制在64K内。
	3，因为没有连接，是不可靠协议。
	4，不需要建立连接，速度快。
	----UDP传输：
	DatagramSocket与DatagramPacket
	建立发送端，接收端。
	建立数据包。
	调用Socket的发送接收方法。
	关闭Socket。
	发送端和接收端是两个独立的运行程序。

	Socket：
	1，Socket就是为网络服务提供的一种机制。
	2，通信的两端都有Socket。
	3，网络通信其实就是Socket间的通信。
	4，数据在两个Socket间通过IO传输。


TCP/IP系列协议：
TCP/IP（Transmission Control Protocol/Internet Protocol）不只是TCP/IP两个协议，而是有很多个协议组成，并且是在不同的层，是互联网的基础通信架构。
一个http请求浏览：应用层HTTP -> 传输层TCP -> 网络层IP（数据包）、 ICMP(确保源地址和目的地址之间是网络通)、IGMP(本地路由器和英特网的路由器联通) ->链路层
直接使用网络层协议的应用：ping命令，ICMP协议。



TCP的通讯原理：
“阻塞模式”：如果接收端，当然接收端缓冲区为空的时候，调用Socket的read方法的线程会阻塞，阻塞到有数据进入接收缓冲区；另外对于写数据到Socket中的线程来说，如果待发送的数据长度大于发送缓冲区空余长度，则会阻塞在write方法上，等待发送缓冲区的报文被发送到网络上，所以呢这个就是TCP的阻塞。
滑动窗口协议：
发送方和接收方都会维护一个数据帧的序列，这个序列被称作窗口。发送方的窗口大小由接收方确认，目的是控制发送速度，以免接收方的缓存不够大导致溢出，同时控制流量也可以避免网络拥塞




1，三次握手（重点）？
TCP 提供面向有连接的通信传输。面向有连接是指在数据通信开始之前先做好两端之间的准备工作。
所谓三次握手是指建立一个 TCP 连接时需要客户端和服务器端总共发送三个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发。
第一次握手：客户端将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给服务器端，客户端进入SYN_SENT状态，等待服务器端确认。
第二次握手：服务器端收到数据包后由标志位SYN=1知道客户端请求建立连接，服务器端将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给客户端以确认连接请求，服务器端进入SYN_RCVD状态。
第三次握手：客户端收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给服务器端，服务器端检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，客户端和服务器端进入ESTABLISHED状态，完成三次握手，随后客户端与服务器端之间可以开始传输数据了。



2，四次挥手？
四次挥手即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发。
由于TCP连接是全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。
1.	客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
2.	服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。
3.	客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
4.	服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
5.	客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。
6.	服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。


3,同步，异步，阻塞，非阻塞？
同步：
所谓同步，就是在发出一个功能调用时，在没有得到结果之前，该调用就不返回。也就是必须一件一件事做,等前一件做完了才能做下一件事。
例如普通B/S模式（同步）：提交请求->等待服务器处理->处理完毕返回 这个期间客户端浏览器不能干任何事

异步：
异步的概念和同步相对。当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。
例如 ajax请求（异步）: 请求通过事件触发->服务器处理（这是浏览器仍然可以作其他事情）->处理完毕

阻塞：
阻塞调用是指调用结果返回之前，当前线程会被挂起（线程进入非可执行状态，在这个状态下，cpu不会给线程分配时间片，即线程暂停运行）。函数只有在得到结果之后才会返回。
有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回,它还会抢占cpu去执行其他逻辑，也会主动检测io是否准备好。

非阻塞：
非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。
再简单点理解就是：
1. 同步，就是我调用一个功能，该功能没有结束前，我死等结果。
2. 异步，就是我调用一个功能，不需要知道该功能结果，该功能有结果后通知我（回调通知）
3. 阻塞，就是调用我（函数），我（函数）没有接收完数据或者没有得到结果之前，我不会返回。
4. 非阻塞，就是调用我（函数），我（函数）立即返回，通过select通知调用者



4，Linux的五种IO模型？
1)阻塞I/O（blocking I/O）
 应用程序调用一个IO函数，导致应用程序阻塞，等待数据准备好。 如果数据没有准备好，一直等待….数据准备好了，从内核拷贝到用户空间,IO函数返回成功指示。
 当调用recv()函数时，系统首先查是否有准备好的数据。如果数据没有准备好，那么系统就处于等待状态。当数据准备好后，将数据从系统缓冲区复制到用户空间，然后该函数返回。在套接应用程序中，当调用recv()函数时，未必用户空间就已经存在数据，那么此时recv()函数就会处于等待状态。

2)非阻塞I/O （nonblocking I/O）
 我们把一个SOCKET接口设置为非阻塞就是告诉内核，当所请求的I/O操作无法完成时，不要将进程睡眠，而是返回一个错误。这样我们的I/O操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用CPU的时间。上述模型绝不被推荐。
    把SOCKET设置为非阻塞模式，即通知系统内核：在调用Windows Sockets API时，不要让线程睡眠，而应该让函数立即返回。在返回时，该函数返回一个错误代码。图所示，一个非阻塞模式套接字多次调用recv()函数的过程。前三次调用recv()函数时，内核数据还没有准备好。因此，该函数立即返回WSAEWOULDBLOCK错误代码。第四次调用recv()函数时，数据已经准备好，被复制到应用程序的缓冲区中，recv()函数返回成功指示，应用程序开始处理数据。

3)I/O复用(select 和poll) （I/O multiplexing）
  简介：主要是select和epoll；对一个IO端口，两次调用，两次返回，比阻塞IO并没有什么优越性；关键是能实现同时对多个IO端口进行监听；
      I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。
	当用户进程调用了select，那么整个进程会被block；而同时，kernel会“监视”所有select负责的socket；当任何一个socket中的数据准备好了，select就会返回。这个时候，用户进程再调用read操作，将数据从kernel拷贝到用户进程。
    这个图和blocking IO的图其实并没有太大的不同，事实上还更差一些。因为这里需要使用两个系统调用(select和recvfrom)，而blocking IO只调用了一个系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）

4)信号驱动I/O （signal driven I/O (SIGIO)）
简介：两次调用，两次返回；
    首先我们允许套接口进行信号驱动I/O,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。

5)异步I/O （asynchronous I/O (the POSIX aio_functions)）
  当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者的输入输出操作，linux下的异步IO其实不是完全实现了异步，真正完全实现了异步IO的是windows下的IOCP。netty5使用了异步IO，但是现在停止开发了，都是用netty4.


6） 同步IO和异步IO的区别就在于：数据拷贝的时候进程是否阻塞
	阻塞IO和非阻塞IO的区别就在于：应用程序的调用是否立即返回
	NIO和IO的区别？
	1、面向流与面向缓冲
	     Java IO和NIO之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，
	     它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。 
	     Java NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。
	     但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。

	2、阻塞与非阻塞IO
	     Java IO的各种流是阻塞的。这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。
	     该线程在此期间不能再干任何事情了。Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，
	     如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 
	     非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 
	     线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。

	3、选择器（Selectors）
	     Java NIO的选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：
	     这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。
  



5，AIO,BIO,NIO？
1，同步阻塞IO（BIO）
我们熟知的Socket编程就是BIO，一个socket连接一个处理线程（这个线程负责这个Socket连接的一系列数据传输操作）。阻塞的原因在于：操作系统允许的线程数量是有限的，多个socket申请与服务端建立连接时，服务端不能提供相应数量的处理线程，没有分配到处理线程的连接就会阻塞等待或被拒绝。

2，同步非阻塞IO（NIO）
New IO是对BIO的改进，基于Reactor模型。我们知道，一个socket连接只有在特点时候才会发生数据传输IO操作，大部分时间这个“数据通道”是空闲的，但还是占用着线程。NIO作出的改进就是“一个请求一个线程”，在连接到服务端的众多socket中，只有需要进行IO操作的才能获取服务端的处理线程进行IO。这样就不会因为线程不够用而限制了socket的接入。客户端的socket连接到服务端时，就会在事件分离器注册一个 IO请求事件 和 IO 事件处理器。在该连接发生IO请求时，IO事件处理器就会启动一个线程来处理这个IO请求，不断尝试获取系统的IO的使用权限，一旦成功（即：可以进行IO），则通知这个socket进行IO数据传输。

3，异步阻塞IO（AIO）
NIO是同步的IO，是因为程序需要IO操作时，必须获得了IO权限后亲自进行IO操作才能进行下一步操作。AIO是对NIO的改进（所以AIO又叫NIO.2），它是基于Proactor模型的。每个socket连接在事件分离器注册 IO完成事件 和 IO完成事件处理器。程序需要进行IO时，向分离器发出IO请求并把所用的Buffer区域告知分离器，分离器通知操作系统进行IO操作，操作系统自己不断尝试获取IO权限并进行IO操作（数据保存在Buffer区），操作完成后通知分离器；分离器检测到 IO完成事件，则激活 IO完成事件处理器，处理器会通知程序说“IO已完成”，程序知道后就直接从Buffer区进行数据的读写。
异步IO：客户端的连接，发送数据，接收数据都是异步的，服务端的连接，接收数据，发送数据都是异步的。

注意：AIO是发出IO请求后，由操作系统自己去获取IO权限并进行IO操作；NIO则是发出IO请求后，由线程不断尝试获取IO权限，获取到后通知应用程序自己进行IO操作。当时客户端应用可以使用BIO，如果是服务端建议使用BIO或者AIO。


6，selector，poll和epoll？
1、支持一个进程所能打开的最大连接数
select：单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是32*32，同理64位机器上FD_SETSIZE为32*64），可以对进行修改，然后重新编译内核，但是性能可能会受到影响。
poll：poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的
epoll：连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接
2、FD剧增后带来的IO效率问题
select：因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。
poll：同上
epoll：因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。
3、 消息传递方式
select：内核需要将消息传递到用户空间，都需要内核拷贝动作
poll：同上
epoll：epoll通过内核和用户空间共享一块内存来实现的。


7，原生JDK网络编程- NIO之Reactor模式？
有点类似于观察者模式（一个数据源，即是一个被观察者，多个观察者，一对多），NIO之Reactor模式（反应器），观察多个客户端连接，即是多对多的关系，所以又有点不同。Netty服务端使用了“多Reactor线程模式”。


8，buffer缓冲区？
Buffer用于和NIO通道进行交互。数据是从通道读入缓冲区，从缓冲区写入到通道中的。以写为例，应用程序都是将数据写入缓冲，再通过通道把缓冲的数据发送出去，读也是一样，数据总是先从通道读到缓冲，应用程序再读缓冲的数据。
缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO的Buffer对象，并提供了一组方法，用来方便的访问该块内存。
重要属性：
1，capacity
作为一个内存块，Buffer有一个固定的大小值，也叫“capacity”.你只能往里写capacity个byte、long，char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。
2，position
当你写数据到Buffer中时，position表示当前的位置。初始的position值为0.当一个byte、long等数据写到Buffer后， position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1.
当读取数据时，也是从某个特定位置读。当将Buffer从写模式切换到读模式，position会被重置为0. 当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。
3，limit
在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。 写模式下，limit等于Buffer的capacity。
当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是position）
注意：buffer可以在堆内存上分配，也可以在直接内存上分配，一般建议在堆内存上分配。


9，java原生NIO模型？
1、reactor（反应器）模式
　　使用单线程模拟多线程，提高资源利用率和程序的效率，增加系统吞吐量。
2、NIO中的重要概念 通道、缓冲区、选择器
　　通道（Chnannle）：类似于流，但是可以异步读写数据（流只能同步读写），通道是双向的，（流是单向的），通道的数据总是要先读						到一个buffer或者从一个buffer写入，即通道与buffer进行数据交互。
	缓冲区（Buffer）：本质上是一块可以存储数据的内存，被封装成了buffer对象而已！
				选择器也叫多路复用器（Selector）：相当于一个观察者，用来监听通道感兴趣的事件，一个选择器可以绑定多个通道；
	操作类型（SelectionKey）：提供读、写、连接、接收连接的操作。注意：一般注册OP_READ，不注册OP_WRITE，OP_WRITE用于表示底层缓冲区是否有空间，是则返回TRUE。


10，为什么要用Netty？
1、虽然JAVA NIO框架提供了 多路复用IO的支持，但是并没有提供上层“信息格式”的良好封装。例如前两者并没有提供针对 Protocol Buffer、JSON这些信息格式的封装，但是Netty框架提供了这些数据格式封装（基于责任链模式的编码和解码功能）；
2、直接使用NIO需要需要额外的技能，例如Java多线程，网络编程；
3、要编写一个可靠的、易维护的、高性能的NIO服务器应用。除了框架本身要兼容实现各类操作系统的实现外。更重要的是它应该还要处理很多上层特有服务，例如：客户端的权限、还有上面提到的信息格式封装、简单的数据读取，断连重连，半包读写，心跳等等，这些Netty框架都提供了响应的支持。
4、JAVA NIO框架存在一个poll/epoll bug：Selector doesn’t block on Selector.select(timeout)，不能block意味着CPU的使用率会变成100%（这是底层JNI的问题，上层要处理这个异常实际上也好办）。当然这个bug只有在Linux内核上才能重现。
这个问题在JDK 1.7版本中还没有被完全解决，但是Netty已经将这个bug进行了处理。
这个Bug与操作系统机制有关系的，JDK虽然仅仅是一个兼容各个操作系统平台的软件，但在JDK5和JDK6最初的版本中（严格意义上来将，JDK部分版本都是），这个问题并没有解决，而将这个帽子抛给了操作系统方，这也就是这个bug最终一直到2013年才最终修复的原因(JDK7和JDK8之间)。



11，为什么不用Netty5
1. netty5 中使用了 ForkJoinPool，增加了代码的复杂度，但是对性能的改善却不明显
2. 多个分支的代码同步工作量很大
3. 作者觉得当下还不到发布一个新版本的时候
4. 在发布版本之前，还有更多问题需要调查一下，比如是否应该废弃 exceptionCaught， 是否暴露EventExecutorChooser等等。


12，为什么Netty使用NIO而不是AIO？,
Netty不看重Windows上的使用，在Linux系统上，AIO的底层实现仍使用EPOLL，没有很好实现AIO，因此在性能上没有明显的优势，而且被JDK封装了一层不容易深度优化。
AIO还有个缺点是接收数据需要预先分配缓存, 而不是NIO那种需要接收时才需要分配缓存, 所以对连接数量非常大但流量小的情况, 内存浪费很多。
据说Linux上AIO不够成熟，处理回调结果速度跟不上处理需求，有点像外卖员太少，顾客太多，供不应求，造成处理速度有瓶颈。



13，Netty？
	1，Channel
		Channel是Java NIO的一个基本构造，和Jdk的Channel不同，jdk的范围更广，包括了文件读写，netty只针对socket网络编程。
		它代表一个到实体（如一个硬件设备、一个文件、一个网络套接字或者一个能够执行一个或者多个不同的IO操作的程序组件）的开放连接，如读操作和写操作
		目前，可以把Channel 看作是传入（入站）或者传出（出站）数据的载体。因此，它可以被打开或者被关闭，连接或者断开连接。
		实现基本的I/O操作（bind（）、connect（）、read（）和write（）依赖于底层网络传输所提供的原语。在基于Java的网络编程中，其基本的构造是class Socket。Netty 的Channel 接口所提供的API，被用于所有的I/O 操作。大大地降低了直接使用Socket 类的复杂性。此外，Channel也是拥有许多预定义的、专门化实现的广泛类层次结构的根。

		每个Channel 都将会被分配一个ChannelPipeline和ChannelConfig。ChannelConfig包含了该Channel的所有配置设置，并且支持热更新。由于Channel是独一无二的，所以为了保证顺序将Channel声明为java.lang.Comparable的一个子接口。因此，如果两个不同的Channel实例都返回了相同的散列码，那么AbstractChannel中的compareTo()方法的实现将会抛出一个Error。

		Channel的生命周期状态：
			ChannelUnregistered Channel：已经被创建，但还未注册到EventLoop
			ChannelRegistered Channel：已经被注册到了EventLoop
			ChannelActive Channel：处于活动状态（已经连接到它的远程节点）。它现在可以接收和发送数据了
			ChannelInactive Channel：没有连接到远程节点

		最重要Channel的方法：
			eventLoop：返回分配给Channel的EventLoop
			pipeline：返回分配给Channel的ChannelPipeline
			isActive：如果Channel是活动的，则返回true。活动的意义可能依赖于底层的传输。例如，一个Socket传输一旦连接到了远程节点便是活动的，而一个Datagram 传输一旦被打开便是活动的。
			localAddress：返回本地的SokcetAddress
			remoteAddress：返回远程的SocketAddress
			write：将数据写到远程节点。这个数据将被传递给ChannelPipeline，并且排队直到它被冲刷
			flush：将之前已写的数据冲刷到底层传输，如一个Socket
			writeAndFlush：一个简便的方法，等同于调用write()并接着调用flush()


	2，EventLoop和EventLoopGroup
			EventLoop定义了Netty 的核心抽象，用于处理连接的生命周期中所发生的事件。io.netty.util.concurrent包构建在JDK 的java.util.concurrent包上。一个EventLoop将由一个永远都不会改变的Thread驱动，同时任务（Runnable或者Callable）可以直接提交给EventLoop 实现，以立即执行或者调度执行。

			根据配置和可用核心的不同，可能会创建多个EventLoop实例用以优化资源的使用，并且单个EventLoop可能会被指派用于服务多个Channel。
			Netty的EventLoop在继承了ScheduledExecutorService的同时，只定义了一个方法，parent()。在Netty 4 中，所有的I/O操作和事件都由已经被分配给了EventLoop的那个Thread来处理。

			任务调度：
				偶尔，你将需要调度一个任务以便稍后（延迟）执行或者周期性地执行。例如，你可能想要注册一个在客户端已经连接了5 分钟之后触发的任务。一个常见的用例是，发送心跳消息到远程节点，以检查连接是否仍然还活着。如果没有响应，你便知道可以关闭该Channel 了。
				在内部，当提交任务到如果（当前）调用线程正是支撑EventLoop的线程，那么所提交的代码块将会被（直接）执行。否则，EventLoop将调度该任务以便稍后执行，并将它放入到内部队列中。当EventLoop下次处理它的事件时，它会执行队列中的那些任务/事件。

			异步传输：
				异步传输实现只使用了少量的EventLoop（以及和它们相关联的Thread），而且在当前的线程模型中，它们可能会被多个Channel 所共享。这使得可以通过尽可能少量的Thread来支撑大量的Channel，而不是每个Channel分配一个Thread。EventLoopGroup 负责为每个新创建的Channel 分配一个EventLoop。在当前实现中，使用顺序循环（round-robin）的方式进行分配以获取一个均衡的分布，并且相同的EventLoop可能会被分配给多个Channel。
				一旦一个Channel 被分配给一个EventLoop，它将在它的整个生命周期中都使用这个EventLoop（以及相关联的Thread）。请牢记这一点，因为它可以使你从担忧你的Channel-Handler 实现中的线程安全和同步问题中解脱出来。
				另外，需要注意的是，EventLoop 的分配方式对ThreadLocal的使用的影响。因为一个EventLoop通常会被用于支撑多个Channel，所以对于所有相关联的Channel来说，ThreadLocal都将是一样的。这使得它对于实现状态追踪等功能来说是个糟糕的选择。然而，在一些无状态的上下文中，它仍然可以被用于在多个Channel之间共享一些重度的或者代价昂贵的对象，甚至是事件。


	3，ChannelFuture接口
			Netty 中所有的I/O 操作都是异步的。因为一个操作可能不会立即返回，所以我们需要一种用于在之后的某个时间点确定其结果的方法。为此，Netty 提供了ChannelFuture 接口，其addListener（）方法注册了一个ChannelFutureListener，以便在某个操作完成时（无论是否成功）得到通知。可以将ChannelFuture 看作是将来要执行的操作的结果的占位符。它究竟什么时候被执行则可能取决于若干的因素，因此不可能准确地预测，但是可以肯定的是它将会被执行。

	4，ctx.write()和channel().write()的区别
			如果我们是使用channel().write（）方法。可以不用考虑outbound和inbound的添加顺序。每次都会从tail往前找第一个是outbound的handler来执行。
			而ctx.write()则是从当前outbound或inbound开始执行。



	5，ChannelHandler接口		
			从应用程序开发人员的角度来看，Netty的主要组件是ChannelHandler，它充当了所有处理入站和出站数据的应用程序逻辑的容器。ChannelHandler 的方法是由网络事件触发的。事实上，ChannelHandler 可专门用于几乎任何类型的动作，例如将数据从一种格式转换为另外一种格式，例如各种编解码，或者处理转换过程中所抛出的异常。
				举例来说，ChannelInboundHandler 是一个你将会经常实现的子接口。这种类型的ChannelHandler 接收入站事件和数据，这些数据随后将会被你的应用程序的业务逻辑所处理。当你要给连接的客户端发送响应时，也可以从ChannelInboundHandler冲刷数据。你的应用程序的业务逻辑通常驻留在一个或者多个ChannelInboundHandler 中。
				这种类型的ChannelHandler 接收入站事件和数据，这些数据随后将会被你的应用程序的业务逻辑所处理。
				ChannelHandler 的生命周期
					下面列出了interface ChannelHandler 定义的生命周期操作，在ChannelHandler被添加到ChannelPipeline 中或者被从ChannelPipeline 中移除时会调用这些操作。这些方法中的每一个都接受一个ChannelHandlerContext 参数。
					handlerAdded 当把ChannelHandler 添加到ChannelPipeline 中时被调用
					handlerRemoved 当从ChannelPipeline 中移除ChannelHandler 时被调用
					exceptionCaught 当处理过程中在ChannelPipeline 中有错误产生时被调用
					Netty 定义了下面两个重要的ChannelHandler 子接口：
					ChannelInboundHandler——处理入站数据以及各种状态变化；
					ChannelOutboundHandler——处理出站数据并且允许拦截所有的操作。


	6，ChannelInboundHandler接口和ChannelOutboundHandler接口
			ChannelInboundHandler接口：处理入站事件
			ChannelOutboundHandler接口：处理出站事件


	7，ChannelHandler的适配器
			有一些适配器类可以将编写自定义的ChannelHandler 所需要的努力降到最低限度，因为它们提供了定义在对应接口中的所有方法的默认实现。因为你有时会忽略那些不感兴趣的事件，所以Netty提供了抽象基类ChannelInboundHandlerAdapter 和ChannelOutboundHandlerAdapter。


	8，ChannelPipeline 接口
			当Channel 被创建时，它会被自动地分配到它专属的ChannelPipeline。每一个新创建的Channel都将会被分配一个新的ChannelPipeline。这项关联是永久性的；Channel 既不能附加另外一个ChannelPipeline，也不能分离其当前的。在Netty组件的生命周期中，这是一项固定的操作，不需要开发人员的任何干预。
			使得事件流经ChannelPipeline 是ChannelHandler 的工作，它们是在应用程序的初始化或者引导阶段被安装的。这些对象接收事件、执行它们所实现的处理逻辑，并将数据传递给链中的下一个ChannelHandler。它们的执行顺序是由它们被添加的顺序所决定的。
			入站和出站ChannelHandler可以被安装到同一个ChannelPipeline中。如果一个消息或者任何其他的入站事件被读取，那么它会从ChannelPipeline 的头部开始流动，最终，数据将会到达ChannelPipeline 的尾端，届时，所有处理就都结束了。
			数据的出站运动（即正在被写的数据）在概念上也是一样的。在这种情况下，数据将从ChannelOutboundHandler 链的尾端开始流动，直到它到达链的头部为止。在这之后，出站数据将会到达网络传输层，这里显示为Socket。通常情况下，这将触发一个写操作。
			如果将两个类别的ChannelHandler都混合添加到同一个ChannelPipeline中会发生什么。虽然ChannelInboundHandle和ChannelOutboundHandle 都扩展自ChannelHandler，但是Netty 能区分ChannelInboundHandler实现和ChannelOutboundHandler实现，并确保数据只会在具有相同定向类型的两个ChannelHandler 之间传递。


	9，ChannelHandlerContext
			通过使用作为参数传递到每个方法的ChannelHandlerContext，事件可以被传递给当前ChannelHandler链中的下一个ChannelHandler。虽然这个对象可以被用于获取底层的Channel，但是它主要还是被用于写出站数据。
			ChannelHandlerContext代表了ChannelHandler和ChannelPipeline之间的关联，每当有ChannelHandler添加到ChannelPipeline 中时，都会创建ChannelHandler-Context。ChannelHandlerContext的主要功能是管理它所关联的ChannelHandler和在同一个ChannelPipeline 中的其他ChannelHandler 之间的交互。
			ChannelHandlerContext有很多的方法，其中一些方法也存在于Channel和Channel-Pipeline本身上，但是有一点重要的不同。如果调用Channel 或者ChannelPipeline 上的这些方法，它们将沿着整个ChannelPipeline进行传播。而调用位于ChannelHandlerContext上的相同方法，则将从当前所关联的ChannelHandler开始，并且只会传播给位于该ChannelPipeline中的下一个（入站下一个，出站上一个）能够处理该事件的ChannelHandler。


	10，选择合适的内置通信传输模式
			NIO： 使用java.nio.channels 包作为基础——基于选择器的方式
			Epoll： 由 JNI 驱动的 epoll()和非阻塞 IO。这个传输支持只有在Linux 上可用的多种特性，如SO_REUSEPORT，比NIO传输更快，而且是完全非阻塞的。将NioEventLoopGroup替换为EpollEventLoopGroup，并且将NioServerSocketChannel.class替换为EpollServerSocketChannel.class 即可。
			OIO： 使用java.net 包作为基础——使用阻塞流
			Local： 可以在VM 内部通过管道进行通信的本地传输
			Embedded：Embedded传输，允许使用ChannelHandler而又不需要一个真正的基于网络的传输。在测试ChannelHandler实现时非常有用


	11，引导Bootstrap
			有两种类型的引导：一种用于客户端（简单地称为Bootstrap），而另一种（ServerBootstrap）用于服务器。无论你的应用程序使用哪种协议或者处理哪种类型的数据，唯一决定它使用哪种引导类的是它是作为一个客户端还是作为一个服务器。
			ServerBootstrap 将绑定到一个端口，因为服务器必须要监听连接，而Bootstrap 则是由想要连接到远程节点的客户端应用程序所使用的。
			第二个区别可能更加明显。引导一个客户端只需要一个EventLoopGroup，但是一个ServerBootstrap则需要两个（也可以是同一个实例）。
			因为服务器需要两组不同的Channel。第一组将只包含一个ServerChannel，代表服务器自身的已绑定到某个本地端口的正在监听的套接字。而第二组将包含所有已创建的用来处理传入客户端连接（对于每个服务器已经接受的连接都有一个）的Channel。
			与ServerChannel相关联的EventLoopGroup将分配一个负责为传入连接请求创建Channel的EventLoop。一旦连接被接受，第二个EventLoopGroup 就会给它的Channel分配一个EventLoop。


	12，ChannelOption
			可以配置各种属性


	13，ByteBuf缓冲区
			ByteBuf API 的优点：
			它可以被用户自定义的缓冲区类型扩展；
			通过内置的复合缓冲区类型实现了透明的零拷贝；
			容量可以按需增长（类似于JDK 的StringBuilder）；
			在读和写这两种模式之间切换不需要调用ByteBuffer 的flip()方法；
			读和写使用了不同的索引；
			支持方法的链式调用；
			支持引用计数；
			支持池化。
			ByteBuf 维护了两个不同的索引，名称以read 或者write 开头的ByteBuf 方法，将会推进其对应的索引，而名称以set或者get 开头的操作则不会。
			如果打算读取字节直到readerIndex 达到和writerIndex 同样的值时会发生什么。在那时，你将会到达“可以读取的”数据的末尾。就如同试图读取超出数组末尾的数据一样，试图读取超出该点的数据将会触发一个IndexOutOf-BoundsException。可以指定ByteBuf 的最大容量。试图移动写索引（即writerIndex）超过这个值将会触发一个异常。（默认的限制是Integer.MAX_VALUE。）

			分配：
				堆缓冲区：
					最常用的ByteBuf 模式是将数据存储在JVM 的堆空间中。这种模式被称为支撑数组（backingarray），它能在没有使用池化的情况下提供快速的分配和释放。可以由hasArray（）来判断检查ByteBuf是否由数组支撑。如果不是，则这是一个直接缓冲区。

				直接缓冲区：
					直接缓冲区是另外一种ByteBuf 模式。
					直接缓冲区的主要缺点是，相对于基于堆的缓冲区，它们的分配和释放都较为昂贵。如果你正在处理遗留代码，你也可能会遇到另外一个缺点：因为数据不是在堆上，所以你不得不进行一次复制。 
					显然，与使用支撑数组相比，这涉及的工作更多。因此，如果事先知道容器中的数据将会被作为数组来访问，你可能更愿意使用堆内存。


			ByteBuf与JDK中的ByteBuffer的区别： 
				（1）netty的ByteBuf采用了读/写索引分离，一个初始化的ByteBuf的readerIndex和writerIndex都处于0位置。 
				（2）当读索引和写索引处于同一位置时，如果我们继续读取，就会抛出异常IndexOutOfBoundsException。 
				（3）对于ByteBuf的任何读写操作都会分别单独的维护读索引和写索引。maxCapacity最大容量默认的限制就是Integer.MAX_VALUE。


	14，什么是TCP粘包半包？
			假设客户端分别发送了两个数据包D1和D2给服务端，由于服务端一次读取到的字节数是不确定的，故可能存在以下4种情况。
			（1）服务端分两次读取到了两个独立的数据包，分别是D1和D2，没有粘包和拆包；
			（2）服务端一次接收到了两个数据包，D1和D2粘合在一起，被称为TCP粘包；
			（3）服务端分两次读取到了两个数据包，第一次读取到了完整的D1包和D2包的部分内容，第二次读取到了D2包的剩余内容，这被称为TCP拆包；
			（4）服务端分两次读取到了两个数据包，第一次读取到了D1包的部分内容D1_1，第二次读取到了D1包的剩余内容D1_2和D2包的整包。
			如果此时服务端TCP接收滑窗非常小，而数据包D1和D2比较大，很有可能会发生第五种可能，即服务端分多次才能将D1和D2包接收完全，期间发生多次拆包。


	15，TCP粘包/半包发生的原因
			由于TCP协议本身的机制（面向连接的可靠地协议-三次握手机制）客户端与服务器会维持一个连接（Channel），数据在连接不断开的情况下，可以持续不断地将多个数据包发往服务器，但是如果发送的网络数据包太小，那么他本身会启用Nagle算法（可配置是否启用）对较小的数据包进行合并（基于此，TCP的网络延迟要UDP的高些）然后再发送（超时或者包大小足够）。那么这样的话，服务器在接收到消息（数据流）的时候就无法区分哪些数据包是客户端自己分开发送的，这样产生了粘包；服务器在接收到数据库后，放到缓冲区中，如果消息没有被及时从缓存区取走，下次在取数据的时候可能就会出现一次取出多个数据包的情况，造成粘包现象。
			UDP：本身作为无连接的不可靠的传输协议（适合频繁发送较小的数据包），他不会对数据包进行合并发送（也就没有Nagle算法之说了），他直接是一端发送什么数据，直接就发出去了，既然他不会对数据合并，每一个数据包都是完整的（数据+UDP头+IP头等等发一次数据封装一次）也就没有粘包一说了。
			分包产生的原因就简单的多：可能是IP分片传输导致的，也可能是传输过程中丢失部分包导致出现的半包，还有可能就是一个包可能被分成了两次传输，在取数据的时候，先取到了一部分（还可能与接收的缓冲区大小有关系），总之就是一个数据包被分成了多次接收。
			更具体的原因有三个，分别如下。
				1. 应用程序写入数据的字节大小大于套接字发送缓冲区的大小
				2. 进行MSS大小的TCP分段。MSS是最大报文段长度的缩写。MSS是TCP报文段中的数据字段的最大长度。数据字段加上TCP首部才等于整个的TCP报文段。所以MSS并不是TCP报文段的最大长度，而是：MSS=TCP报文段长度-TCP首部长度
				3. 以太网的payload大于MTU进行IP分片。MTU指：一种通信协议的某一层上面所能通过的最大数据包大小。如果IP层有一个数据包要传，而且数据的长度比链路层的MTU大，那么IP层就会进行分片，把数据包分成托干片，让每一片都不超过MTU。注意，IP分片可以发生在原始发送端主机上，也可以发生在中间路由器上。


	16，解决粘包半包问题
			由于底层的TCP无法理解上层的业务数据，所以在底层是无法保证数据包不被拆分和重组的，这个问题只能通过上层的应用协议栈设计来解决，根据业界的主流协议的解决方案，可以归纳如下。
				（1）在包尾增加分割符，比如回车换行符进行分割，例如FTP协议；linebase包和delimiter包下，分别使用LineBasedFrameDecoder和DelimiterBasedFrameDecoder，如果超过规定字节长度，会报错。
				（2）消息定长，例如每个报文的大小为固定长度200字节，如果不够，空位补空格；fixed包下，使用FixedLengthFrameDecoder
				（3）将消息分为消息头和消息体，消息头中包含表示消息总长度（或者消息体长度）的字段，通常设计思路为消息头的第   一个字段使用int32来表示消息的总长度，LengthFieldBasedFrameDecoder；。




	17,服务器推送技术？
		1，短轮询？
			Ajax短轮询：http 短轮询是 server 收到请求不管是否有数据到达都直接响应http请求；如果浏览器收到的数据为空，则隔一段时间，浏览器又会发送相同的http请求到server 以获取数据响应，就是用一个定时器不停的去网站上请求数据。
			缺点：消息交互的实时性较低（server端到浏览器端的数据反馈效率低）。
		
		2，长轮询？
				http 长轮询是server 收到请求后如果有数据，立刻响应请求；如果没有数据 就会 停留 一段时间，这段时间内，如果 server 请求的数据到达（如查询数据库或数据的逻辑处理完成），就会立刻响应；如果这段时间过后，还没有数据到达，则以空数据的形式响应http请求；若浏览器收到的数据为空，会再次发送同样的http请求到server；

			实现：
				1，AJAX的长轮询：
						1，DeferredResult：Springmvc的控制层接收用户的请求之后，采用异步处理，立即返回DeferedResult泛型对象，此时驱动控制层的容器主线程，可以处理更多的请求。
						2，Servlet3：也是异步处理。
					缺点：server 没有数据到达时，http连接会停留一段时间，这会造成服务器资源浪费；

				2，SSE：
					严格地说，HTTP 协议无法做到服务器主动推送信息。但是，有一种变通方法，就是服务器向客户端声明，接下来要发送的是流信息（streaming）。
					也就是说，发送的不是一次性的数据包，而是一个数据流，会连续不断地发送过来。这时，客户端不会关闭连接，会一直等着服务器发过来的新的数据流，视频播放就是这样的例子。本质上，这种通信就是以流信息的方式，完成一次用时很长的下载。
					SSE 就是利用这种机制，使用流信息向浏览器推送信息。它基于 HTTP 协议，目前除了 IE/Edge，其他浏览器都支持。
					SSE 与 WebSocket 作用相似，都是建立浏览器与服务器之间的通信渠道，然后服务器向浏览器推送信息。
					总体来说，WebSocket 更强大和灵活。因为它是全双工通道，可以双向通信；SSE是单向通道，只能服务器向浏览器发送，因为流信息本质上就是下载。如果浏览器向服务器发送信息，就变成了另一次 HTTP 请求。
					SSE 也有自己的优点：
						SSE 使用 HTTP 协议，现有的服务器软件都支持。WebSocket 是一个独立协议。
						SSE 属于轻量级，使用简单；WebSocket 协议相对复杂。
						SSE 默认支持断线重连，WebSocket 需要自己实现。
						SSE 一般只用来传送文本，二进制数据需要编码后传送，WebSocket 默认支持传送二进制数据。
						SSE 支持自定义发送的消息类型。
						SSE 也是长连接

				SSE和WebSocket相比的优势：
					1，最大的优势就是便利：不需要添加任何新组件，用任何你习惯的后端语言和框架就能继续使用。你不用为新建虚拟机、弄一个新的IP或新的端口号而劳神，就像在现有网站中新增一个页面那样简单。可以称为既存基础设施优势。
					2，SSE的第二个优势是服务端的简洁。相对而言，WebSocket则很复杂，不借助辅助类库基本搞不定。WebSocket能做的，SSE也能做，反之亦然，但在完成某些任务方面，它们各有千秋。WebSocket是一种更为复杂的服务端实现技术，但它是真正的双向传输技术，既能从服务端向客户端推送数据，也能从客户端向服务端推送数据。


				注意：技术没有优劣之分，只有场景是否合适，在京东的支付完成之后的跳转的推送技术中，也是用的ajax段轮训的方式，原因是要用有限的资源来为千万级甚至上亿的用户提供服务，如果是用长连接，对于接入的服务器，比如说Nginx，是很大的压力，光是为用户维持这个长连接都需要成百上千的Nginx的服务器，这是很划不来的。因为对于京东这类购物网站来说，用户的浏览查询量是远远大于用户下单量的，京东需要注重的是服务更多的用户，而且相对于用户浏览页面的图片等等的流量而言，这点带宽浪费占比是很小的。所以我们看京东的付款后的实现，是用的短轮询机制，而且时长放大到了5秒。

		3，http 长轮询 和 短轮询的异同：
			1）相同点：当server 的数据不可达时，基于http长轮询和短轮询 的http请求，都会 停留一段时间；
			2）不同点：http长轮询是在服务器端的停留，而http 短轮询是在 浏览器端的停留；
			3）性能总结：从这里可以看出，不管是长轮询还是短轮询，都不太适用于客户端数量太多的情况，因为每个服务器所能承载的TCP连接数是有上限的，这种轮询很容易把连接数顶满；


	18，WebSocket通信？
		1，什么是WebSocket？
			WebSocket 是 html5 规范发布的新协议，和 http协议完全是两个不同的概念，或者说基本没关系；WebSocket协议和http协议的唯一联系点在于，WebSocket协议为了兼容现有浏览器的握手规范而采用了http协议中的握手规范以建立WebSocket连接，其客户端与服务器建立的是 持久连接。

			WebSocket 解决了 HTTP 的几个难题：
				1（http协议的被动性）：采用 WebSocket 协议后，服务器可以主动推送消息给客户端；而不需要客户端以（长/短）轮询的方式发起http请求到server以获取数据更新反馈；这样一来，客户端只需要经过一次HTTP请求，就可以做到源源不断的信息传送了（在程序设计中，这种设计叫做回调，即：server端有信息了再来通知client端，而不是client端每次都傻乎乎地跑去轮询server端 是否有消息更新）；
				2（http协议的无状态性/健忘性）：短轮询是每次http请求前都要建立连接，而长轮询是相邻几次请求前都要建立连接；http请求响应完成后，服务器就会断开连接，且把连接的信息全都忘记了；所以每次建立连接都要重新传输连接上下文（下面有补充），将 client 端的连接上下文来告诉server端；而WebSockct只需要一次HTTP握手，整个通讯过程是建立在一次连接（状态）中的，server端会一直推送消息更新反馈到客户端，直到客户端关闭请求，这样就无需客户端为发送消息而建立不必要的 tcp 连接 和 为了建立tcp连接而发送不必要的冗余的连接上下文消息；

			特点：
				1，HTML5中的协议，实现与客户端与服务器双向，基于消息的文本或二进制数据通信
				2，适合于对数据的实时性要求比较强的场景，如通信、直播、共享桌面，特别适合于客户与服务频繁交互的情况下，如实			时共享、多人协作等平台。
				3，采用新的协议，后端需要单独实现
				4，客户端并不是所有浏览器都支持

			实现：
				1，HTML5规范中的WebSocket API

				2，WebSocket的子协议STOMP。
					STOMP(Simple Text Oriented Messaging Protocol)：
						1，简单(流)文本定向消息协议
						2，STOMP协议的前身是TTMP协议（一个简单的基于文本的协议），专为消息中间件设计。是属于消息队列的一种协议, 和AMQP,JMS平级.它的简单性恰巧可以用于定义websocket的消息体格式.STOMP协议很多MQ都已支持,比如RabbitMq, ActiveMq。
						3，生产者（发送消息）、消息代理、消费者（订阅然后收到消息）
						4，STOMP是基于帧的协议







---------------------------------------------------------------------------------------------------------------------------------------------------------------

四，nginx？

1,linux常用命令？
rpm：安装rpm类型的文件
wget：远程下载
crul：展示某个地址的所有信息
yum search ：查找某个命令的安装源
yum -y install：安装某个命令，默认Y
sz：将linux中的某个文件下载到本地
rz：将本地中的某个文件上传到服务器
netstat -nlpt| grep 20：查看20端口被占用情况
ps -aux | grep java：查看java进程使用情况
scp root@ip:/路径：远程从其他服务器拷贝文件到当前路径
find -name ：查找某个文件的路径
top：查看当前系统的CPU,内存等使用情况
pwd：显示当前路径
useradd ：增加用户
su username passwd：给用户设置密码
chmod：权限操作，rwx rwd rwd，分别为当前用户，当前用户组，其他用户，r是读，w是写，x是执行
whereis java：查找java安装路径
whoami：查看当前用户
tar -zcxf ：打包，之后可能需要再压缩
gzip/zip：压缩
unzip：解压
tail -10f xx|grep xxx：从文件末尾读取10行，可以用户查看日志
yum install -y epel-release：安装yum扩展源，这样有一些安装包就可以直接安装了，比如yum install nginx

2，linux的epoll机制？


3，ngnix？
作用：
1，集群负载均衡
2，反向代理
3，常用于处理静态资源
4，解决跨域问题
5，设置防盗链
6，静态资源缓存
7，文件压缩


分布式和集群和微服务：
集群：多个服务器做同一个服务
分布式：同个服务器不同服务
微服务：分布式中拆分的一个个小的服务就是微服务，多个微服务就组成了分布式系统



4，正向代理和反向代理？
代理：客户端通过访问代理服务器，通过代理服务器去获取真正服务器的资源。
正向代理：客户端和代理在同一个LAN，客户端知道代理服务器的存在，服务端不知道。
正向代理的用途：
（1）访问原来无法访问的资源，如google
（2）可以做缓存，加速访问资源
（3）对客户端访问授权，上网进行认证
（4）代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息

反向代理：服务端和代理在同一个LAN，客户端不知道代理服务器的存在，服务端知道。
反向代理的作用：
（1）保证内网的安全，可以使用反向代理提供WAF功能，阻止web攻击，大型网站，通常将反向代理作为公网访问地址，Web服务器是内网。
（2）负载均衡，通过反向代理服务器来优化网站的负载


5,nginx -s stop and -s quit 有什么区别?
quit：是安全关闭方式，即是在关闭，如果有未处理完的请求会等请求处理完才关闭
stop：是强制关闭

6，nginx的负载均衡的session共享问题？
问题：客户端发送同一个ip请求，当请求中带有token，nginx对请求进行负载均衡，第一次分发到A服务器，A保存了token，第二次分发到B服务器，B服务器上没有token值，所以就不能保证登录共享。
解决：ip_hash技术，nginx中可以配置，当某个ip下的客户端请求指定（固定，因为根据IP地址计算出一个hash值，根据hash值来判断分配给那台服务器，从而每次该ip请求都分配到指定的服务器）的服务器，这样就可以保证有状态请求的状态的完整性，不至于出现状态丢失的情况。
注意：ip_hash这个方案确实可以保证带有状态的请求的完整性，但是它有一个很大的缺陷，那就是ip_hash方案必须保证Nginx是最前端的服务器（接受真实的ip），如果nginx不是最前端的服务器，还存在中间件（中间服务器什么的），那么nginx获取的ip地址就不是真实的ip地址，那么这个ip_hash就没有任何意义。


7，nginx的运行原理？
nginx运行阶段：  
rewrite 阶段：类比于controller阶段
access 阶段：类比于service阶段
content 阶段：类比于jsp阶段，最后的阶段，是响应给客户端的结果


8，location语法？
 比如：location /nginx2 {
		 proxy_pass http://nginx2/;
	   }
当proxy_pass的代理ip末尾有/，就表示将所匹配的URL，不带nginx2传递给代理服务器，反之没有/，就将匹配的URL全部传递给代理服务器
。

9，upstream/location/rewrite功用？
upstream --- 用以配置负载的策略，nginx自带的有：轮询/权重/ip_hash。特殊需求可用第三方策略（使用较少）。
location:----用以匹配url信息结构，配足即进入对应逻辑块。是一套匹配逻辑的小型语法，核心是做url匹配。
rewrite：----用以修改url信息（ip+port部分无法改）的path部分，做重定向。与servlet类似，有页面重定向和内部重定向两类。
proxy_pass----用以转发命令。是实际的转发执行者。它可将流程转给upstream模块。


10，nginx.conf中的server？
1、每一个server，对应一个监听port端口，一个ip/域名
2、nginx里面可配置多个server，多个upstream
3、每个server配置多个location
4、一般配置方式：
在/etc/nginx/con.d/目录下，放置多个server配置文件，每个配置文件里仅含一个server配置。
然后在主配置nginx.conf中 ： include 文件夹下所以server配置 ====  jsp里的include


11，rewrite使用：？
rewrite regex replacement [flag];	 flag=【break/last/redirect/permanent】 
regex 是正则表达式
replacement 是替换值，新值
flag -- 是处理标志
flag=【break/last/redirect/permanent/不写】：
1，/redirect/permanent，如果rewrite命中，发页面重定向，即是浏览器端重定向，地址会发生变化。区别在于分别是301/302重定向，对浏览器的记忆有区别。
2，break/last 服务器内部重定向，地址不变化。
break标记，停止执行后续命令。for（）{break}
last标记，会引发location重新匹配。for（）{continue;}，不要轻易使用last标签，容易引起死循环。
当有flag值的时候，rewrite层面的命令会中断。last会引发location重匹配
当没有flag值的时候，rewrite还会往下走，最后一个rewrite覆盖前面的。再引发location重匹配


12，跨域问题？
在请求一个域名时，这个域名又将请求转给了其他域名，这就是跨域。
产生原因：浏览器的自我保护机制，当浏览器在请求一个域名时，这个域名返回给浏览器信息，浏览器这时候就建立了一个保护机制识别了这个域名，当这个域名转发请求给另一个域名时，另一个域名将结果返回给浏览器，浏览器的自我保护机制无法识别另一个域名，所以就报错，这就是跨域问题的产生由来。
常见的跨域方案：
jsonp、 document.domain + iframe 跨域、Cors。
Cors：
即是在另一个域名被请求的时候，在另一个域名下设置一个白名单，只有在白名单内的域名的请求才能被通过，被通过就告诉浏览器放心，这时候浏览器的保护机制就能识别了。
	if ($http_origin ~ http://(.*).enjoy.com){
	    set $allow_url $http_origin;
	}
  	 #是否允许请求带有验证信息
	 add_header Access-Control-Allow-Credentials true;
	 #允许跨域访问的域名,可以是一个域的列表，也可以是通配符*
	 add_header Access-Control-Allow-Origin  $allow_url;
	 #允许脚本访问的返回头
	 add_header Access-Control-Allow-Headers 'x-requested-with,content-type,Cache-Control,Pragma,Date,x-timestamp';
	 #允许使用的请求方法，以逗号隔开
	 add_header Access-Control-Allow-Methods 'POST,GET,OPTIONS,PUT,DELETE';
	 #允许自定义的头部，以逗号隔开,大小写不敏感
	 add_header Access-Control-Expose-Headers 'WWW-Authenticate,Server-Authorization';
	 #P3P支持跨域cookie操作
	 add_header P3P 'policyref="/w3c/p3p.xml", CP="NOI DSP PSAa OUR BUS IND ONL UNI COM NAV INT LOC"';
	 add_header test  1;

	 if ($request_method = 'OPTIONS') {
        return 204;
     }
注意：$http_origin即是浏览器跨域请求的时候携带的第一个域名。


13，在https中发送http请求的解决方案？
1，给每个http配置证书，转成https。
2，因为https请求http是跨域请求，所以可以：
	1，nginx中Cros跨域解决
	2，后台代码跨域解决


14，nginx高可用？
keepalived来解决，思想是lvs（即是vip，虚拟网关）。
keepalived的思路，由 2台服务器软件虚拟出来一台 虚拟网关vip，此vip由两台机器共同协商生成。当有一台机器宕机时，另一台机器一样能维持vip。这保证了，只要两台机器不同时宕机，vip就存在。
当主机器挂了之后，就会漫游到从机器，并且只有主备两台机器，不能有3台，并且nginx没有集群概念。
注意：正常开发中，一般这种方式不用，一般使用一个域名多IP的方式实现高可用。keepalived这种解决方式，也可以和其他方式使用，比如tomcat。


15，https的原理
	1，在nginx中根据私钥生成证书，配置证书（包含公钥）和私钥。
	2，浏览器发送请求到nginx，并且将nginx中的证书下载到浏览器。
	3，浏览器随机生成一个对称加密的秘钥，使用证书中的公钥和RSA算法对这个秘钥进行加密，得到一串密文，然后传给nginx。
	4，nginx拿到这个密文后也能够私钥解密就得到了这个对称加密的秘钥。
	5，浏览器使用这个对称秘钥对真正的业务数据进行加密，然后再传给nginx。
	6，nginx通过解密之后的对称秘钥对这个业务数据进行解密，得到业务数据。

	注意：
		因为传统的https加密的公钥是非常大的，所以如果使用公钥直接对业务数据加密，会非常消耗性能，所以，采取这种方式，先生成一个随机对称密码，然后对这个密码利用https的证书公钥加密，再服务器用私钥解密就得到这个对称密码，然后客户端真正的业务利用这个密码加密，速度就很快，服务端再通过这个密码解密就行了，这样既保证了安全性，也提高了性能。




---------------------------------------------------------------------------------------------------------------------------------------------------------------

五，mysql？

1,mysql性能的衡量指标？
三大指标：
	TPS：每秒传输事务处理的个数，这是指服务器每秒处理的事务数，支持事务处理的存储引擎是InooDB。
		算法：TPS=（事务提交数+事务回滚数）/运行时间
	QPS：每秒查询处理数，同时适用于MyISAM和InnoDB。
		算法：TPS=查询数/运行时间
	响应时间


2，mysqlslap测试windows系统下的数据库压测工具？
在mysql的bin目录下，执行测试语句例如：（参数含义见课件）
mysqlslap -uroot -proot --concurrency=50 --iterations 3 -a --auto-generate-sql-add-autoincrement --engine=innodb --number-of-queries=50

mysqlslap -uroot -proot --concurrency=1,50,100,200 --iterations=3 --number-char-cols=5 --number-int-cols=5 --auto-generate-sql --auto-generate-sql-add-autoincrement --engine=myisam,innodb --create-schema='test1' --debug-info

两种存储引擎比较：
mysqlslap -uroot -proot --concurrency=500 --iterations=3 --number-char-cols=5 --number-int-cols=5 --auto-generate-sql --auto-generate-sql-add-autoincrement --engine=myisam,innodb --create-schema='enjoytest1' --debug-info
内存信息：
system time:在内核态下花费的时间
user time:在用户态花费的时间
max resident size:占用的最大物理内存(驻留内存)
Non-physical pagefaults:直接通过回收脏页来解决IO读写而产生的缺页中断的次数
involuntary context switch:线程因为时间片到了或更高优先级的线程抢占导致的切换的次数
voluntary context switch:线程主动让出处理器导致的切换的次数，很可能是等待IO



3，mysql逻辑架构？
分为：
	连接层：
		根据IP,账号，密码进行认证操作，然后连接。
	服务层：
		1，当一次sql操作执行的时候，是在（sql interface中执行），会首先去找缓存中是否有，没有就先解析查询，再优化，再返回结果；有就直接返回缓存的结果。注意：缓存包括sql语句和sql结果，mysql默认开启缓存sql语句，默认不开启缓存sql语句的结果。
		优化过程是mysql在执行sql的时候，会自动的进行优化操作，比如：
		select * from xxx where 1==1就等价于select * from xxx，sql会自动的优化，不会去执行1==1的判断。
		show variables like '%query_cache_type%' ：显示缓存是否开启
		show variables like '%query_cache_size%' ：显示缓存大小
		SET GLOBAL query_cache_size = xxx ：设置缓存大小
	引擎层
		show ENGINES：显示当前数据库的存储引擎是否支持
	存储层



4，mysql的存储引擎？
MyISAM：
	创建的表之后，在mysql的data目录中，会生成三个对应的文件，分别是：xxx.frm，xxx.MYD，xxx.MYI三种类型，其中：
	frm：储存表结构，任何存储引擎都具备
	MYD：数据文件（MyISAM具备）
	MYI：索引文件，也叫非聚集索引（MyISAM具备）
	CHECK table xxx：检查某个表是否有错误
	REPAIR table xxx：修复某个表
	特点：
		1，表级锁，不支持行级锁，不适合高并发
		2，支持全文索引
		3，支持数据压缩
			命令：myisampack -b -f xxx.MYI
			例如：myisampack -b -f E:\cleaning\mysql5.6\mysql-5.6.36-winx64\data\mysqldemo\product_info.MYI，最后会解压源文件，生成一个OLD的新文件。
		4，不支持事务，当做gis（地图类的，空间类的）的时候，就必须使用，因为myisam包含空间函数。
		5，读操作很快
		6，支持主键，不支持外键
		7，只支持缓存索引，不缓存数据

InnoDB（mysql5.5之后默认）：
	show VARIABLES like 'innodb_file_per_table'：显示是独立表空间还是系统表空间。
		ON：独立表空间，创建的表会生成frm和ibd两个文件，其中ibd是存储了数据和索引的文件。
		OFF：系统表空间，创建的表只有frm，存储的数据和索引被放在了ibdataX系统文件中。
		5.6之前默认是系统表空间，5.6之后默认是独立表空间。
		独立表空间和系统表空间特点：
			1，系统表空间无法简单的收缩文件大小，会影响性能。
			2，独立表空间可以通过optimize table收缩系统文件，比如：optimize table xxx（收缩独立表数据和索引文件大小，当删除了一些数据之后，使用此命令收缩文件，可以节约空间以及提高性能）
			3，系统表空间会产生IO瓶颈。
			4，独立表空间可以同时向多个文件刷新数据。

			建议使用：独立表空间。
	特点：
		1，支持行级锁，并发程度更高（也支持表锁）
		2，支持事务
		3，支持主键，外键
		4，支持缓存数据和索引

CSV:
	数据以文本方式存储在文件中
	组成：
		.csv：文件存储内容
		.csm：存储表的元数据和表状态的数据量
		.frm：储存表结构，任何存储引擎都具备
	特点：
		1，所有列都不能为null
		2，不支持索引，不适合大表，不适合在线处理
		3，可以对数据文件直接编辑（文本内容），注意：新增数据结束要加上回车


Archive：
	以zlib对表数据进行压缩，磁盘I/O更少，数据存储在arz文件中
	特点：
		1，只支持insert和select
		2，只允许在自增ID列上加索引
		适用于日志和数据采集


Memory：
	特点：
		1，文件系统存储特点，也称为HEAP存储引擎，所以数据保存在内存中
		2，支持HASH索引和BTree索引
		3，所有字段都是固定长度，vachar（10）=char（10）
		4，不支持Blog和Text等大字段类型
		5，使用表级锁
		6，最大大小由max_heap_table_size决定
		临时表：create temporary xxx  注意：临时表是session会话级别的，memory表虽然也是存在内存中的，但是是mysql应用级别的
			1，超过限制的时候使用Myisam临时表
			2，没超过限制使用Memory表
	数据易丢失，所以要求数据可再生，适用于：
	1，缓存周期性聚合数据的结果表
	2，保存数据分析中产生的中间表
	3，hash索引用于查找或者是映射表（邮编和地区的对应表）
	show VARIABLES like 'max_heap_table_size'：显示存储空间大小


Federated：
	特点：
		1，可以远程连接其他mysql服务器
		2，本地不存储数据，数据全部放在远程服务器上
		3，本地需要保存表结构和远程服务器的连接信息
	使用场景：偶尔的统计分析和手工查询
	默认是禁止的，需要在mysql启动时增加federated启动参数。




5，锁？
表级锁：
	1，开销小，加锁快
	2，不会出现死锁
	3，锁的粒度大，发生锁冲突的概率最高，并发度最低
	使用场景：表级锁更适合查询，只有少量按照索引条件更新数据的应用，如OLAP系统
	注意：和行锁不一样的是，表锁的事务提交或者回滚是不能释放锁的，只能是unlock tables，才能释放锁。
	有两种模式：
		1，表共享读锁
			给表加上共享锁，语法：lock table 表名 read（这种不支持别名）  lock table 表名 as 别名 read（支持别名）
			加上读锁之后，在一个session中执行更新加锁的表的操作会失败，在不同session中执行更新加锁的表的操作会等待。
						  在一个session中执行更新和查询其他表的操作会失败，在不同session中执行更新和查询其他表的操作会成功。
		2，表独占写锁
			给表加上共享锁，语法：lock table 表名 write
			加上写锁之后，在一个session中执行更新和读取加锁的表的操作成功，在不同session中执行更新和查询加锁的表的操作会等				待。
						  在一个session中执行更新和查询其他表的操作会失败，在不同session中执行更新和查询其他表的操作会成功。

行级锁：
	1，开销大，加锁慢
	2，会出现死锁
	3，锁的粒度小，发生锁冲突的概率最低，并发度最高
	使用场景：只有大量按照索引条件并发更新少量数据的应用，同时又有并发查询的应用。比如OLTP（在线事务处理系统）
	需要先开启事务，然后锁表，再提交事务或者回滚，才能释放锁，或者是开启一个新事务的时候，也会释放表锁。
	读锁（共享锁）：
		语法：select * from 表名 where 条件 lock in share mode
		当一个事务对某几行上读锁之后，允许其他事务对这些行进行读操作，但不允许进行写操作，也不允许其他事务给这些行加排它锁，但可以加读锁。

	写锁（排它锁）：
		语法：select * from 表名 where 条件 for update 
		当一个事务对某几行上写锁之后，不允许其他事务写，但允许读，更不允许其他事务加任何锁。

	注意：
		1，两个事务不能锁同一个索引
		2，insert，update，delete会默认加上排它锁
		3，行锁必须有索引才能实现，否则会自动锁全表，就变成了表锁了

页面锁：
	1，开销和加锁时间介于表锁和行锁之间
	2，会出现死锁
	3，锁粒度在表锁和行锁之间，并发度一般


面试题：当一个并发量很高的系统，数据量也很大，需要给A表增加一个字段，怎么办？
解决：
	第一种：
	1，需要创建一个字段和A表一样的，并且增加这个新字段的B表。
	2，给A表设置一个触发器，然后将A表中的数据全部复制到B表中，并且触发器的条件设置成更新表数据的时候同步更新到B表。
	3，当复制完成后，给A表加上表锁，然后修改B表的名称为A表，同时删除之前的A表。

	第二种：
	使用工具pt-online-schema-change
	例如：
	perl E:\cleaning\pt-online-schema-change h=127.0.0.1,p=root,u=root,D=mysqldemo,t=test_numberic --alter "modify c4 varchar(15) not null default '' " --execute

pt-online-schema-change原理:
1、如果存在外键，根据alter-foreign-keys-method参数的值，检测外键相关的表，做相应设置的处理。
2、创建一个新的表，表结构为修改后的数据表，用于从源数据表向新表中导入数据。
3、创建触发器，用于记录从拷贝数据开始之后，对源数据表继续进行数据修改的操作记录下来，用于数据拷贝结束后，执行这些操作，保证数据不会丢失。
4、拷贝数据，从源数据表中拷贝数据到新表中。
5、修改外键相关的子表，根据修改后的数据，修改外键关联的子表。
6、rename源数据表为old表，把新表rename为源表名，并将old表删除。
7、删除触发器。



6,事务？
只有InnoDB支持事务。
数据库中执行事务涉及到很多方面，包括如何处理临界资源，如何加锁解锁等等。但是无论事务如何执行，都需要保证以下几个特性（ACID）：
原子性：所有的操作是一个逻辑单元，要么都提交成功，要么就都失败；
一致性：只有合法的数据被写入数据库，否则事务回滚到最初的状态；
隔离性：允许多个事务同时进行，而不会破坏数据的正确性和完整性；
持久性：事务结束后，已经提交的结果被固化保存。注意：数据持久性并不是数据库就能完全解决的。



悲观锁：在当前事务执行的时候，不允许其他事务的操作。
	悲观锁的几种实现：
	共享锁（读锁）
	排它锁（写锁）
	更新锁（写锁）
	锁包括行级锁和表级锁:
	行级锁:
		是一种排他锁，防止其他事务修改此行；在使用以下语句时，Oracle会自动应用行级锁.

	表级锁又分为5类：
	行共享 (ROW SHARE) – 禁止排他锁定表
	行排他(ROW EXCLUSIVE) – 禁止使用排他锁和共享锁
	共享锁(SHARE) - 锁定表，对记录只读不写，多个用户可以同时在同一个表上应用此锁
	共享行排他(SHARE ROW EXCLUSIVE) – 比共享锁更多的限制，禁止使用共享锁及更高的锁
	排他(EXCLUSIVE) – 限制最强的表锁，仅允许其他用户查询该表的行。禁止修改和锁定表。
	
乐观锁：在表中加时间戳或者版本的字段，在第一次查询的时候将这个字段记录下来，用于在事务结束提交之前比较，如果字段内容相同就提交事务。

如果不考虑事务隔离，会发生的三种情况：
脏读，不可重复读，幻读

四种事务的隔离级别：
Serializable（串行化）：可避免脏读，不可重复读，幻读
Repeatable read（可重复读其实就是读已提交，即是在同一事务中，多次查询同一数据不一样，因为在其他事务更新了这个数据，还未提交事务的时候查询的是之前的值，提交了之后读取了更新后的值，两次查询结果不一样）：可避免脏读，不可重复读
Read committed（读已提交，读取其他事务已经提交了的值）：可避免脏读
Read uncommitted（读未提交，读取其他事务更新了的值，就算没有提交事务也可以查询到）：什么都不能避免
事务级别越高，执行效率就越低。
mysql的默认隔离级别是可重复读。
show variables like '%tx_isolation%'：显示事务的隔离级别。
savepoint：回滚点，可以设置事务回滚到这个点。


脏读：事务A读取了事务B更新的数据，然后B回滚，A就读取了脏数据。
不可重复读：事务A多次读取同一数据，事务B在事务A读取过程中，修改了这个数据，并且提交事务，这个时候事务A就读取了修改后的数据，导致事务A多次读取的数据不一致。
幻读：事务A将数据库的成绩字段由具体分数改为了ABCD等级，但是这个时候事务B又提交了一条之前的显示具体分数的记录，事务A修改完了之后发现了这条记录，就发现是一条以前的数据，感觉像幻觉一样，就是幻读。

注意：不可重复读和幻读容易混淆，不可重复读侧重于修改，幻读侧重于新增或者删除，解决不可重复读的问题只需要锁住满足条件的行，解决幻读需要锁表。
事务级别是可重复读的时候，如果有索引（包括主键索引）的时候，以索引列为条件更新数据，会存在间隙锁间，行锁，页锁的问题，从而锁住一些行，如果没有索引，更新数据就会锁住整个表。
所以，当没有索引的时候，会出现行锁升级为表锁的情况。

7种事务传播行为：（最常用的两种）
1、PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。
2、PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。

在spring中配置事务：
1，配置事务源，绑定数据源
2，开启事务源的注解驱动
3，设置事务源的传播行为
4，设置切面，设置被代理的目标类是否为类或者接口以确定aop的实现方式，指定事务源为切点



7，数据库范式和反范式？
范式：
第一范式：表中的字段是单一属性。
第二范式：表中只具有一个业务主键，也就是说符合第二范式的表不能存在非主键列只对部分主键的依赖关系。
第三范式：每一个非非主属性既不部分依赖于也不传递依赖于业务主键，也就是在第二范式的基础上相处了非主键对主键的传递依赖。
优点：
  可以尽量得减少数据冗余
  范式化的更新操作比反范式化更快
  范式化的表通常比反范式化的表更小
缺点：
   对于查询需要对多个表进行关联
   更难进行索引优化 


反范式：
反范式化是针对范式化而言得，所谓得反范式化就是为了性能和读取效率得考虑而适当得对数据库设计范式得要求进行违反，允许存在少量得冗余，换句话来说反范式化就是使用空间来换取时间。
优点：
 可以减少表的关联
 可以更好的进行索引优化
缺点：
  存在数据冗余及数据维护异常
  对数据的修改需要更多的成本


8，字段设计？
当一个列可以选择多种数据类型时：
优先考虑数字类型
其次是日期、时间类型
最后是字符类型
对于相同级别的数据类型，应该优先选择占用空间小的数据类型

浮点类型：
FlOAT：4个字节，不是精确类型
DOUBLE：8个字节，不是精确类型
DECIMAL：每4个字节存9个数字，小数点占1个字节，是精确类型（设计财务类的字段时候，优先考虑）

时间类型：
datetime在5.5及其以前是8个字节，5.6以后是5个字节，timestamp是4个字节。
timestamp和时区有关，而datetime无关，所以优先使用timestamp。
注意：timestamp因为本质存的是int类型的时间戳，所有有大小区间，默认是从1970开始到2037年结束，超过就存不了了。


9，慢查询？
慢查询日志：顾名思义，就是查询慢的日志，是指mysql记录所有执行超过long_query_time参数设定的时间阈值的SQL语句的日志。该日志能为SQL语句的优化带来很好的帮助。默认情况下，慢查询日志是关闭的，要使用慢查询日志功能，首先要开启慢查询日志功能。
常用配置：
slow_query_log 启动停止技术慢查询日志
slow_query_log_file 指定慢查询日志得存储路径及文件（默认和数据文件放一起）
long_query_time 指定记录慢查询日志SQL执行时间得伐值（单位：秒，默认10秒）
log_queries_not_using_indexes  是否记录未使用索引的SQL
log_output 日志存放的地方【TABLE】【FILE】【FILE,TABLE】，默认是存放在文件中。（注意：在开发中，不要设置为TABLE）


记录符合条件得SQL：
查询语句
数据修改语句
已经回滚得SQL  

show VARIABLES like 'slow_query_log'：显示数据库是否启动慢查询日志（默认关闭）。
set GLOBAL slow_query_log = 1：启动慢查询日志。
set GLOBAL long_query_time = 1：设置慢查询阈值为1S。


10，慢查询工具？
1，mysqldumpslow
作用：汇总除查询条件外其他完全相同的SQL，并将分析结果按照参数中所指定的顺序输出。
语法：
  mysqldumpslow -s r -t 10 slow-mysql.log
  -s order (c,t,l,r,at,al,ar) 
     c:总次数
     t:总时间
     l:锁的时间
     r:总数据行
     at,al,ar  :t,l,r平均数  【例如：at = 总时间/总次数】
  -t  top   指定取前面几天作为结果输出
例如：mysqldumpslow.pl -s t -t 10 E:\cleaning\mysql5.6\mysql-5.6.36-winx64\data\SWNMOZSRILYL6H0-slow.log  （打印本地mysql慢查询日志中的前十条信息）
缺点：必须要有登录mysql的权限才可以使用。


2，pt_query_digest
可以更显示更详细的慢sql日志信息，比如执行计划等，并且可以远程连接其他数据库。
例如：perl .\pt-query-digest  --explain h=127.0.0.1,u=root,p=root E:\cleaning\mysql5.6\mysql-5.6.36-winx64\data\SWNMOZSRILYL6H0-slow.log



11，索引？
MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。
可以得到索引的本质：索引是数据结构。
索引的实现的数据结构是：树，mysql默认存储引擎innodb只显式支持B-Tree( 从技术上来说是B+Tree)索引。
B+树索引是B+树在数据库中的一种实现，是最常见也是数据库中使用最为频繁的一种索引。
分类：
普通索引：即一个索引只包含单个列，一个表可以有多个单列索引
唯一索引：索引列的值必须唯一，但允许有空值
复合索引：即一个索引包含多个列
聚簇索引(聚集索引)：并不是一种单独的索引类型，而是一种数据存储方式。具体细节取决于不同的实现，InnoDB的聚簇索引其实就是在同一个结构中保存了B-Tree索引(技术上来说是B+Tree)和数据行。
非聚簇索引：不是聚簇索引，就是非聚簇索引
查看索引：
SHOW INDEX FROM table_name
创建索引：
CREATE  [UNIQUE ] INDEX indexName ON mytable(columnname(length));
ALTER TABLE 表名 ADD  [UNIQUE ]  INDEX [indexName] ON (columnname(length)) 
删除索引：
DROP INDEX [indexName] ON mytable;
关于建立索引的几个准则：
1、合理的建立索引能够加速数据读取效率，不合理的建立索引反而会拖慢数据库的响应速度。
2、索引越多，更新数据的速度越慢。
3、不要在选择的栏位上放置索引，这是无意义的。应该在条件选择的语句上合理的放置索引，比如where，order by。
4、把最常用的，筛选数据最多的字段放在左侧。
5、单个索引需要注意的事项，组合索引全部通用。比如索引列不要参与计算啊、or的两侧要么都索引列，要么都不是索引列啊、模糊匹配的时候%不要在头部啦等等。
6、最左匹配原则。(A,B,C) 这样3列，mysql会首先匹配A，然后再B，C，如果用(B,C)这样的数据来检索的话，就会找不到A使得索引失效。如果使用(A,C)这样的数据来检索的话，就会先找到所有A的值然后匹配C，此时联合索引是失效的。
适合建索引的条件：
1，某个字段相对唯一
2，经常用来查询显示的列
3，作为条件或者是关联条件的列


12,数据库的横向分表和纵向分表？
主库：
对于经常变化处理的数据和新数据，在主库中处理。
从库：
对于不经常变化，只是查询的一些旧数据，在从库中处理。

横向分表：
将一个数据量很大的表，将其中的数据分割到其他相同结构的分表中去，再利用算法在查询的时候，查询具体的表数据。

纵向分表：
分析表的结构字段，例如创建时间，作者，标题这样的不经常变化的数据，称为冷数据，这样的数据存储在从库中，而对于经常变化的数据称为活跃数据，如浏览量等，这些数据存储在主库中，
利用横向分表的形式分表处理。对于冷数据存储引擎用Myisam，查询速度快，对于活跃数据存储引擎用Inoodb，更新速度快。


13,数据库n+1问题？
1+n是执行一次查询获取n条主数据后，由于关联引起的执行n次查询从数据,它带来了性能问题；
一般来说，通过懒加载可以部分缓解1+n带来的性能问题




算法的时间复杂度：
算法的时间复杂度是一个函数，它定性描述了该算法的运行时间，时间复杂度越大，算法运行效率越低。
计算方法：
	算法时间复杂度，是根据算法中每行代码运行的次数，累加起来，再根据具体的规则简化等式得到结果。
	比如：
		1,int main()
		{
		    int i, j, x = 0, sum = 0, n = 100;	/* 执行1次 */
		    for( i = 1; i <= n; i++)
		    {
		        sum = sum + i;
		        //printf("%d \n", sum);  /* 执行n次 */
		        for( j = 1; j <= n; j++)
		        {
		            x++;                /* 执行n*n次 */
		            sum = sum + x;
		        }
		    }
		    printf("%d", sum);			/* 执行1次 */
		}

		执行总次数 = 1 + (n + 1) + n*(n + 1) + n*n + (n + 1) + 1 = 2n^2 + 3n + 3
		推导方法：
			1，用常数1取代运行时间中的所有加法常数。
			2，在修改后的运行次数函数中，只保留最髙阶项。
			3，如果最高阶项存在且不是1,则去除与这个项相乘的常数。
		得到时间复杂度是：O（2n^2）

		2,for(int j=1; j<=n; j*=2)
			2^j = n ，j = log2n（2为底数），所以时间复杂度是O(log2n)

		3,for(int j=1; j<=n/2; j*=2)
			2^j =n /2, j=log2n-1,j=log2n，所以时间复杂度是O(log2n)

常见的算法时间复杂度由小到大依次为：
　　Ο(1)＜Ο(log2n)＜Ο(n)＜Ο(nlog2n)＜Ο(n2)＜Ο(n3)＜…＜Ο(2n)＜Ο(n!)



二叉树：
二叉树具有以下性质：左子树的键值小于根的键值，右子树的键值大于根的键值。 对该二叉树的节点进行查找发现深度为1的节点的查找次数为1，深度为2的查找次数为2，深度为n的节点的查找次数为n，因此其平均查找次数为(1+2+2+3+3+3)/6=2.3次。二叉查找树可以任意地构造，但是如果不是平衡构造，就会造成查找效率低的问题，所以若想二叉树的查询效率尽可能高，需要这棵二叉树是平衡的，从而引出新的定义——平衡二叉树，或称AVL树。


平衡二叉树（AVL Tree）：
平衡二叉树（AVL树）在符合二叉查找树的条件下，还满足任何节点的两个子树的高度最大差为1。如果在AVL树中进行插入或删除节点，可能导致AVL树失去平衡。


红黑树：
红黑树是一种近似平衡的二叉查找树，它能够确保任何一个节点的左右子树的高度差不会超过二者中较低那个的一倍。
红黑树是满足如下条件的二叉查找树（binary search tree）：
1，每个节点要么是红色，要么是黑色。
2，根节点必须是黑色
3，红色节点不能连续（也即是，红色节点的孩子和父亲都不能是红色）。
4，每个叶节点（NIL或空节点）是黑色； 
5，对于每个节点，从该点至null（树尾端）的任何路径，都含有相同个数的黑色节点。
旋转（左旋，右旋）：
旋转的目的是将节点多的一支出让节点给另一个节点少的一支，旋转操作在插入和删除操作中经常会用到，用于平衡树。红黑树能够以O(log2(N))的时间复杂度进行搜索、插入、删除操作。此外,任何不平衡都会在3次旋转之内解决。还可以解决hash碰撞。


平衡多路查找树（B-Tree）：
B-Tree是为磁盘等外存储设备设计的一种平衡查找树。
系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。InnoDB存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB存储引擎中默认每个页的大小为16KB，可通过参数innodb_page_size将页的大小设置为4K、8K、16K，而系统一个磁盘块的存储空间往往没有这么大，因此InnoDB每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小16KB。InnoDB在把磁盘数据读入到内存时会以页为基本单位，在查询数据如果在一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘I/O次数，提高查询效率。B-Tree结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述B-Tree，首先定义一条记录为一个二元数组[key, data] ，key为记录的键值，对应表中的主键值，data为一行记录中除主键外的数据。对于不同的记录，key值互不相同。


磁盘IO与预读：
磁盘读取依靠的是机械运动，分为寻道时间、旋转延迟、传输时间三个部分，这三个部分耗时相加就是一次磁盘IO的时间，大概9ms左右。这个成本是访问内存的十万倍左右；正是由于磁盘IO是非常昂贵的操作，所以计算机操作系统对此做了优化：预读；每一次IO时，不仅仅把当前磁盘地址的数据加载到内存，同时也把相邻数据也加载到内存缓冲区中。因为局部预读原理说明：当访问一个地址数据的时候，与其相邻的数据很快也会被访问到。每次磁盘IO读取的数据我们称之为一页（page）。一页的大小与操作系统有关，一般为4k或者8k。这也就意味着读取一页内数据的时候，实际上发生了一次磁盘IO。


B-Tree与二叉查找树的对比：
我们知道二叉查找树查询的时间复杂度是O（logN），查找速度最快和比较次数最少，既然性能已经如此优秀，但为什么实现索引是使用B-Tree而不是二叉查找树，关键因素是磁盘IO的次数。
数据库索引是存储在磁盘上，当表中的数据量比较大时，索引的大小也跟着增长，达到几个G甚至更多。当我们利用索引进行查询的时候，不可能把索引全部加载到内存中，只能逐一加载每个磁盘页，这里的磁盘页就对应索引树的节点。
总结：减少磁盘IO的次数就必须要压缩树的高度，让瘦高的树尽量变成矮胖的树，所以B-Tree就在这样伟大的时代背景下诞生了。


B+Tree：
B+Tree是在B-Tree基础上的一种优化，使其更适合实现外存储索引结构，InnoDB存储引擎就是用B+Tree实现其索引结构。B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，每一个节点可以存多个key值，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。
B+Tree相对于B-Tree有几点不同：
1.	非叶子节点只存储键值信息。
2.	所有叶子节点之间都有一个链指针（链表）。
3.	数据记录都存放在叶子节点中。
MyISAM的索引方式也叫做“非聚集”的索引（索引，表结构，数据分成三个文件存放的），InnoDB为聚集索引（索引和数据存放在一个文件里面，表结构存放在一个文件里面）。
注意：虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。
第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。


12，执行计划？
使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的，分析你的查询语句或是表结构的性能瓶颈。

语法：
   Explain + SQL语句

执行计划的作用？
1，表的读取顺序
2，数据读取操作的操作类型
3，哪些索引可以使用
4，哪些索引被实际使用
5，表之间的引用
6，每张表有多少行被优化器查询


ID列：描述select查询的序列号,包含一组数字，表示查询中执行select子句或操作表的顺序
根据ID的数值结果可以分成一下三种情况：
	id相同：执行顺序由上至下
	id不同：如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行
	id相同不同：同时存在



执行计划-select_type：
1，SIMPLE：简单的 select 查询,查询中不包含子查询或者UNION

2，PRIMARY：查询中若包含任何复杂的子部分，最外层查询则被标记为PRIMARY
3，SUBQUERY：在SELECT或WHERE列表中包含了子查询
	例如：select t1.*,(select t2.id from t2 where t2.id = 1 ) from t1 

4，DERIVED：在FROM列表中包含的子查询被标记为DERIVED(衍生)MySQL会递归执行这些子查询, 把结果放在临时表里。
例如：select t1.* from t1 ,(select t2.* from t2 where t2.id = 1 ) s2  where t1.id = s2.id

5，UNION：若第二个SELECT出现在UNION之后，则被标记为UNION；若UNION包含在FROM子句的子查询中,外层SELECT将被标记为：DERIVED
6，UNION RESULT：从UNION表获取结果的SELECT
	例如：select * from t1 UNION select * from t2


执行计划-type：
type显示的是访问类型，是较为重要的一个指标，结果值从最好到最坏依次是：
system>const>eq_ref>ref>range>index>ALL
一般至少要达到range级别。
System：表只有一行记录（等于系统表），这是const类型的特列，平时不会出现，这个也可以忽略不计
Const：表示通过索引一次就找到了
eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描
例如： SELECT * from t1,t2 where t1.id = t2.id
Ref :非唯一性索引扫描，返回匹配某个单独值的所有行.
Range：只检索给定范围的行,使用一个索引来选择行。key 列显示使用了哪个索引，一般就是在你的where语句中出现了between、<、>、in等的查询，这种范围扫描索引扫描比全表扫描要好，因为它只需要开始于索引的某一点，而结束语另一点，不用扫描全部索引。
Index：当查询的结果全为索引列的时候，虽然也是全部扫描，但是只查询的索引库，而没有去查询数据。
All：将遍历全表以找到匹配的行。


执行计划-key：
实际使用的索引。如果为NULL，则没有使用索引。

执行计划-possible_keys：
可能使用的key。
注意：查询中若使用了覆盖索引，则该索引和查询的select字段重叠。


执行计划-key_len：
表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。在不损失精确性的情况下，长度越短越好。
key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的。
注意：
	1，key_len表示索引使用的字节数，
	2，根据这个值，就可以判断索引使用情况，特别是在组合索引的时候，判断所有的索引字段是否都被查询用到。
	3，char和varchar跟字符编码也有密切的联系,
	4，latin1占用1个字节，gbk占用2个字节，utf8占用3个字节。（不同字符编码占用的存储空间不同），datetime在5.5以及之前是8个字		  节，在5.6以后是5个字节。


执行计划-ref：
显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引列上的值。


执行计划-rows：
根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数。


执行计划-Extra：
包含不适合在其他列中显示但十分重要的额外信息。
Using filesort ：说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取，MySQL中无法利用索引完成的排序操作称为“文件排序”。
Using temporary ：使了用临时表保存中间结果,MySQL在对查询结果排序时使用临时表。常见于排序 order by 和分组查询 group by。
USING index：是否用了覆盖索引。
Using where：表明使用了where过滤。
Using join buffer：使用了连接缓存：。
Impossible where：where子句的值总是false，不能用来获取任何元组。

覆盖索引（Covering Index）：
理解方式一:就是select的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件,换句话说查询列要被所建的索引覆盖。
理解方式二:索引是高效找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行。毕竟索引叶子节点存储了它们索引的数据;当能通过读取索引就可以得到想要的数据，那就不需要读取行了。一个索引包含了(或覆盖了)满足查询结果的数据就叫做覆盖索引。
注意：
如果要使用覆盖索引，一定要注意select列表中只取出需要的列，不可select*，因为如果将所有字段一起做索引会导致索引文件过大，查询性能下降。




13，优化？
1，如果有索引，在where条件后面尽量将所有索引都加上。
2，最佳左前缀法则：开火车的例子，索引顺序不影响，优化器会自动匹配。
3，不在索引列上做任何操作（计算、函数、(自动or手动)类型转换），会导致索引失效而转向全表扫描
4，范围条件放最后，因为在索引上使用了范围查询之后（比如大于，小于），本身不会失效（覆盖索引除外），其之后的索引会失效，所有放最后。
5，覆盖索引尽量用，非常重要，不要使用select *
6，不等于要慎用，会导致索引失效，但是如果使用了覆盖索引，就不会失效
7，设计表字段的时候，null/not null对索引的可能影响，如果是设计的not null，索引使用is not null不会失效，使用is null会失效，但是加上覆盖索引就可以生效，设计字段为null，同理。
8，like以通配符开头('%abc...')mysql索引失效会变成全表扫描的操作，加上覆盖索引可以生效
9，OR索引会失效，改UNION效率高可以使用索引，也可以加上覆盖索引生效
10，字符串要加引号索引生效，也可以加上覆盖索引生效
11，order by（索引+非索引）非失效，并且使用Myisam的时候，查询的列有其他字段，索引也会失效，Innodb不会。


14，大量数据的批量导入数据库？
java程序实现：
	1，将事务自动提交关闭
	2，将数据库表改成Myisam
	3，将一行行的例如：insert XXX value（x,x），拼接成insert XXX value（x,x）,（x,x）....执行，这样就相当于减少了行级锁。
	4，提交事务

使用LOAD DATA INFLIE（这种速度最快）：
	1，select * into OUTFILE 'D:\\xxx.txt' from xxx：将表中的结果和数据复制到指定路径下的文件中
	2，load data INFILE 'D:\\xxx.txt' into table xxx：将文件中的数据导入到表中



15，总结？
1，redo和undo的区别？
为了满足事务的持久性，防止buffer pool数据丢失，innodb引入了redo log。为了满足事务的原子性，innodb引入了undo log。
redo和undo是两种不同的innodb事务实现机制，它们都需要用到ib_logfile日志文件；
redo：是先记录操作日志，虽然记录操作日志也是应用了缓存（innodb_log_buffer）但是它还是在数据更新之前，更新redo日志到磁盘日志文件中，数据的更新会在后面的线程刷新操作过程中被更新，redo操作事务提交后，只有日志被持久化，数据暂时未被持久化（如果数据还未持久化的时候，系统崩溃了，这样可以根据redo日志，去恢复数据），保证了持久性。
undo:undo操作也使用了缓存，只是它在事务提交的时候会同时将数据和日志更新到磁盘，这步操作就是和redo的主要区别，并且该操作对磁盘IO的消耗非常大，所以undo操作保证了事务的原子性，事务一旦提交，日志和数据都被持久化了。


2，hash索引是什么？什么存储引擎支持？有什么优缺点？
哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。
缺点：
（1）Hash 索引仅仅能满足"=","IN"和"<=>"查询，不能使用范围查询。

（2）Hash 索引无法被用来避免数据的排序操作。

（3）Hash 索引不能利用部分索引键查询。

（4）Hash 索引在任何时候都不能避免表扫描。

（5）Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。

注意：只有HEAP/MEMORY两个存储引擎支持。


3，b-tree和b+tree的区别？对于检索范围来说，b+tree好在哪里？
1. B+树中只有叶子节点会带有指向记录的指针（ROWID），而B树则所有节点都带有，在内部节点出现的索引项不会再出现在叶子节点中。
2. B+树中所有叶子节点都是通过指针连接在一起，而B树不会。

B+树的优点：
1，非叶子节点不会带上ROWID，这样，一个块中可以容纳更多的索引项，一是可以降低树的高度。二是一个内部节点可以定位更多的叶子节点。
2，叶子节点之间通过指针来连接，范围扫描将十分简单，而对于B树来说，则需要在叶子节点和内部节点不停的往返移动。


4，全文索引是什么？
全文索引是为了使得“关键词搜索”功能更加的高效能，就是将搜索关键单独建立一个索引文件，对应具体的数据。
工作原理：
1、索引程序从数据库读取数据，比如索引程序通过sql语句：select 文章id,文章标题，文章内容 from 文章表.获得文章的相关数据。
2、索引程序对需要索引的内容进行“分词”，而这里的分词就是调用分词程序。
3、索引程序对分好词的一个个词条加入索引文件。
mysql现在一般使用的版本其实也支持全文索引啦，索引类型为fulltext，对中文的支持不够好，无法智能分词。


5，mysql中的间隙锁？产生间隙锁几种方式？
间隙锁（Gap Lock）：锁加在不存在的空闲空间，可以是两个索引记录之间，也可能是第一个索引记录之前或最后一个索引之后的空间。
间隙锁在InnoDB的唯一作用就是防止其它事务的插入操作，以此来达到防止幻读的发生，所以间隙锁不分什么共享锁与排它锁。

间隙锁的出现主要集中在同一个事务中先delete后 insert的情况下， 当我们通过一个参数去删除一条记录的时候， 
如果参数在数据库中存在，那么这个时候产生的是普通行锁，锁住这个记录， 然后删除， 然后释放锁。如果这条记录不存在，
问题就来了， 数据库会扫描索引，发现这个记录不存在， 这个时候的delete语句获取到的就是一个间隙锁，
然后数据库会向左扫描扫到第一个比给定参数小的值，向右扫描扫描到第一个比给定参数大的值， 然后以此为界，
构建一个区间， 锁住整个区间内的数据， 一个特别容易出现死锁的间隙锁诞生了，当间隙锁产生后，在高并发的情况下可能会出现，死锁的情况，即是假如根据id=6删除，6不存在，就会在6的前后产生间隙锁，锁住了之后，在删除语句还未提交的时候，其他增加id=6的操作就不能执行，产生了死锁，这样只有修改逻辑了，不要去删除不存在的数据。


6，执行计划的type中的ref和index的区别？
ref：是表示使用到了索引。
index：表示使用到了索引，但是寻找索引是扫描整个索引表的，效率要比ref低。


7，drop truncate delete区别？
1、在速度上，一般来说，drop> truncate > delete。
2、在使用drop和truncate时一定要注意，虽然可以恢复，但为了减少麻烦，还是要慎重。
3、如果想删除部分数据用delete，注意带上where子句，回滚段要足够大；
   如果想删除表，当然用drop； 
   如果想保留表而将所有数据删除，如果和事务无关，用truncate即可；
   如果和事务有关，或者想触发trigger，还是用delete；
   如果是整理表内部的碎片，可以用truncate跟上reuse stroage，再重新导入/插入数据。




---------------------------------------------------------------------------------------------------------------------------------------------------------------


六，tomcat？

1，tomcat的核心？
Connector和Container。
1、Connector用于处理连接相关的事情，并提供Socket与Request和Response相关的转化; 2、Container用于封装和管理Servlet，以及具体处理Request请求；
一个Tomcat中只有一个Server，一个Server可以包含多个Service，一个Service只有一个Container，但是可以有多个Connectors，这是因为一个服务可以有多个连接，如同时提供Http和Https链接，也可以提供向相同协议不同端口的连接。

一个请求发送到Tomcat之后，首先经过Service然后会交给我们的Connector，Connector用于接收请求并将接收的请求封装为Request和Response来具体处理，Request和Response封装完之后再交由Container进行处理，Container处理完请求之后再返回给Connector，最后在由Connector通过Socket将处理的结果返回给客户端，这样整个请求的就处理完了！
Connector最底层使用的是Socket来进行连接的，Request和Response是按照HTTP协议来封装的，所以Connector同时需要实现TCP/IP协议和HTTP协议！


2，tomcat顶层架构小结：
（1）Tomcat中只有一个Server，一个Server可以有多个Service，一个Service可以有多个Connector和一个Container； 
（2）Server掌管着整个Tomcat的生死大权； 
（4）Service 是对外提供服务的； 
（5）Connector用于接受请求并将请求封装成Request和Response来具体处理； 
（6）Container用于封装和管理Servlet，以及具体处理request请求；


3，Connector？
Connector就是使用ProtocolHandler来处理请求的，不同的ProtocolHandler代表不同的连接类型，比如：Http11Protocol使用的是普通Socket来连接的，Http11NioProtocol使用的是NioSocket来连接的。
其中ProtocolHandler由包含了三个部件：Endpoint、Processor、Adapter。
（1）Endpoint用来处理底层Socket的网络连接，Processor用于将Endpoint接收到的Socket封装成Request，Adapter用于将Request交给Container进行具体的处理。
（2）Endpoint由于是处理底层的Socket网络连接，因此Endpoint是用来实现TCP/IP协议的，而Processor用来实现HTTP协议的，Adapter将请求适配到Servlet容器进行具体的处理。
（3）Endpoint的抽象实现AbstractEndpoint里面定义的Acceptor和AsyncTimeout两个内部类和一个Handler接口。Acceptor用于监听请求，AsyncTimeout用于检查异步Request的超时，Handler用于处理接收到的Socket，在内部调用Processor进行处理。


4，启动流程？
1，创建Bootstrap启动类实例，并做一些初始化工作，初始化类加载器和创建Catalina实例，然后再启动Catalina线程。Catalina实例执行start方法。这里有两个点，一个是load()加载server.xml配置、初始化Server的过程，一个是getServer().start()开启服务、初始化并开启一系列组件、子容器的过程。load方法解析server.xml配置文件，并加载Server、Service、Connector、Container、Engine、Host、Context、Wrapper一系列的容器。加载完成后，调用getServer().start()来开启一个新的Server。首先利用Digester类解析server.xml文件，得到容器的配置，并创建相应的对象，并关联父子容器。依次创建的是StandardServer、StandardService、StandardEngine、StandardHost。
然后拿到StandardServer实例调用init()方法初始化Tomcat容器的一系列组件。一些容器初始化的的时候，都会调用其子容器的init()方法，初始化它的子容器。顺序是StandardServer、StandardService、StandardEngine、Connector。每个容器都在初始化自身相关设置的同时，将子容器初始化。

这里插入一个Tomcat中生命周期的概念。在初始化、开启一系列组件、容器的过程中，由tomcat'管理的组件和容器，都有一个共同的特点，都实现了org.apache.catalina.Lifecycle接口，由Tomcat管理其生命周期。Lifecycle提供一种统一的管理对象生命周期的接口。通过Lifecycle、LifecycleListener、LifecycleEvent，Catalina实现了对tomcat各种组件、容器统一的启动和停止的方式。
在Tomcat服务开启过程中启动的一些列组件、容器，都继承了org.apache.catalina.util.LifecycleBase这个抽象类，其中的init()、start() 方法、stop() 方法，为其子类实现了统一的start和stop管理。方法中具体的initInternal()、startInternal() 和stopInternal方法，交由子类自己实现。
init()和start()方法里，调用了initInternal()方法、startInternal()方法和stop()方法，这三者最终会走子类的具体实现。
上面的StandardServer的初始化过程就是一个活生生的例子。在Catalina的load过程中，getServer().init()方法就是LifecycleBase中的init()方法，调用initInternal()时是走的StandardServer的实现，StandardServer的initInternal()中会调用StandardServer的init()方法，进行子容器的初始化。然后依次初始化。

总结一下启动的Tomcat启动的过程：
在Catalina的load方法里，就已经调用了StandardServer里的init方法，一层一层初始化了globalNamingResources，StandardService--》StandardEngine，executors，MapperListener，Connector--》CoyoteAdapter，protocolHandler。至此就将tomcat的catalina中的组件、容器初始化完成。 接下来就是调用start方法一层一层开启，StandardServer的startInternal方法，按层次start：globalNamingResources，StandardService--》StandardEngine，executors，MapperListener，Connector--》StandardHost，StandardContext，protocolHandler。顺序基本同init过程。StandardEngine在start时，会init子容器，并调用子容器的start方法。子容器依次这样init、start，就开启了StandardHost和StandardContext。


2，Bootstrap的初始化init方法：
1，先初始化类加载器（commonLoader，catalinaLoader，sharedLoader）。
2，给当前线程设置特定的类加载器catalinaLoader。
3，向SecurityClassLoad安全机制的类加载器中添加catalinaLoader类加载器。
4，初始化Catalina启动类，并根据构造函数startupClass.getConstructor().newInstance()创建Catalina启动类。
5，设置启动参数。

Bootstrap的初始化load方法（加载参数）。

3，Bootstrap的demon.start()方法就会调用Catalina的start方法。




5，责任链模式？
职责链模式，就是很多对象有每个对象对其下家的引用而连接起来形成一条链，请求在这条链上传递，直到链上的某个对象处理此请求，或者每个对象都可以处理请求，并传给下一家，直到最终链 上每个对象都处理完。这样可以不影响客户端而能够在链上增加任 意的处理节点。
在tomcat中这种设计模式几乎被完整的使用，tomcat的容器设置就是职责链模式，从 Engine 到 Host再到 Context一直到 Wrapper 都是通过一个链传递请求。


6，模板方法模式？
Tomcat在启动的过程中主要的两个方法init()和start()，这里我们以start()为例，LifecycleBase类中的start()方法，会调用startInternal()，这个方法是一个抽象方法需要子类去实现，所以子类需要实现这个特定的开启方法，最终调用的start方法，其他固定的步骤一致，同时也会执行子类实现的特定的开启。

7，tomcat调错？
当tomcat启动异常的时候，一般情况是去logs目录下，查看cetalina.log日志信息，找异常。如果是在运行过程中发生的异常，是放在localhost.log中。


8，嵌入式Tomcat？
非传统的部署方式，将Tomcat嵌入到主程序中进行运行。
优点：
灵活部署、任意指定位置、通过复杂的条件判断。比如，springboot中内嵌的tomcat。
Tomcat类:Tomcat类是外部调用的入口
1.位置：org.apache.catalina.startup.Tomcat
2.该类是public的。
3.该类有Server、Service、Engine、Connector、Host等属性。
4.该类有init()、start()、stop()、destroy()等方法。

9，springboot中内嵌tomcat源码？
在@SpringBootApplication中@EnableAutoConfiguration，默认开启了tomcat配置，在EmbeddedServletContainerAutoConfiguration中有一个内部类EmbeddedTomcat就是嵌入式tomcat的启动入口，根据调用Tomcat类实现的嵌入式启动。

10，Maven集成Tomcat插件启动分析？
Tomcat7RunnerCli是引导类，Tomcat7RunnerCli主要依靠Tomcat7Runner，Tomcat7Runner调用Tomcat类。

11，Tomcat有三种运营模式？
bio、nio、apr，不同模式下Tomcat的运行效率差别比较大。
apr（Apache Portable Runtime）：
从操作系统级别来解决异步的IO问题,大幅度的提高性能，必须要安装apr和native，直接启动就支持apr。



---------------------------------------------------------------------------------------------------------------------------------------------------------------




七，虚拟机？

1，hotspot虚拟机,？
hotspot采用的是热点代码探测技术，即是统计代码被执行次数较多的代码，编译成本地文件。


2，内存模型？
JRE（java运行时环境）：JRE是由Java API和JVM组成的。
JDK：(Java Development Kit 即 Java开发工具包)它是面向开发人员使用的SDK，提供了Java的开发环境和运行环境。所以JDK中包含了JRE和JAVA类库。
程序计数器：较小的内存空间，当前线程执行的字节码的行号指示器；各线程之间独立存储，互不影响；

java栈：线程私有，生命周期和线程，每个方法在执行的同时都会创建一个栈帧用于存储局部变量表，操作数栈，动态链接，方法出口等信息。方法的执行就对应着栈帧在虚拟机栈中入栈和出栈的过程；栈里面存放着各种基本数据类型和对象的引用（-Xss） ；

本地方法栈：本地方法栈保存的是native方法的信息，当一个JVM创建的线程调用native方法后，JVM不再为其在虚拟机栈中创建栈帧，JVM只是简单地动态链接并直接调用native方法；

堆：Java堆是Javaer需要重点关注的一块区域，因为涉及到内存的分配(new关键字，反射等)与回收(回收算法，收集器等) （-Xms；-Xmx；
-Xmn；-XX:NewSize；-XX:MaxNewSize） ；

方法区：也叫永久区，用于存储已经被虚拟机加载的类信息，常量("zdy","123"等)，静态变量(static变量)等数据（-XX:PermSize；- XX:MaxPermSize；-XX:MetaspaceSize； - XX:MaxMetaspaceSize ） 。永久代来存储类信息、常量、静态变量等数据不是个好主意,很容易遇到内存溢出的问题。对永久代进行调优是很困难的,同时将元空间与堆的垃圾回收进行了隔离，避免永久代引发的Full GC和OOM等问题；

运行时常量池：运行时常量池是方法区的一部分，用于存放编译期生成的各种字面量("zdy","123"等)和符号引用。

直接内存：直接内存不是虚拟机规范中定义的内存区域，也不是虚拟机运行时数据区域的一部分。属于堆外内存，也就是本机内存的一部分。
不是虚拟机运行时数据区的一部分，也不是java虚拟机规范中定义的内存区域；
如果使用了NIO,这块区域会被频繁使用，在java堆内可以用directByteBuffer对象直接引用并操作；
这块内存不受java堆大小限制，但受本机总内存的限制，可以通过MaxDirectMemorySize来设置（默认与堆内存最大值一样），所以也会出现OOM异常；

一个线程同一时刻只能执行一个方法，分配一个栈帧。



3，对象的访问定位,？
建立对象是为了使用对象，我们的Java程序需要通过栈上的reference（指针，引用）数据来操作堆上的具体对象。目前主流的访问方式有使用句柄和直接指针两种。
如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。
如果使用直接指针访问， reference中存储的直接就是对象地址。
这两种对象访问方式各有优势，使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改。
使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。
对Sun HotSpot而言，它是使用直接指针访问方式进行对象访问的。


4，调优参数？
-Xms：堆的最小值；
-Xmx：堆的最大值；
-Xmn：新生代的大小；
-XX:NewSize；新生代最小值；
-XX:MaxNewSize：新生代最大值；
用于存储已经被虚拟机加载的类信息，常量("zdy","123"等)，静态变量(static变量)等数据，可用以下参数调整：
jdk1.7及以前：-XX:PermSize；-XX:MaxPermSize；
jdk1.8以后：-XX:MetaspaceSize； -XX:MaxMetaspaceSize
jdk1.8以后大小就只受本机总内存的限制

对象不一定都在堆上分配对象。
栈上分配：虚拟机提供的一种优化技术，基本思想是，对于线程私有的对象，将它打散分配在栈上，而不分配在堆上。
逃逸分析：判断对象的作用域是否会逃逸出方法体。jdk1.8默认开启的。
堆溢出：
参数 ： -Xms5m -Xmx5m -XX:+PrintGC
出现java.lang.OutOfMemoryError: GC overhead limit exceeded  一般是（某个循环里可能性最大）在不停的分配对象，但是分配的太多，把堆撑爆了。
出现java.lang.OutOfMemoryError: Java heap space一般是分配了巨型对象。

栈溢出：
参数：-Xss256k
java.lang.StackOverflowError  一般的方法调用是很难出现的，如果出现了要考虑是否有无限递归。
虚拟机栈带给我们的启示：方法的执行因为要打包成栈桢，所以天生要比实现同样功能的循环慢，所以树的遍历算法中：递归和非递归(循环来实现)都有存在的意义。递归代码简洁，非递归代码复杂但是速度较快。

栈，本地方法栈，程序计数器都是随线程的销毁而销毁，只有堆和方法区是线程共享的，所以GC只发生堆和方法区（jdk1.8以后才会被GC）中。



5，对象的内存布局？
在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。
对象头包括两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。 
对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。
第三部分对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot VM的自动内存管理系统要求对对象的大小必须是8字节的整数倍。当对象其他数据部分没有对齐时，就需要通过对齐填充来补全。


6，对象的分配？
虚拟机遇到一条new指令时：
1）
先执行相应的类加载过程。
2）
接下来虚拟机将为新生对象分配内存。为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。
如果Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”。
如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”。
选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。
除如何划分可用空间之外，还有另外一个需要考虑的问题是对象创建在虚拟机中是非常频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。
解决这个问题有两种方案，一种是对分配内存空间的动作进行同步处理——实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性；
另一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块私有内存，也就是本地线程分配缓冲（Thread Local Allocation Buffer,TLAB），如果设置了虚拟机参数 -XX:+UseTLAB，在线程初始化时，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个Buffer，如果需要分配内存，就在自己的Buffer上分配，这样就不存在竞争的情况，可以大大提升分配效率，当Buffer容量不够的时候，再重新从Eden区域申请一块继续使用。
TLAB的目的是在为新对象分配内存空间时，让每个Java应用线程能在使用自己专属的分配指针来分配空间，减少同步开销。
TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB。
3）
内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值(如int值为0，boolean值为false等等)。这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。
4）
接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头之中。
5）
在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从Java程序的视角来看，对象创建才刚刚开始，所有的字段都还为零值。所以，一般来说，执行new指令之后会接着把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。

注意：软引用 SoftReference和弱引用 WeakReference，可以用在内存资源紧张的情况下以及创建不是很重要的数据缓存。当系统内存不足的时候，缓存中的内容是可以被释放的。
例如，一个程序用来处理用户提供的图片。如果将所有图片读入内存，这样虽然可以很快的打开图片，但内存空间使用巨大，一些使用较少的图片浪费内存空间，需要手动从内存中移除。如果每次打开图片都从磁盘文件中读取到内存再显示出来，虽然内存占用较少，但一些经常使用的图片每次打开都要访问磁盘，代价巨大。这个时候就可以用软引用构建缓存。



7，GC？
标记-清除算法（Mark-Sweep）
算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。
它的主要不足是：空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。

复制算法（Copying）
将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原
来的一半。

标记-整理算法（Mark-Compact）
首先标记出所有需要回收的对象，在标记完成后，后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。

把算法们都用上：
当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。
专门研究表明，新生代中的对象98%是“朝生夕死”的，所以并不需要按照1:1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor[1]。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上（复制算法），最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存会被“浪费”。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。
在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法（复制算法），只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。

Minor GC ，Full GC 触发条件:
Minor GC触发条件：当Eden区满时，触发Minor GC。

Full GC触发条件：
（1）调用System.gc时，系统建议执行Full GC，但是不必然执行
（2）老年代空间不足
（3）方法去空间不足
（4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存
（5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小


8，垃圾回收器？
Serial/Serial Old：
最古老的，单线程，独占式，成熟，适合单CPU  服务器
-XX:+UseSerialGC 新生代和老年代都用串行收集器
-XX:+UseParNewGC 新生代使用ParNew，老年代使用Serial Old
-XX:+UseParallelGC 新生代使用ParallerGC，老年代使用Serial Old

ParNew ：
和Serial基本没区别，唯一的区别：多线程，多CPU的，停顿时间比Serial少
-XX:+UseParNewGC 新生代使用ParNew，老年代使用Serial Old

Parallel Scavenge（ParallerGC）/Parallel Old：
关注吞吐量的垃圾收集器，高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。
所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。
-XX:+UseParallerOldGC：新生代使用ParallerGC，老年代使用Parallel Old
-XX:+MaxGCPauseMills（设置最大垃圾收集停顿时间）  ：参数允许的值是一个大于0的毫秒数，收集器将尽可能地保证内存回收花费的时间不超过设定值。不过大家不要认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快，GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些，收集300MB新生代肯定比收集500MB快吧，这也直接导致垃圾收集发生得更频繁一些，原来10秒收集一次、每次停顿100毫秒，现在变成5秒收集一次、每次停顿70毫秒。停顿时间的确在下降，但吞吐量也降下来了。
-XX:+GCTimeRatio参数的值应当是一个大于0且小于100的整数，也就是垃圾收集时间占总时间的比率，相当于是吞吐量的倒数。如果把此参数设置为19，那允许的最大GC时间就占总时间的5%（即1/（1+19）），默认值为99，就是允许最大1%（即1/（1+99））的垃圾收集时间。
-XX:+UseAdaptiveSizePolicy 当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX：SurvivorRatio）、晋升老年代对象年龄（-XX：PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略。
如果对于收集器运作原来不太了解，手工优化存在困难的时候，使用Parallel Scavenge收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机去完成将是一个不错的选择。只需要把基本的内存数据设置好（如-Xmx设置最大堆），然后使用MaxGCPauseMillis参数（更关注最大停顿时间）或GCTimeRatio（更关注吞吐量）参数给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。自适应调节策略也是Parallel Scavenge收集器与ParNew收集器的一个重要区别。

Concurrent Mark Sweep （CMS）：
收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。
从名字（包含“Mark Sweep”）上就可以看出，CMS收集器是基于“标记—清除”算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为4个步骤，包括：
	初始标记-短暂，仅仅只是标记一下GC Roots能直接关联到的对象，速度很快。
	并发标记-和用户的应用程序同时进行，进行GC RootsTracing的过程
	重新标记-短暂，为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。
	并发清除
由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。
-XX:+UseConcMarkSweepGC ，表示新生代使用ParNew，老年代的用CMS。
缺点：
浮动垃圾：由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃圾”。
同时用户的线程还在运行，需要给用户线程留下运行的内存空间。
-XX:CMSInitialOccupyFraction  ，因为以上两点，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。在JDK 早期版本的默认设置下，CMS收集器当老年代使用了68%的空间后就会被激活，这是一个偏保守的设置，如果在应用中老年代增长不是太快，可以适当调高参数-XX：CMSInitiatingOccupancyFraction的值来提高触发百分比，以便降低内存回收次数从而获取更好的性能，在JDK 1.6中，CMS收集器的启动阈值已经提升至92%。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数-XX：CMSInitiatingOccupancyFraction设置得太高很容易导致大量“Concurrent Mode Failure”失败，性能反而降低。
-XX:+UseCMSCompactAtFullCollection为了解决这个问题，CMS收集器提供了一个这个开关参数（默认就是开启的），用于在CMS收集器顶不住要进行FullGC时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长。
-XX：CMSFullGCsBeforeCompaction，这个参数是用于设置执行多少次不压缩的Full GC后，跟着来一次带压缩的（默认值为0，表示每次进入FullGC时都进行碎片整理）。


G1：
-XX:+UseG1GC
并行与并发：G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。
分代收集：与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。
空间整合：与CMS的“标记—清理”算法不同，G1从整体来看是基于“标记—整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的，但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。
内存布局：在G1之前的其他收集器进行收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。
	新生代GC
回收Eden区和survivor区，回收后，所有eden区被清空，存在一个survivor区保存了部分数据。老年代区域会增多，因为部分新生代的对象会晋升到老年代。
	并发标记周期 
初始标记：短暂，仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，产生一个全局停顿，都伴随有一次新生代的GC。
根区域扫描：扫描survivor区可以直接到达的老年代区域。
并发标记阶段：扫描和查找整个堆的存活对象，并标记。
重新标记：会产生全局停顿，对并发标记阶段的结果进行修正。
独占清理：会产生全局停顿，对GC回收比例进行排序，供混合收集阶段使用
并发清理：识别并清理完全空闲的区域，并发进行
	混合收集 
对含有垃圾比例较高的Region进行回收。
G1当出现内存不足的的情况，也可能进行的FullGC回收。
G1中重要的参数：
-XX:MaxGCPauseMillis 指定目标的最大停顿时间，G1尝试调整新生代和老年代的比例，堆大小，晋升年龄来达到这个目标时间。
-XX:ParallerGCThreads：设置GC的工作线程数量


未来的垃圾回收：
ZGC通过技术手段把stw（安全检查）的情况控制在仅有一次，就是第一次的初始标记才会发生，这样也就不难理解为什么GC停顿时间不随着堆增大而上升了，再大我也是通过并发的时间去回收了
关键技术
1.	有色指针（Colored Pointers）
2.	加载屏障（Load Barrier）


Stop The World现象：
GC收集器和我们GC调优的目标就是尽可能的减少STW的时间和次数。

内存分配与回收策略： 
1，对象优先在Eden分配，如果说Eden内存空间不足，就会发生Minor GC。
2，大对象直接进入老年代，大对象：需要大量连续内存空间的Java对象，比如很长的字符串和大型数组。
导致的结果是：1、导致内存有空间，还是需要提前进行垃圾回收获取连续空间来放他们，2、会进行大量的内存复制，所以在尽量避免大对象的产生。
-XX:PretenureSizeThreshold 参数 ，大于这个数量直接在老年代分配，缺省为0 ，表示绝不会直接分配在老年代。
长期存活的对象将进入老年代，默认15岁，-XX:MaxTenuringThreshold调整。
3，动态对象年龄判定，为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。
4，空间分配担保：新生代中有大量的对象存活，survivor空间不够，当出现大量对象在MinorGC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代.只要老年代的连续空间大于新生代对象的总大小或者历次晋升的平均大小，就进行Minor GC，否则FullGC。



9，内存泄漏和内存溢出辨析？
内存溢出：实实在在的内存空间不足导致；
内存泄漏：该释放的对象没有释放，多见于自己使用容器保存元素的情况下。

JDK为我们提供的工具：
jps 
列出当前机器上正在运行的虚拟机进程
-p  :仅仅显示VM 标示，不显示jar,class, main参数等信息.
-m:输出主函数传入的参数. 下的hello 就是在执行程序时从命令行输入的参数
-l: 输出应用程序主类完整package名称或jar完整名称.
-v: 列出jvm参数, -Xms20m -Xmx50m是启动程序指定的jvm参数

jstat
是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据，在没有GUI图形界面，只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟机性能问题的首选工具。
假设需要每250毫秒查询一次进程2764垃圾收集状况，一共查询20次，那命令应当是：jstat-gc 2764 250 20
常用参数：
-class (类加载器) 
-compiler (JIT) 
-gc (GC堆状态) 
-gccapacity (各区大小) 
-gccause (最近一次GC统计和原因) 
-gcnew (新区统计)
-gcnewcapacity (新区大小)
-gcold (老区统计)
-gcoldcapacity (老区大小)
-gcpermcapacity (永久区大小)
-gcutil (GC统计汇总)
-printcompilation (HotSpot编译统计)

jps 虚拟机进程状况工具
jstat 虚拟机统计信息监视工具
jinfo Java配置信息工具
jmap Java内存映像工具
jhat 虚拟机堆转储快照分析工具
jstack Java堆栈跟踪工具
JConsole Java监视与管理控制台
VisualVM 多合一故障处理工具

浅堆和深堆：
浅堆 :（Shallow Heap）是指一个对象所消耗的内存。例如，在32位系统中，一个对象引用会占据4个字节，一个int类型会占据4个字节，long型变量会占据8个字节，每个对象头需要占用8个字节。
深堆 ：这个对象被GC回收后，可以真实释放的内存大小，也就是只能通过对象被直接或间接访问到的所有对象的集合。通俗地说，就是指仅被对象所持有的对象的集合。深堆是指对象的保留集中所有的对象的浅堆大小之和。
举例：对象A引用了C和D，对象B引用了C和E。那么对象A的浅堆大小只是A本身，不含C和D，而A的实际大小为A、C、D三者之和。而A的深堆大小为A与D之和，由于对象C还可以通过对象B访问到，因此不在对象A的深堆范围内。



10，Class类文件结构？
1， Java跨平台的基础
各种不同平台的虚拟机与所有平台都统一使用的程序存储格式——字节码（ByteCode）是构成平台无关性的基石，也是语言无关性的基础。Java虚拟机不和包括Java在内的任何语言绑定，它只与“Class文件”这种特定的二进制文件格式所关联，Class文件中包含了Java虚拟机指令集和符号表以及若干其他辅助信息。

2， Class类的本质？
Class文件是一组以8位字节为基础单位的二进制流
 类似于结构体的伪结构来存储数据
 只有两种数据类型：无符号数和表
 	无符号数属于基本的数据类型，以u1、u2、u4、u8
 	表是由多个无符号数或者其他表作为数据项构成的复合数据类型。

3，Class文件格式详解？
Class的结构不像XML等描述语言，由于它没有任何分隔符号，所以在其中的数据项，无论是顺序还是数量，都是被严格限定的，哪个字节代表什么含义，长度是多少，先后顺序如何，都不允许改变。


4，类加载机制？
概述
类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）7个阶段。其中验证、准备、解析3个部分统称为连接（Linking）
于初始化阶段，虚拟机规范则是严格规定了有且只有5种情况必须立即对类进行“初始化”（而加载、验证、准备自然需要在此之前开始）：
1）遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。
2）使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。
3）当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。
4）当虚拟机启动时，用户需要指定一个要执行的主类（包含main（）方法的那个类），虚拟机会先初始化这个主类。
5）当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。

注意：
对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。
常量HELLOWORLD，但其实在编译阶段通过常量传播优化，已经将此常量的值“hello world”存储到了NotInitialization类的常量池中，以后NotInitialization对常量ConstClass.HELLOWORLD的引用实际都被转化为NotInitialization类对自身常量池的引用了。
也就是说，实际上NotInitialization的Class文件之中并没有ConstClass类的符号引用入口，这两个类在编译成Class之后就不存在任何联系了。


5，类加载过程？
加载阶段：
	虚拟机需要完成以下3件事情：
	1）通过一个类的全限定名来获取定义此类的二进制字节流。
	2）将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。
	3）在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。
验证：
	是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。但从整体上看，验证阶段大致上会完成下面4个阶段的检验动作：文件格式验证、元数据验证、字节码验证、符号引用验证。
准备阶段：
	是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。这个阶段中有两个容易产生混淆的概念需要强调一下，首先，这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次，这里所说的初始值“通常情况”下是数据类型的零值，假设一个类变量的定义为：
	public static int value=123；
	那变量value在准备阶段过后的初始值为0而不是123，因为这时候尚未开始执行任何Java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器＜clinit＞（）方法之中，所以把value赋值为123的动作将在初始化阶段才会执行。表7-1列出了Java中所有基本数据类型的零值。
	假设上面类变量value的定义变为：public static final int value=123；
	编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123。
解析阶段：
	是虚拟机将常量池内的符号引用替换为直接引用的过程
类初始化阶段：
	是类加载过程的最后一步，前面的类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序员通过程序制定的主观计划去初始化类变量和其他资源，或者可以从另外一个角度来表达：初始化阶段是执行类构造器＜clinit＞（）方法的过程。＜clinit＞（）方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的。
	＜clinit＞（）方法对于类或接口来说并不是必需的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成＜clinit＞（）方法。
	虚拟机会保证一个类的＜clinit＞（）方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的＜clinit＞（）方法，其他线程都需要阻塞等待，直到活动线程执行＜clinit＞（）方法完毕。如果在一个类的＜clinit＞（）方法中有耗时很长的操作，就可能造成多个进程阻塞。




 11，静态分派，动态分派，解析？
  Human man=new Man();  
  Human woman=new Woman();  
  我们把“Human”称为变量的静态类型，后面的“Man”称为变量的实际类型
  解析：
  方法解析：
	Class 文件的编译过程中不包含传统编译中的连接步骤，一切方法调用在 Class 文件里面存储的都只是符号引用，而不是方法在实际运行时内存布局中的入口地址。这个特性给 Java 带来了更强大的动态扩展能力，使得可以在类运行期间才能确定某些目标方法的直接引用，称为动态连接，也有一部分方法的符号引用在类加载阶段或第一次使用时转化为直接引用，这种转化称为静态解析。这在前面的“Java 内存区域与内存溢出”一文中有提到。

	静态解析成立的前提是：方法在程序真正执行前就有一个可确定的调用版本，并且这个方法的调用版本在运行期是不可改变的。换句话说，调用目标在编译器进行编译时就必须确定下来，这类方法的调用称为解析。

	在 Java 语言中，符合“编译器可知，运行期不可变”这个要求的方法主要有静态方法和私有方法两大类，前者与类型直接关联，后者在外部不可被访问，这两种方法都不可能通过继承或别的方式重写出其他的版本，因此它们都适合在类加载阶段进行解析。

	Java 虚拟机里共提供了四条方法调用字节指令，分别是：

	invokestatic：调用静态方法。
	invokespecial：调用实例构造器方法、私有方法和父类方法。
	invokevirtual：调用所有的虚方法。
	invokeinterface：调用接口方法，会在运行时再确定一个实现此接口的对象。
	只要能被 invokestatic 和 invokespecial 指令调用的方法，都可以在解析阶段确定唯一的调用版本，符合这个条件的有静态方法、私有方法、实例构造器和父类方法四类，它们在类加载时就会把符号引用解析为该方法的直接引用。这些方法可以称为非虚方法（还包括 final 方法），与之相反，其他方法就称为虚方法（final 方法除外）。这里要特别说明下 final 方法，虽然调用 final 方法使用的是 invokevirtual 指令，但是由于它无法覆盖，没有其他版本，所以也无需对方发接收者进行多态选择。Java 语言规范中明确说明了 final 方法是一种非虚方法。

	解析调用一定是个静态过程，在编译期间就完全确定，在类加载的解析阶段就会把涉及的符号引用转化为可确定的直接引用，不会延迟到运行期再去完成。而分派调用则可能是静态的也可能是动态的，根据分派依据的宗量数（方法的调用者和方法的参数统称为方法的宗量）又可分为单分派和多分派。两类分派方式两两组合便构成了静态单分派、静态多分派、动态单分派、动态多分派四种分派情况。
  静态分派：
　　编译器在编译期并不知道一个对象的实际类型是什么
　　编译器在重载时是通过参数的静态类型而不是实际类型作为判定的依据。
　　并且静态类型在编译期可知，因此，编译阶段，Javac编译器会根据参数的静态类型决定使用哪个重载版本。
　　所有依赖静态类型来定位方法执行版本的分派动作称为静态分派，其典型应用是方法重载（根据参数的静态类型来定位目标方法）。
　　静态分派发生在编译阶段，因此确定静态分派的动作实际上不是由虚拟机执行的。

  动态分派：
    动态分派与多态性的另一个重要体现——方法覆写有着很紧密的关系。向上转型后调用子类覆写的方法便是一个很好地说明动态分派的例子。这种情况很常见，因此这里不再用示例程序进行分析。很显然，在判断执行父类中的方法还是子类中覆盖的方法时，如果用静态类型来判断，那么无论怎么进行向上转型，都只会调用父类中的方法，但实际情况是，根据对父类实例化的子类的不同，调用的是不同子类中覆写的方法，很明显，这里是要根据变量的实际类型来分派方法的执行版本的。而实际类型的确定需要在程序运行时才能确定下来，这种在运行期根据实际类型确定方法执行版本的分派过程称为动态分派。


12，类加载的执行过程：
遇到一个新的类时，首先会到方法区去找class文件，如果没有找到就会去硬盘中找class文件，找到后会返回，将class文件加载到方法区中，在类加载的时候，静态成员变量会被分配到方法区的静态区域，非静态成员变量分配到非静态区域，然后开始给静态成员变量初始化，赋默认值，赋完默认值后，会根据静态成员变量书写的位置赋显示值，然后执行静态代码。当所有的静态代码执行完，类加载才算完成。


13，类加载机制：
类加载机制就是JVM通过类加载器加载.class文件，将class对象分配到堆内存中，class对象中的常量，静态属性，名称等分配到方法区中等操作。
类被加载到虚拟机，到被内存卸载的生命周期分为7个：
加载，验证，准备，解析，初始化，使用，卸载。
其中解析是可以发生在初始化之后的，这也是为了支持java的动态绑定或者晚期绑定。

从Java虚拟机的角度来说，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器使用C++语言实现（HotSpot虚拟机中），
是虚拟机自身的一部分；另一种就是所有其他的类加载器，这些类加载器都有Java语言实现，独立于虚拟机外部，并且全部继承自java.lang.ClassLoader。
从开发者的角度，类加载器可以细分为：

启动（Bootstrap）类加载器：负责将 Java_Home/lib下面的类库加载到内存中（比如rt.jar）。由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，
所以不允许直接通过引用进行操作。

标准扩展（Extension）类加载器：是由 Sun 的 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将Java_Home /lib/ext或者由系统变量 java.ext.dir指定位置中的类库加载到内存中。
开发者可以直接使用标准扩展类加载器。

应用程序（Application）类加载器：是由 Sun 的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。它负责将系统类路径（CLASSPATH）中指定的类库加载到内存中。
开发者可以直接使用系统类加载器。由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，因此一般称为系统（System）加载器。

双亲委派机制：
某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。
使用双亲委派模型的好处在于Java类随着它的类加载器一起具备了一种带有优先级的层次关系。



13，JVM为什么有1个Eden区和2个Survivor区?
首先说如果没有Survivor区会出现什么情况：每触发一次MinorGC，就会把Eden区的对象复制到老年代，这样当老年代满了之后会触发Major Gc(通常伴随着MinorGC，可以看做Full GC)，比较耗时。
设置 Survivor 空间的目的是让那些中等寿命的对象尽量在MinorGC时被干掉，最终在总体上减少虚拟机的垃圾收集过程对用户程序的影响。
新生代一般都采用复制算法进行垃圾收集。原始的复制算法是把一块内存一分为二， gc 时把存活的对象从一块空间（From space）复制到另外一块空间（To space），再把原先的那块内存（From space）清理干净，最后调换 From space 和 To space 的逻辑角色（这样下一次 gc 的时候还可以按这样的方式进行）。如果只有1个Survivor区，那当Eden区满了之后，就会复制对象到Survivor区，容易产生内存碎片化。严重影响性能。
所以使用2个Survivor区，始终保持有一个空的Survivor区，可以避免内存碎片化。


---------------------------------------------------------------------------------------------------------------------------------------------------------------



八，mybatis？

1，原生JDBC操作数据库的步骤：
	1，导入相关的包（sql）  
	2，注册数据库驱动
	3，获得数据库连接
	4，编写SQL语句，建立结果集，并将结果集封装到返回的对象中
	5，写操作事务处理
	6，关闭连接



4，动态sql？
	case when语法   in语法，传入的集合或者数组    FIELD（）按照某个字段指定规则排序   concat（）用于like模糊查询


5，批量操作数据库？
	1，检查数据库是否支持批量操作
	2，使用foreach动态sql进行批量操作
	3，或者使用Batch执行器，SqlSession sqlSession = sqlSessionFactory.openSession(ExecutorType.BATCH, true)，将批量操作一起放入到
	Batch队列中，然后最终一起执行，只有一次数据库的连接。但是如果执行的数据太对了，可能会造成队列溢出，或者执行时间过长。在和spring
	集成之后，因为封装了SqlSessionFactory，所以要使用Batch就需要自己手动的去获取SqlSessionFactory


6，几种执行器？
	1，Statement简单类型的执行器
	2，PreparedStatement预处理执行器
	3，Batch批量操作的执行器


2，PreparedStatement预处理结果集？
	PreparedStatement结果集，可以在第一次执行时进行预编译，指令缓存在数据库中，提高效率，并且可以防止sql注入。


3，#{}和${}的区别？
	#{}：预编译，可以防止sql注入，传入的字符串会自动加上单引号，在预编译的时候会用？占位符表示
	${}：不会预处理，不可以防止sql注入，传入的字符串直接替换，在表名和查询出来的字段名是动态的时候，需要使用，因为不能加单引号

7，几个重要组件？
	SqlSessionFactoryBuilder：读取所有的配置信息，创建SqlSessionFactory，使用建造者模式，方法级别生命周期；

	SqlSessionFactory：创建Sqlsession，工厂单例模式，存在于程序的整个生命周期，管理连接池，用于生产SqlSession的工厂；

	SqlSession：代表一次数据库连接，可以直接发送SQL执行，也可以通过调用Mapper访问数据库；线程不安全，要保证线程独享（方法级）；

	SQL Mapper：由一个Java接口和XML文件组成，包含了要执行的SQL语句和结果集映射规则。方法级别生命周期；


8，example类？
	最好不要使用example类，因为example类不利用解耦，不利用sql调优。


9.嵌套结果和嵌套查询？
	嵌套结果：一个sql把关联查询的数据都查出来
	嵌套查询：先查出一部分数据，再根据这部分数据查出剩下的数据，这样在查询的时候会先查一次主表，再根据结果去查从表，可能会引起N+1的问题，所以需要开启延迟加载（fatchType=lazy），去解决这个问题，在日常开发中，推荐使用这种方式去解决关联查询。


10，关联查询？
	1，一对多association
	2，一对多collection
	3，选择策略discriminator（鉴别器），可以设置条件选择某一个resultMap执行。


11，一级和二级缓存？
	1，insert，update，delete这些操作会去清空一级缓存，一级缓存默认开启，一级缓存是sqlsession级别的，根据第一次查出的id作为key。
	2，二级缓存是跨sqlseesion级别的，是以空间namespace为单位的。但是最好不要使用二级缓存，因为非常容易出现脏读。设置<cache/>即可开启，同时可以设置缓存回收算法策略，有FIFO（先进先出），LRU（最近最少使用）。建议不要使用二级缓存，容易出现脏读，可以使用第三方的缓存框架代替mybatis的二级缓存。
	3，优先级：优先从二级缓存找，其次是一级缓存，Hibernate是先去本地的一级缓存，如果没有就会去找二级缓存，再没有就去查数据库。

12，适配器模式？
	举例：姚明不会讲英语，需要一个适配器（翻译）来，适配之后，姚明讲的中文就变成了翻译之后的英文了。比如，mybatis的日志实现，就是将很多第三方的日志实现通过各自的适配器转成mybatis的日志Log实现。
	开发使用场景：
		1，比如支付宝接口，微信支付接口，银联支付接口，可以写一个自己规则的支付接口，然后用适配器模式，将其他第三方的支付接口适配成自己支付接口模式。      
		2，还比如机票接口，有很多厂商提供机票接口，就可以用适配器模式。
	在mybatis的日志框架中使用了这种模式，因为有很多日志框架的实现中的LEVEL等级都不一样，mybatis统一定制了一套日志等级，然后将其他日志框架在mybatis中转换成了自己的等级。同时，在LogFactory工厂中，static静态块中定义了日志加载顺序，优先级顺序：slf4J → commonsLoging → Log4J2 → Log4J → JdkLog.会按照顺序依次判断是否已经有了此日志实现，如果没有就开启一个线程去尝试（因为可能没有加入此依赖）创建此日志框架，如果有就不再加载其他日志框架。


13，对功能的扩展？
	1，继承（静态的，如果是一个类要多方向扩展功能，就得添加很多个增强类，这时候使用装饰器模式最佳）
	2，动态代理（mybatis中的日志部分，在ConnectionLogger代理类中，让JDBC原生的Connection和PreparedStatement和Statement和ResultSet都具备了打印日志的能力，即是都被增强了）
	3，装饰器模式（扩展性，灵活性更强），比如IO的设计就使用了装饰器，servlet中的httpservletrequestwrapper和mybatis缓存组件。
	设计模式的几大原则：
		1，单一职责（分工明确）
		2，依赖倒转（高层不依赖底层，解耦）
		3，开放封闭（对扩展开放，对修改封闭）


14，装饰器模式和动态代理的区别？
	假设这样一种场景，我们要为类Origin增加A功能，B功能和C功能。
	JDK动态代理：需要生成三个Origin的Handler来分别增加A,B,C功能。
	这三个代理类分别为OriginHandlerA,OriginHandlerB,OriginHandlerC
	装饰器模式：也需要生成三个Origin的装饰器来增加A,B,C的功能。
	这三个装饰器分别为OriginDecoratorA，OriginDecoratorB，OriginDecoratorC
	现在我们有了新的需求，需要为Origin类增加A,B功能。
	动态代理：再生成一个子类来实现AB功能的组合，客户端代码获取对应功能的代理类可以解耦到配置文件中。
	这样就可以不用修改客户端代码来实现新的功能了。
	装饰器模式：不需要生成新的装饰器类，只需要在客户端代码中组合的OriginDecoratorA和OriginDecoratorB来或者AB功能。

15，mybatis的数据源？
	采用工厂模式：（因为DataSource的创建很麻烦，构造函数和内部实现很复杂，同时解耦，所以使用工厂模式）
	UnpooledDataSourceFactory：创建不使用数据库连接池的数据库连接的工厂
	PooledDataSourceFactory：创建使用数据库连接池的数据库连接的工厂

	UnpooledDataSource：不使用数据库连接池的数据库连接对象，继承DataSource，创建连接的过程和JDBC原生一致，其中数据库驱动通过反射
	去注册，在注册的时候，其实就是Driver类被加载的时候调用其内部的static进行初始化后注册到DriverManager中。
	PooledDataSource：使用数据库连接池的数据库连接对象，是线程安全的，继承DataSource，几个重要的组件：
		PooledConnection：使用动态代理对从连接池中获取的Connection连接对象进行增强的代理类。
						  增强的地方有：1，使用前检查连接是否有效  2，手动关闭时对连接进行回收
		PoolState：管理PooledConntection中的一些组件信息，比如空闲连接池数idleConnections，以及活跃连接池数activeConnections....获取连接和回收连接的方法。
	
	
16，mybatis的缓存？
	缓存被清空的策略：FIFO（先进先出），LRU（最近最少使用的先出）。
	数据库的查询操作，超过0.3S就被称为你慢查询，需要优化系统了。
	使用缓存就是一种空间换时间的操作，将磁盘数据库上的数据，备份到内存中，免去了去请求磁盘的IO操作的费时。
	tomcat默认的失效时间是30分钟。

	使用缓存的时候，存在数据一致性问题，有四种处理方法，其中使用比较多的缓存失效机制，容易引起缓存雪崩。
	缓存雪崩：就是在缓存失效的一瞬间，有多高并发请求直接透过缓存请求数据库，使得数据库挂掉。
	解决：
		  1，给缓存失效时间加“盐”，不让所有的缓存的失效时间一样。
		  2，使用jvm锁，推荐使用细粒度锁，mybatis的缓存机制，中就是使用的对key进行的加锁的细粒度锁。
		  3，使用分布式锁。
	java连接池最大连接数不能超过数据库自带的连接池的连接数。
	连接数 = ((核心数 * 2) + 有效磁盘数)

	CacheKey对象中重写的equals方法，比较两个对象是否相同（这两个对象是根据对象中的很多属性是否相等比较），采用的一种很高效的办法。


17，mybatis的反射？
	ObjectFactory：MyBatis每次创建结果对象的新实例时，它都会使用对象工厂（ObjectFactory）去构建POJO；
	ReflectorFactory：创建Reflector的工厂类，Reflector是mybatis反射模块的基础，每个Reflector对象都对应一个类，在其中缓存了反射操作所需要的类元信息，如果没有get和set方法，也可以通过对其进行自动的设置set和get方法。
	ObjectWrapper：是一种增强，对对象的包装，抽象了对象的属性信息，他定义了一系列查询对象属性信息的方法，以及更新属性的方法，可以给将sql查出来的数据赋值给相应的对象。
	ObjectWrapperFactory： ObjectWrapper 的工厂类，用于创建ObjectWrapper。
	MetaObject：封装了对象和类的元信息，包装了mybatis中五个核心的反射类。也是提供给外部使用的反射工具类，可以利用它可以读取或者修改对象的属性信息；


18，mybatis的核心流程？
	1，初始化配置
		读取XML配置文件和注解中的配置信息，创建配置对象，并完成各个模块的初始化的工作；
	2，代理增强阶段
		封装iBatis的编程模型，使用mapper接口开发的初始化工作，就是根据mapper接口，动态代理增强获取对应的mapper接口的实现类。
	3，数据读写阶段
		通过SqlSession完成SQL的解析，参数的映射、SQL的执行、结果的解析过程；

	建造者模式：
		使用多个简单的对象一步一步构建成一个复杂的对象。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。符合Fluent编程风格。

	建造者模式和工厂模式的区别：
		工厂模式一般都是创建一个产品，注重的是把这个产品创建出来就行，只要创建出来，不关心这个产品的组成部分。从代码上看，工厂模式就是一个方法，用这个方法就能生产出产品。
		建造者模式也是创建一个产品，但是不仅要把这个产品创建出来，还要关系这个产品的组成细节，组成过程。从代码上看，建造者模式在建造产品时，这个产品有很多方法，建造者模式会根据这些相同方法但是不同执行顺序建造出不同组成细节的产品。可以比较两个模式的example代码，一比较就会比较出来，工厂模式关心整体，建造者模式关心细节。
		
		对象复杂度：
		 建造者建造的对象更加复杂，是一个复合产品，它由各个部件复合而成，部件不同产品对象不同，生成的产品
		粒度细：
		 在工厂方法模式里，我们关注的是一个产品整体，无须关心产品的各部分是如何创建出来的；
		 客户端参与程度
		 建造者模式，导演对象参与了产品的创建，决定了产品的类型和内容，参与度高；适合实例化对象时属性变化
		频繁的场景：
		 工厂模式，客户端对产品的创建过程参与度低，对象实例化时属性值相对比较固定；

	创建对象的几种方法：
		1，工厂模式
		2，建造者模式
		3，反射
		4，new
		5，clone
		6，反序列化

	Configuration ： Mybatis启动初始化的核心就是将所有xml配置文件信息加载到Configuration对象中， Configuration是单例的，生命周期是应用级的；
					 XMLConfigBuilder是用于处理核心配置文件，XMLMapperBuilder处理映射文件中的映射实体，XMLStatementBuilder处理映射文件中的一
					 sql，这三个类实际上都是使用建造者模式思想，并没有使用建造者模式的写法，后两个都调用了“秘书类”去建造Configuration ，并添加进相应的属性。
	MapperRegistry：mapper接口动态代理工厂类的注册中心。在MyBatis中，通过mapperProxy实现
	InvocationHandler接口，MapperProxyFactory用于生成动态代理的实例对象；
	ResultMap：用于解析mapper.xml文件中的resultMap节点，使用ResultMapping来封装id，result等子元素；
	MappedStatement：用于存储mapper.xml文件中的select、insert、update和delete节点，同时还包含了这些节点的很多重要属性；
	SqlSource：mapper.xml文件中的sql语句会被解析成SqlSource对象，经过解析SqlSource包含的语句最终仅仅包含？占位符，可以直接提交给数据库执行；
	TypeHandlerRegistry：用于映射数据库字段属性类型和java类型。通过xml中指定typeHandler和自定义转换类实现BaseTypeHandler接口即可实现映射枚举类。


19，mybatis的mapper动态代理增强？
	MapperRegistry ： mapper接口和对应的代理对象工厂的注册中心；
	MapperProxyFactory：用于生成mapper接口动态代理的实例对象；
	MapperProxy：实现了InvocationHandler接口，它是增强mapper接口的实现；
	MapperMethod：封装了Mapper接口中对应方法的信息，以及对应的sql语句的信息；它是mapper接口与映射配置文件中sql语句的桥梁；
		MapperMethod：封装了Mapper接口中对应方法的信息，以及对应的sql语句的信息；它是mapper接口与映射配置文件中sql语句的桥梁； MapperMethod对象不记录任何状态信息，所以它可以在多个代理对象之间共享；
	  SqlCommand ： 从configuration中获取方法的命名空间.方法名以及SQL语句的类型；
	  MethodSignature：封装mapper接口方法的相关信息（入参，返回类型）；
	  ParamNameResolver： 解析mapper接口方法中的入参；

20，创建sqlsession的策略模式？
	策略模式定义了一系列的算法，并将每一个算法封装起来，而且使他们可以相互替换，让算法独立于使用它的客户而独立变化。
	策略模式的使用场景：
	 针对同一类型问题的多种处理方式，仅仅是具体行为有差别时；
	 出现同一抽象类有多个子类，而又需要使用 if-else 或者 switch-case 来选择具体子类时。
	   就比如是，spring的依赖注入，@Autowired，如果不指定注入的value，就是按照类型注入，如果指定了，就按照名称注入，但是注入的方式都是一样的，
	   所以spring的依赖注入的实现方式就是策略模式。springmvc的dispatcherservlet用到了门面模式。
	sqlSessionManager同时继承了SqlSession接口和SqlSessionFactroy接口，提供了创建SqlSession对象和操纵数据库的能力；
	 SqlSessionManager有两种获取SqlSession的模式：
	 第一种模式和SqlSessionFactroy 相同，同一个线程每次访问数据库，每次都可以创建新的SqlSession对象；
	 第二种模式，同一个线程每次访问数据库，都是使用同一个SqlSession对象,通过localSqlSession实现；

21，核心组件Excutor？
	Executor是MyBaits核心接口之一，定义了数据库操作最基本的方法，SqlSession的功能都是基于它来实现的。
	使用了模板方法模式。
	模板模式：
	遇到由一系列步骤构成的过程需要执行，这个过程从高层次上看是相同的，但是有些步骤的实现可能不同，这个时候就需要考虑用模板模式了。
	SimpleExecutor：默认配置，使用statement对象访问数据库，每次访问都要创建新的statement对象；
	ReuseExecutor：使用预编译PrepareStatement对象访问数据库，访问时，会重用缓存中的statement对象；
	BatchExecutor：实现批量执行多条SQL语句的能力；

	Executor的三个重要小弟
	 通过对SimpleExecutor doQuery()方法的解读发现，Executor是个指挥官，它在调度三个小弟工作：
	 StatementHandler：它的作用是使用数据库的Statement或PrepareStatement执行操作，启承上启下作用；
	 ParameterHandler：对预编译的SQL语句进行参数设置，SQL语句中的的占位符“？”都对应
	   BoundSql.parameterMappings集合中的一个元素，在该对象中记录了对应的参数名称以及该参数的相关属性
	 ResultSetHandler：对数据库返回的结果集（ResultSet）进行封装，返回用户指定的实体类型；

	StatementHandler完成Mybatis最核心的工作，也是Executor实现的基础；功能包括：创建statement对象，为sql语句绑定参数，执行增删改查等SQL语句、将结果映射集进行转化；
	BaseStatementHandler：所有子类的抽象父类，定义了初始化statement的操作顺序，由子类实现具体的实例化不同的statement
	（模板模式）；
	 RoutingStatementHandler：Excutor组件真正实例化的子类，使用静态代理模式，根据上下文决定创建哪个具体实体类；
	 SimpleStatmentHandler ：使用statement对象访问数据库，无须参数化；
	 PreparedStatmentHandler ：使用预编译
	   PrepareStatement：对象访问数据库；
	 CallableStatmentHandler ：调用存储过程；

	执行流程是：
	Sqlsession获取连接-->Executor执行sql-->StatementHandler执行(创建执行对象Statment和返回对象ResultSet)-->ParameterHandler填充参数到Statment占位符中-->请求数据库返回结果集-->ResultSetHandler处理返回结果集，封装到ResultSet-->StatementHandler返回结果集-->Executor返回结果集-->Sqlsession返回结果集.

	mybatis的分页其实就是个假分页，是先将所有的数据一次性查出来，再遍历找出相应页码的数据返回，所以不用mybatis自带的分页。


22，spring和myabtis整合？
	SqlSessionFactoryBean中初始化mybatis的一系列配置文件和接口和参数。
	MapperScannerConfigurer扫描mapper接口和mapper配置文件，将mapper接口转化成MapperFactoryBean。
	spring只是做了初始化和mapper接口增强映射的一些操作，底层连接数据库还是mybatis自己实现的。


23，插件开发？
	1. 实现Interceptor接口方法，配置mybatis中需要去拦截的方法（mybatis中有很多种可以被拦截的方法）。
	   mybatis中能使用插件进行拦截的接口和方法如下：
	 Executor（update、query 、 flushStatment 、 commit 、 rollback 、 getTransaction 、 close 、 isClose）
	 StatementHandler（prepare 、 paramterize 、 batch 、 update 、 query）
	 ParameterHandler（ getParameterObject 、 setParameters ）
	 ResultSetHandler（ handleResultSets 、 handleCursorResultSets 、 handleOutputParameters ）
	2. 确定拦截的签名
	3. 在配置文件中配置插件
	4. 运行测试用例
	插件的执行流程：
	1. 插件的初始化 （XMLConfigBuilder.pluginElement）
	2. 插件的加载 （Configuration.new*方法，四大对象的创建的时候都会加载插件的代理）
	3. 插件的调用 （Plugin. wrap、 Plugin. invoke）

	使用场景：
	比如可以过滤一些非法的sql。


24，责任链模式？
	责任链模式：就是把一件工作分别经过链上的各个节点，让这些节点依次处理这个工作；和装饰器模式不同，每个节点都知道后继者是谁；适合为完成同一个请求需要多个处理类的场景；
	责任链模式优点：
	 降低耦合度。它将请求的发送者和接收者解耦。
	 简化了对象。使得对象不需要知道链的结构。
	 增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。
	 增加新的请求处理类很方便。
	拦截器/过滤器的实现就是一种责任链模式。


25,mybatis 是怎么使用枚举的方式来关联数据库字段的?
	1，编写枚举类
	2，编写自定义枚举转换器，实现BaseTypeHandler接口，重写相应方法。
	3，在mapper中的结果映射中的相应字段配置typeHandler。


26，有41亿个数字，现在随便找到去一个数字A，如何判断A在这41亿个数字中？
	https://mp.weixin.qq.com/s/XC7Wpc5ZdvcT_7h3I956RQ
	2的32次方是42亿左右。

27，一个进程中是三个线程，有一个线程内存泄漏了，另外两个线程会影响不？
	不会。

28，123这三个数字组成的最大的数字是多少？
	3的21次方。


29，代理模式的作用？
	对某些对象提供一种对外访问的接口，扩展实现类的功能。
	静态代理：若代理类在程序运行前就已经存在，那么这种代理方式被成为静态代理。
	优点：可以扩展原功能，不侵入原来的代码。
	缺点：灵活性低，当需要扩展的对象多了之后，代理类就会随之改变。

	动态代理：代理类在程序运行时创建的代理方式被成为动态代理。
	优点：可以很方便的对代理类的函数进行统一的处理，而不用修改每个代理类中的方法。是因为所有被代理执行的方法，都是通过在InvocationHandler中的invoke方法调用的，
	所以我们只要在invoke方法中统一处理，就可以对所有被代理的方法进行相同的操作了。

	jdk动态代理和cglib动态代理的区别：
	使用JDK动态代理，目标类必须实现的某个接口，如果某个类没有实现接口则不能生成代理对象，这也是jdk动态代理的缺点。
	Cglib原理是针对目标类生成一个子类，覆盖其中的所有方法，所以目标类和方法不能声明为final类型。
	从执行效率上看，Cglib动态代理效率较高，所以spring的aop实现一般都用cglib。


30，工厂模式的作用？
	帮助我们创建实例，不需要我们去频繁的new实例。

	简单工厂模式：不属于设计模式，是一种思想，由一个工厂决定创建哪一个对象。
	优点：在工厂中包含了必要的逻辑，帮助我们去自动生成对应的实例。
	缺点：当实例发生改变的时候，工厂也要发生响应的改变，并且工厂中的逻辑写死的，违反了高内聚低耦合的分配原则，违反了开放封闭原则。

	工厂设计模式：
	优点：创建对象的接口，让子类去决定具体实例化的对象，把简单的内部逻辑判断移到了客户端代码。工厂方法克服了简单工厂违背开放-封闭原则的缺点，
	又保持了封装对象创建过程的优点。
	缺点：每增加一个产品，相应的也要增加一个子工厂，加大了额外的开发量。

	抽象工厂模式：
	其实就是在工厂模式的基础上，有多个产品的时候。就在抽象工厂的接口上加上新增的产品就行。






---------------------------------------------------------------------------------------------------------------------------------------------------------------

十，hibernate？

hibernate的缓存机制？
Hibernate中的缓存包括一级缓存（Session缓存）、二级缓存（SessionFactory缓存）和查询缓存。
一级缓存：
hibernate的一级缓存是session级别的，所以如果session关闭后，缓存就没了，此时就会再次发sql去查数据库。
二级缓存：
hibernate并没有提供相应的二级缓存的组件，所以需要加入额外的二级缓存包，常用的二级缓存包是EHcache。因为二级缓存是sessionFactory级别的缓存，我们看到，
在配置了二级缓存以后，当我们session关闭以后，我们再去查询对象的时候，此时hibernate首先会去二级缓存中查询是否有该对象，有就不会再发sql了。
把获得的所有数据对象根据ID放入到第二级缓存中。
Hibernate的二级缓存策略，是针对于ID查询的缓存策略，对于条件查询则毫无作用。
查询缓存：
查询普通属性，会先到查询缓存中取，如果没有，则查询数据库；查询实体，会先到查询缓存中取id，如果有，则根据id到缓存(一级/二级)中取实体，如果缓存中取不到实体，
再查询数据库。


Hibernate中的三种状态：
瞬时状态：刚创建的对象还没有被Session持久化、缓存中不存在这个对象的数据并且数据库中没有这个对象对应的数据为瞬时状态这个时候是没有OID。　　　

持久状态：对象经过Session持久化操作，缓存中存在这个对象的数据为持久状态并且数据库中存在这个对象对应的数据为持久状态这个时候有OID。

游离状态：当Session关闭，缓存中不存在这个对象数据而数据库中有这个对象的数据并且有OID为游离状态。


mybatis和hibernate的区别？
hibernate:是一个标准的ORM框架（对象关系映射）。入门门槛较高，不需要写sql，sql语句自动生成，对sql语句进行优化、修改比较困难。
应用场景：适用需求变化不多的中小型项目，比如：后台管理系统，erp，orm，oa等

mybatis：专注sql本身，需要程序员自己编写sql语句，sql修改、优化比较方便。mybatis是一个不完全的ORM框架，虽然程序员自己写sql，mybatis也可以实现映射（输入映射，输出映射）
应用场景：适用需求变化较多的项目，比如：互联网项目。

当时使用Mybaits的时候，也有去社区了解了一下两个框架的口碑，发现大家的战队都坚定而对立。对Hibernate的不满通常是因为它在复杂关联中往往会带来严重的性能问题，
也就是N+1的问题。但是它是面向对象支持的最好的框架了。而Mybatis则相对而言比较易于使用，只需要会SQL语句就行了。但是也意味着会破坏一些面向对象的规则。



---------------------------------------------------------------------------------------------------------------------------------------------------------------

十一，Web service技术？

Web service就是一种跨平台的跨编程语言的远程调用技术。
*  WebService的三要素是：(面试)
*     SOAP (Simple Object Access Protocol)：简易对象访问协议，soap用来描述传递信息的格式。
*     WSDL (WebServices Description Language)：Web服务描述语言，用来描述如何访问具体的接口。
*     UDDI (Universal Description Discovery and Integration)：通用描述、发现及整合，用来管理、分发、查询webService。


WebService采用Http协议来在客户端和服务端之间传输数据。WebService使用XML来封装数据，XML主要的优点在于它是跨平台的。

WebService通过HTTP协议发送请求和接收结果时，发送的请求内容和结果内容都采用XML格式封装，并增加了一些特定的HTTP消息头，
以说明HTTP消息的内容格式，这些特定的HTTP消息头和XML内容格式就是SOAP协议规定的。

WebService服务器端首先要通过一个WSDL文件来说明自己有什么服务可以对外调用。简单的说，WSDL就像是一个说明书，用于描述WebService及其方法、参数和返回值。 
WSDL文件保存在Web服务器上，通过一个url地址就可以访问到它。客户端要调用一个WebService服务之前，要知道该服务的WSDL文件的地址。
WebService服务提供商可以通过两种方式来暴露它的WSDL文件地址：1.注册到UDDI服务器，以便被人查找；2.直接告诉给客户端调用者。




---------------------------------------------------------------------------------------------------------------------------------------------------------------

十二，单例设计模式？

1,饿汉式
class single
{
	private static final single s=new single();
	private single(){}
	public static single getInstance()
	{
		return s;
	}
}
2,懒汉式(即是什么时候用这个对象，才创建。)
class single
{
	private static single s=null;
	private single(){}
	public static single getInstance()
	{
		if(s==null)
			 s=new single();
		return s;
	}
}

多线程下的单例：
public static single getInstance()
{
	if(s==null)//提高效率问题。
	{
		synchronized(single.class//注意不能用this.getClass因为静态中没有this)//解决安全问题。
		{
			if(s==null)
			single s=new single();
		}
	
	}
	return s;
}
这个方法在单核和多核的cpu下都不能保证很好的工作。导致这个方法失败的原因是当前java平台的内存模型。java平台内存模型中有一个叫“无序写”（out-of-order writes）的机制。正是这个机制导致了双重检查加锁方法的失效。这个问题的关键在上面代码上的第5行：instance = new SingletonThree(); 这行其实做了两个事情：1、调用构造方法，创建了一个实例。2、把这个实例赋值给instance这个实例变量。可问题就是，这两步jvm是不保证顺序的。也就是说。可能在调用构造方法之前，instance已经被设置为非空了。



懒加载模式（最好）：
public class SingleInit {
    private SingleInit(){}

    //定义一个私有类，来持有当前类的实例
    private static class InstanceHolder{
        public static SingleInit instance = new SingleInit();
    }

    public static SingleInit getInstance(){
        return InstanceHolder.instance;
    }

}



---------------------------------------------------------------------------------------------------------------------------------------------------------------

十三，异常？

异常：在运行时期发生的不正常的情况。
java中将这些异常的处理方式用对象封装起来了。用异常类进行描述。
不同的问题用不同的类进行具体的描述，这样所描述问题的类就有很多。这样就需要将其共性进行向上抽取，形成异常体系。
最终问题（异常）就形成了两大类：
Throwable（父类）：无论是Error还是Exception都是问题，问题一旦发生，就可以被抛出让调用者知道并且处理。
该体系的特点是Throwable及其所有的子类都具有可抛性。
1，不可处理的。Error（错误）
2，可处理的。Exception（异常）
可抛性通过两个关键字来体现：throws,throw
凡是可以被这两个关键字所操作的类和对象都具有可抛性。
throws和throw的区别：
1，throws使用在函数上。
   throw使用在函数内。
2，throws抛出的是异常类，还可以用于声明自定义异常。
   throw抛出的是异常对象。

还可以处理方式是：
try
{
	//需要被检测的异常的代码。
}
catch（异常类 变量）//该变量用于接收发生异常的异常对象。
{
	//处理异常的代码。
}
finally
{
	//一定会被执行的代码。
}
异常处理的原则：
1，如果在函数内部有抛出的需要检测的异常，需要在函数上进行声明，或者是在函数内使用try{} catch（）{}捕捉。否则编译失败。
2，如果调用到声明的异常的函数，必须要进行try catch捕捉或者是在函数上进行throws声明。
3，什么时候用catch，什么时候用throws呢?
	功能内部可以解决就用catch，不能解决就用throws。
4，如果一个功能出现了多个异常，那么在解决时，就需要用对应的多个catch进行针对性的处理。

finally关键字。例如：学生进教室打开门，上课，课上完走的时候要关门。但是如果上课途中有异常，都出去了，这个时候门还是得关上。
这个关门动作是必须做的，这个动作就放在finally中。即是必须要执行的代码。

异常的分类：
1，编译时被检测异常：只要是Exception和其子类都是。除了他的特殊子类RuntimeException体系。
2，编译时不检测异常，运行时才检测异常。就是Exception中的RuntimeException体系和其子类，开发中大多数自定义异常都是运行时异常。


try with resouce语法是jdk1.7的，自动关闭外部资源（如关闭流）：
1、当一个外部资源的句柄对象实现了AutoCloseable接口，JDK7中便可以利用try-with-resource语法更优雅的关闭资源，消除板式代码。
2、try-with-resource时，如果对外部资源的处理和对外部资源的关闭均遭遇了异常，“关闭异常”将被抑制，“处理异常”将被抛出，
但“关闭异常”并没有丢失，而是存放在“处理异常”的被抑制的异常列表中。

---------------------------------------------------------------------------------------------------------------------------------------------------------------

十五，Redis 的数据结构都有哪些？
Redis 是一个基于内存的高性能key-value数据库。 

字符串(strings)：存储整数（比如计数器）和字符串（废话。。），有些公司也用来存储json/pb等序列化数据，并不推荐，浪费内存 
哈希表(hashes)：存储配置，对象（比如用户、商品），优点是可以存取部分key，对于经常变化的或者部分key要求atom操作的适合 
列表(lists)：可以用来存最新用户动态，时间轴，优点是有序，确定是元素可重复，不去重 
集合(sets)：无序，唯一，对于要求严格唯一性的可以使用 

Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。





---------------------------------------------------------------------------------------------------------------------------------------------------------------

十六，Shiro 的优点
	1，简单的身份认证, 支持多种数据源
	2，对角色的简单的授权, 支持细粒度的授权(方法级)
	3，支持一级缓存，以提升应用程序的性能；
	4，内置的基于 POJO 企业会话管理, 适用于 Web 以及非 Web 的环境
	5，非常简单的加密 API
	6，不跟任何的框架或者容器捆绑, 可以独立运行

	Shiro 架构 3 个核心组件:
	    1，Subject: 正与系统进行交互的人, 或某一个第三方服务. 
	    所有 Subject 实例都被绑定到（且这是必须的）一个SecurityManager 上。
	    2，SecurityManager: Shiro 架构的心脏, 用来协调内部各安全组件, 管理内部组件实例, 并通过它来提供安全管理的各种服务. 
	    当 Shiro 与一个 Subject 进行交互时, 实质上是幕后的 SecurityManager 处理所有繁重的 Subject 安全操作。
	    3，Realms: 本质上是一个特定安全的 DAO. 当配置 Shiro 时, 必须指定至少一个 Realm 用来进行身份验证和/或授权. 
	    Shiro 提供了多种可用的 Realms 来获取安全相关的数据. 如关系数据库(JDBC), INI 及属性文件等. 
	    可以定义自己 Realm 实现来代表自定义的数据源。



---------------------------------------------------------------------------------------------------------------------------------------------------------------


十七，RESTful风格？
	RESTful是一种软件架构风格
	Rest架构的主要原则：
		1，网络上的所有事物都被抽象为资源
		2，每个资源都有一个唯一的资源标识符
		3，同一个资源具有多种表现形式(xml,json等)
		4，对资源的各种操作不会改变资源标识符
		5，所有的操作都是无状态的
		6，符合REST原则的架构方式即可称为RESTful

特点是：
GET  查询
POST 新增
PUT 修改
DELETE 删除



---------------------------------------------------------------------------------------------------------------------------------------------------------------


十八，常见问题？

高并发处理：
了解一点高并发性问题，比如一W人抢一张票时，如何保证票在没买走的情况下所有人都能看见这张票，显然是不能用同步机制，因为synchronize是锁同步一次只能一个人进行
。这时候可以用到锁机制，采用乐观锁可以解决这个问题。乐观锁的简单意思是在不锁定表的情况下，利用业务的控制来解决并发问题，这样即保证数据的可读性，
又保证保存数据的排他性，保证性能的同时解决了并发带来的脏读数据问题。



springboot？
设置静态资源访问路径：spring.resource.static-location
设置tomcat端口：server-port
设置项目访问根目录:server.servlet-path

@SpringBootApplication启动类，继承SpringBootServletInitializer。
public static void main(String[] args) {
	SpringApplication.run(RenrenApplication.class, args);
}

@Override
protected SpringApplicationBuilder configure(SpringApplicationBuilder application) {
	return application.sources(RenrenApplication.class);
}



获取class对象的三种方法？
1，
Object object=new Object;
Class class=object.getClass();
2,
Class class=Object.class;
3,
Class class=Class.forName("java.lang.Object");



字符串常见操作方法？
concat() – 将两个或多个字符的文本组合起来，返回一个新的字符串。
indexOf() – 返回字符串中一个子串第一处出现的索引。如果没有匹配项，返回 -1 。
charAt() – 返回指定位置的字符。
lastIndexOf() – 返回字符串中一个子串最后一处出现的索引，如果没有匹配项，返回 -1 。
match() – 检查一个字符串是否匹配一个正则表达式。
substr() 函数 -- 返回从string的startPos位置，长度为length的字符串
substring() – 返回字符串的一个子串。传入参数是起始位置和结束位置。
slice() – 提取字符串的一部分，并返回一个新字符串。
replace() – 用来查找匹配一个正则表达式的字符串，然后使用新字符串代替匹配的字符串。
search() – 执行一个正则表达式匹配查找。如果查找成功，返回字符串中匹配的索引值。否则返回 -1 。
split() – 通过将字符串划分成子串，将一个字符串做成一个字符串数组。
length – 返回字符串的长度，所谓字符串的长度是指其包含的字符的个数。
toLowerCase() – 将整个字符串转成小写字母。
toUpperCase() – 将整个字符串转成大写字母。


闭包？
定义和用法：当一个函数的返回值是另外一个函数，而返回的那个函数如果调用了其父函数内部的其它变量，如果返回的这个函数在外部被执行，就产生了闭包。
var count=10;   //全局作用域 标记为flag1
function add(){
    var count=0;    //函数全局作用域 标记为flag2
    return function(){
        count+=1;   //函数的内部作用域
        alert(count);
    }
}
var s = add()
s();//输出1
s();//输出2


使用闭包的注意点

1）滥用闭包，会造成内存泄漏：由于闭包会使得函数中的变量都被保存在内存中，内存消耗很大，所以不能滥用闭包，否则会造成网页的性能问题，
在IE中可能导致内存泄露。解决方法是，在退出函数之前，将不使用的局部变量全部删除。

2）会改变父函数内部变量的值。所以，如果你把父函数当作对象（object）使用，把闭包当作它的公用方法（Public Method），把内部变量当作它的私有属性（private value），
这时一定要小心，不要随便改变父函数内部变量的值。



$(document).ready()方法和window.onload有什么区别？
 (1)、window.onload方法是在网页中所有的元素(包括元素的所有关联文件)完全加载到浏览器后才执行的。

 (2)、$(document).ready() 方法可以在DOM载入就绪时就对其进行操纵，并调用执行绑定的函数。




sessionStorage 、localStorage 和 cookie 之间的区别
共同点：用于浏览器端存储的缓存数据
不同点：
(1)、存储内容是否发送到服务器端：当设置了Cookie后，数据会发送到服务器端，造成一定的宽带浪费；
     web storage,会将数据保存到本地，不会造成宽带浪费；
(2)、数据存储大小不同：Cookie数据不能超过4K,适用于会话标识；web storage数据存储可以达到5M;
(3)、数据存储的有效期限不同：cookie只在设置了Cookid过期时间之前一直有效，即使关闭窗口或者浏览器；
        sessionStorage,仅在关闭浏览器之前有效；localStorage,数据存储永久有效；
(4)、作用域不同：cookie和localStorage是在同源同窗口中都是共享的；sessionStorage不在不同的浏览器窗口中共享，即使是同一个页面。




浏览器是如何渲染页面的？
渲染的流程如下：
1.解析HTML文件，创建DOM树。

   自上而下，遇到任何样式（link、style）与脚本（script）都会阻塞（外部样式不阻塞后续外部脚本的加载）。

2.解析CSS。优先级：浏览器默认设置<用户设置<外部样式<内联样式<HTML中的style样式；

3.将CSS与DOM合并，构建渲染树（Render Tree）

4.布局和绘制，重绘（repaint）和重排（reflow）



对两个list集合取并集，交集？
//并集
//list1.addAll(list2);
//交集
//list1.retainAll(list2);
//差集
//list1.removeAll(list2);
//无重复并集
list2.removeAll(list1);
list1.addAll(list2);



如何获取src下的文件？
1，
InputStream in = Test.class.getResourceAsStream("/env.properties");  
URL url = Test.class.getResource("env.properties"); 

2，
InputStream in = Test.class.getClassLoader().getResourceAsStream("env.properties");  
URL url = Test.class.getClassLoader().getResource("env.properties"); 

3，
InputStream in = Thread.currentThread().getContextClassLoader().getResourceAsStream("ExcelModeMappingl.xml");  



strust2的拦截器的实现？
1，定义一个拦截器类实现Filter接口，重写doFilter方法，处理完毕后需要交给下一个拦截器使用，chain.doFilter(request, response);  
2，在web.xml中加入拦截器和配置拦截器的拦截方式，如：
<filter-mapping>//先调用  
  <filter-name>SetCharacterEncoding</filter-name>  
  <url-pattern>/*</url-pattern>  
</filter-mapping>  
  
<filter-mapping>//后调用  
      <filter-name>FilterDispatcher</filter-name>  
      <url-pattern>*.action</url-pattern>  
</filter-mapping>  





set里的元素是不能重复的，那么用什么方法来区分重复与否呢？
用iterator();方法比较重复。

Iterator和ListIterator的区别是什么？
Iterator是集合的迭代器，ListIterator是List的迭代器，是Iterator的子类。

List,Set,Map是否继承自Collection接口？
List，Set是，Map不是。 

Java中是否可以继承String类，为什么？
不可以，因为String类有final修饰符，而final修饰的类是不能被继承的，实现细节不允许改变。


两个对象值相同 (x.equals(y) == true) ,但却可有不同的 hash code ,这 句话对不对
答：不对，有相同的 hash code
这是java语言的定义：
1) 对象相等则hashCode一定相等；
2) hashCode相等对象未必相等


值传递和引用类型传递？
（1）基本数据类型传值，对形参的修改不会影响实参；
（2）引用类型传引用，形参和实参指向同一个内存地址（同一个对象），所以对参数的修改会影响到实际的对象；
（3）String, Integer, Double等immutable的类型特殊处理，可以理解为传值，最后的操作不会修改实参对象。


switch语句能否作用在byte上,能否作用在long上,能否作用在String上？
switch可作用于char byte short int
switch可作用于char byte short int对应的包装类
switch不可作用于long double float boolean

float f = 3.4是否正确？
精度不准确,应该用强制类型转换，如下所示：float f=(float)3.4 或float f = 3.4f 
在java里面，没小数点的默认是int,有小数点的默认是 double; 

System.out.println(1.0/0.0);无线大
System.out.println(1/0);报错
因为double的0.0不是0，而是无线趋于0

数组和集合类同时容器的区别：数组虽然也可以存储对象，但数组的长度是固定的。而集合类容器的长度是可变的。
不论Collection的实际类型如何，它都支持一个iterator()的方法，该方法返回一个迭代子，使用该迭代子即可逐一访问Collection中每一个元素。

Stack继承自Vector，实现一个后进先出的堆栈。
Set：集合中对象不按特殊方式排序，并且没有重复对象。

如果涉及到堆栈，队列等操作，应该考虑用List，
对于需要快速插入，删除元素，应该使用LinkedList，
如果需要快速随机访问元素，应该使用ArrayList


Collection框架中实现比较方法？
实现Comparable接口或者Comparator接口。

String是最基本的数据类型吗？
不是，是引用类型，基本数据类型只有8个，int，byte，float，double，boolean，short，long，char。


垃圾回收的原理和特点，并考虑2种回收机制？
1.java语言最显著的特点就是引入了垃圾回收机制，它使java程序员在编写程序时不再考虑内存管理的问题。

2.由于有这个垃圾回收机制，java中的对象不再有“作用域”的概念，只有引用的对象才有“作用域”。

3.垃圾回收机制有效的防止了内存泄露，可以有效的使用可使用的内存。

4.垃圾回收器通常作为一个单独的低级别的线程运行，在不可预知的情况下对内存堆中已经死亡的或很长时间没有用过的对象进行清除和回收。

5.程序员不能实时的对某个对象或所有对象调用垃圾回收器进行垃圾回收。

6.垃圾回收有分代复制垃圾回收、标记垃圾回收、增量垃圾回收。


冒泡和选择排序的区别？
例如：1 2 3 4我们分别用a[0],a[1],a[2],a[3]存储。假设从大到小排序
选择排序，是a[0]和a[1],a[2],a[3]依次比较，遇到小的就交换，这样一次下来，最大的被保存在了a[0].下次排序就从a[1]开始重复以上步骤。
冒泡排序，是a[0]和a[1]比较，小的就交换。然后a[1]和a[2]比较，小的交换。然后a[2]和a[3]比较小的就交换。这样一次下来，最大的被保存在a[0]。下次排序从a[1]开始重复以上步骤。
虽然差不多，但是请注意：两者的比较方法是右差别的，一个事依次比下来，一个是俩俩比较。


一个’.java’源文件是否可以包括多个类，有什么限制？
一个.java类中是可以有多个类。
但是，在多个类中，有且只有一个public类，且public类的类名必须与*.java的文件名相一致。


Java中会存在内存泄漏吗，请简单描述？
理论上Java因为有垃圾回收机制（GC）不会存在内存泄露问题（这也是Java被广泛使用于服务器端编程的一个重要原因）；然而在实际开发中，
可能会存在无用但可达的对象，这些对象不能被GC回收，因此也会导致内存泄露的发生。例如Hibernate的Session（一级缓存）中的对象属于持久态，
垃圾回收器是不会回收这些对象的，然而这些对象中可能存在无用的垃圾对象，如果不及时关闭（close）或清空（flush）一级缓存就可能导致内存泄露。


写clone()方法时，通常都有一行代码？
clone 有缺省行为，super.clone();因为首先要把父类中的成员复制到位，然后才是复制自己的成员。


同步和异步的区别？
同步，是所有的操作都做完，才返回给用户结果。即写完数据库之后，在相应用户，用户体验不好。
异步，将用户请求放入消息队列，并反馈给用户，不用等所有操作等做完，就相应用户请求。即先相应用户请求，然后慢慢去写数据库，用户体验较好。



Servlet的生命周期，并说出Servlet和CGI的区别，Servlet与JSP的区别
一、Servlet 生命周期
1、加载  2、实例化  3、初始化  4、处理请求  5、销毁

二、Servlet与cgi的区别：
Servlet处于服务器进程中，它通过多线程方式运行其service方法，一个实例可以服务于多个请求，并且其实例一般不会销毁，
而CGI对每个请求都产生新的进程，服务完成后就销毁，所以效率上低于servlet。

三、Servlet与JSP的比较：

有许多相似之处，都可以生成动态网页。
JSP的优点是擅长于网页制作，生成动态页面比较直观，缺点是不容易跟踪与排错。
Servlet是纯Java语言，擅长于处理流程和业务逻辑，缺点是生成动态网页不直观。


sleep和wait的区别?
sleep是Thread类的一个方法，wait是Object类的一个方法。
sleep不会释放资源，wait会释放掉资源。


SimpleDateFormat是线程不安全的，使用ThreadLocal: 每个线程都将拥有自己的SimpleDateFormat对象副本。
1.8LocalDateTimeprase是线程安全的。


tcp/ip三次握手和四次分手？
三次握手：
1，客户端发送连接请求给服务端
2，服务器收到请求，并指示可以连接给客户端
3，客户端成功连接
四次分手：
1，客户端发送断开请求给服务端
2，服务器收到请求，并指示可以断开客户端
3，客户端成功断开，并告诉服务端断开了
4，服务器收到后也断开了
三次握手发送三个报文，SYN,SYN1+ACK1,ACK2



影藏url？
1，使用表单提交
2，使用onclick
3，ajax


表单提交中get和post方式的区别有5点 
1.get是从服务器上获取数据，post是向服务器传送数据。 
2.get是把参数数据
队列加到提交表单的ACTION属性所指的URL中，值和表单内各个字段一一对应，在URL中可以看到。post是通过HTTPpost机制，将表单内各
个字段与其内容放置在HTML HEADER内一起传送到ACTION属性所指的URL地址。用户看不到这个过程。 
3.对于get方式，服务器端用Request.QueryString获取变量的值，对于post方式，服务器端用Request.Form获取提交的数据。 
4.get传送的数据量较小，不能大于2KB。post传送的数据量较大，一般被默认为不受限制。但理论上，IIS4中最大量为80KB，IIS5中为100KB。 
5.get安全性非常低，post安全性较高。



一次完整的HTTP请求所经历的7个步骤
HTTP通信机制是在一次完整的HTTP通信过程中，Web浏览器与Web服务器之间将完成下列7个步骤：
1. 建立TCP连接
在HTTP工作开始之前，Web浏览器首先要通过网络与Web服务器建立连接，该连接是通过TCP来完成的，该协议与IP协议共同构建Internet，
即著名的TCP/IP协议族，因此Internet又被称作是TCP/IP网络。HTTP是比TCP更高层次的应用层协议，根据规则，只有低层协议建立之后才能进行更高层协议的连接，
因此，首先要建立TCP连接，一般TCP连接的端口号是80。
2. Web浏览器向Web服务器发送请求命令 
一旦建立了TCP连接，Web浏览器就会向Web服务器发送请求命令。例如：GET/sample/hello.jsp HTTP/1.1。
3. Web浏览器发送请求头信息 
浏览器发送其请求命令之后，还要以头信息的形式向Web服务器发送一些别的信息，之后浏览器发送了一空白行来通知服务器，它已经结束了该头信息的发送。
4. Web服务器应答 
客户机向服务器发出请求后，服务器会客户机回送应答， HTTP/1.1 200 OK ，应答的第一部分是协议的版本号和应答状态码。
5. Web服务器发送应答头信息 
正如客户端会随同请求发送关于自身的信息一样，服务器也会随同应答向用户发送关于它自己的数据及被请求的文档。
6. Web服务器向浏览器发送数据 
Web服务器向浏览器发送头信息后，它会发送一个空白行来表示头信息的发送到此为结束，接着，它就以Content-Type应答头信息所描述的格式发送用户所请求的实际数据。
7. Web服务器关闭TCP连接 
一般情况下，一旦Web服务器向浏览器发送了请求数据，它就要关闭TCP连接，然后如果浏览器或者服务器在其头信息加入了这行代码：Connection:keep-alive
TCP连接在发送后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。



SpringMvc的controller是singleton的（非线程安全的）
1、springmvc的成员是非线程安全的
2、在Controller中使用ThreadLocal变量
3、在spring配置文件Controller中声明 scope="prototype"，每次都创建新的controller
所在在使用spring开发web 时要注意，默认Controller、Dao、Service都是单例的。
4、因为springmvc是单例模式，所以影响同时互斥请求



strings1.stream().distinct().collect(Collectors.toList());集合去重

MyISAM引擎不能设置外键。只能Innodb设置外键和事务。



springmvc执行流程（源码分析）：
1，项目刚启动的时候，spring容器加载，首先调用AbstractHandlerMethodMapping的initHandlerMethods方法，初始化项目所有的bean，装在一个数组中，
然后再根据isHandler方法，过滤出所有的controller。
2，再循环调用AbstractHandlerMethodMapping的register方法，将一个个controller中的方法和其url一一对应，放在注册中心中（Map）。
3，再调用AbstractHandlerMethodMapping的getHandlerMethods方法，将这个Map设置为不可修改。
4，DispatcherServlet接收到用户请求时，首先调用initStrategies方法，初始化HandlerMapping适配器映射器等。
5，再执行doDispatch方法，通过调用getHandler方法，调用AbstractHandlerMapping的getHandler方法和AbstractUrlHandlerMapping的getHandlerInternal方法的协作，
通过请求中的url去匹配Map中的处理器，获取到对应的hanlder。
6，再通过DispatcherServlet的getHandlerAdapter获取到handler对应的适配器，然后去执行对应的方法，获取到modelandview，再由视图解析器解析成真正的视图，再传给前端。
mv = ha.handle(processedRequest, response, mappedHandler.getHandler());是执行语句。



java中equals()方法与hashCode()方法的隐式调用时的约定详解：
1、如果两个对象相同，那么它们的hashCode值一定要相同；
2、如果两个对象的hashCode相同，它们并不一定相同


如何在HTTP客户端与服务器端之间保持状态 ？
1、Http协议本身是无状态的，每一次请求都是独立的。

2、为了使web变得更加方便，存储状态，就出现了cookie与session
 cookie机制采用的是在客户端保持状态的方案，session采用的是在服务器端保持状态的方案。同时，由于采用服务器端保持状态的方案在客户端也需要保存一个标识，
 所以session机制可能需要借助于cookie机制来达到保存标识的目的。
 

多线程的坑：
在自旋里面去读取内存中list的size，会存在速度太快一直读取不到就会死循环，但是如果加上System.out.println语句，因为这个打印语句是
加了同步锁的，所以就能读取到数据。
线程要使用主内存的变量需要将变量从堆内存中copy到线程本地的工作内存中，而while循环中没有对list的size做任何变更操作，
所以线程也不会去主内存中同步数据，导致了一直使用的第一次循环得到的size值。println里面用了加锁操作，
线程加锁之后是需要从堆内存重新同步到线程的本地内存里面。


Arrays.asList()得到的ArrayList是一个自定义的内部类，并没有重写add和remove方法，所以这两个方法不能使用。

 
创建对象的三种方式：
1，new
2，反射
3，工厂模式

测试数据库连接是否有效：
mysql：select 1
orcle：select 1 from drud



查找字符串中某些字符？
1，用String的indexOf或者contanis
2，用正则
3，用KMP或者Boyer-Moore算法


intern()方法解析：
String s = new String("1");//生成了常量池中的“1” 和堆空间中的字符串对象。
s.intern();//这一行的作用是s对象去常量池中寻找后发现"1"已经存在于常量池中了。
String s2 = "1";//这行代码是生成一个s2的引用指向常量池中的“1”对象。
System.out.println(s == s2);
 
String s3 = new String("1") + new String("1");//这行代码在字符串常量池中生成“1”，并在堆空间中生成s3引用指向的对象（内容为"11"）。注意此时常量池中是没有 “11”对象的。
s3.intern();//这一行代码，是将s3中的“11”字符串放入String常量池中，此时常量池中不存在“11”字符串，JDK1.6的做法是直接在常量池中生成一个 "11" 的对象。
String s4 = "11";
System.out.println(s3 == s4);
结果：
1.6以前：false，false
1.6以后：false，true

intern()方法在JDK1.6中的作用是：比如String s = new String("SEU_Calvin")，再调用s.intern()，此时返回值还是字符串"SEU_Calvin"，表面上看起来好像这个方法没什么用处。但实际上，在JDK1.6中它做了个小动作：检查字符串池里是否存在"SEU_Calvin"这么一个字符串，如果存在，就返回池里的字符串；如果不存在，该方法会把"SEU_Calvin"添加到字符串池中，然后再返回它的引用。同时因为1.6以前，元数据空间和堆内存是分开的，所以两个引用地址就不一样了。
但是在JDK1.7中，常量池中不需要再存储一份对象了，可以直接存储堆中的引用。这份引用直接指向 s3引用的对象，也就是说s3.intern() ==s3会返回true。






---------------------------------------------------------------------------------------------------------------------------------------------------------------

二十，git？
提交到本地
git add .

git commit -m 修改描述

第一次推送到云端
git flow feature publish chengbo_featurename

git branch -a 查看远程和本地所有分支
git branch 查看本地分支

git pull —rebase origin develop  查看远程分支是否冲突


tmux？
#tmux
tmux -ls 查看session
tmux new-session -s webserver8001 创建一个新的session
Tmux kill-session -t webserver8001 删除一个session
Tmux a -t 标识符




---------------------------------------------------------------------------------------------------------------------------------------------------------------

二十一：Zookpeer

1，分布式系统是什么？
分布式系统：一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统
这是分布式系统，在不同的硬件，不同的软件，不同的网络，不同的计算机上，仅仅通过消息来进行通讯与协调。
这是他的特点，更细致的看这些特点又可以有：分布性、对等性、并发性、缺乏全局时钟、故障随时会发生。


2，分布式系统带来的问题？
如果把分布式系统和平时的交通系统进行对比，哪怕再稳健的交通系统也会有交通事故，分布式系统也有很多需要攻克的问题，比如：通讯异常，网络分区，三态，节点故障等。
网络分区就是所谓的脑裂，本来有一个交通警察，来管理整个片区的交通情况，一切井然有序，突然出现了停电，或者出现地震等自然灾难，某些道路接受不到交通警察的指令，可能在这种情况下，会出现一个零时工，片警零时来指挥交通。
三态就是成功，失败，超时这三种状态。


3，CAP理论？
CAP其实就是一致性，可用性，分区容错性这三个词的缩写。
一致性：
	一致性是事务ACID的一个特性【原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）】。
可用性：
	可用性指系统提供服务必须一直处于可用状态，对于用户的操作请求总是能够在有限的时间内访问结果。
分区容错性：
	分布式系统在遇到任何网络分区故障的时候，仍然需要能够对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。
	不能出现脑裂的情况。

注意：一个分布式系统不可能同时满足一致性、可用性和分区容错性这三个基本需求，最多只能同时满足其中的两项。但是因为不可能将所有服务都用一个节点控制，所以P是一定要满足的，所以只能在C和A上考虑，但是单独放弃C和A也不可能，因此架构师的精力往往就花在怎么样根据业务场景在A和C之间寻求平衡。
zk的思想是cp，eruka的思想是ap。


4，BASE理论？
BASE理论：即使无法做到强一致性，但分布式系统可以根据自己的业务特点，采用适当的方式来使系统达到最终的一致性；
	基本可用:当分布式系统出现不可预见的故障时，允许损失部分可用性，保障系统的“基本可用”；体现在“时间上的损失”和“功能上的损失		”。例如：部分用户双十一高峰期淘宝页面卡顿或降级处理
	软状态：既允许系统中的数据存在中间状态，既系统的不同节点的数据副本之间的数据同步过程存在延时，并认为这种延时不会影响系统		可用性。例如：12306网站卖火车票，请求会进入排队队列。
	最终一致性：所有的数据在经过一段时间的数据同步后，最终能够达到一个一致的状态。例如：理财产品首页充值总金额短时不一致。


5，设计目标？
	简单的数据结构：共享的树形结构，类似文件系统，存储于内存；
	可以构建集群：避免单点故障，3-5台机器就可以组成集群，超过半数正常工作就能对外提供服务；
	顺序访问：对于每个读请求，zk会分配一个全局唯一的递增编号，利用这个特性可以实现高级协调服务；
	高性能：基于内存操作，服务于非事务请求，适用于读操作为主的业务场景。3台zk集群能达到13w QPS；


6，哪些常见操作需要用到ZK？
数据发布订阅
负载均衡
命名服务
Master选举
集群管理
配置管理
分布式队列
分布式锁


7，ZK数据模型？
ZooKeeper的视图结构和标准的Unix文件系统类似，其中每个节点称为“数据节点”或ZNode,每个znode可以存储数据，还可以挂载子节点，因此可以称之为“树”
第二点需要注意的是，每一个znode都必须有值，如果没有值，节点是不能创建成功的。


8，会话？
Zk客户端和服务端成功连接后，就创建了一次会话，ZK会话在整个运行期间的生命周期中，会在不同的会话状态之间切换，这些状态包括：
CONNECTING、CONNECTED、RECONNECTING、RECONNECTED、CLOSE
一旦客户端开始创建Zookeeper对象，那么客户端状态就会变成CONNECTING状态，同时客户端开始尝试连接服务端，连接成功后，客户端状态变为CONNECTED，通常情况下，由于断网或其他原因，客户端与服务端之间会出现断开情况，一旦碰到这种情况，Zookeeper客户端会自动进行重连服务，同时客户端状态再次变成CONNCTING，直到重新连上服务端后，状态又变为CONNECTED，在通常情况下，客户端的状态总是介于CONNECTING和CONNECTED之间。但是，如果出现诸如会话超时、权限检查或是客户端主动退出程序等情况，客户端的状态就会直接变更为CLOSE状态


9，参数？
Conf目录为配置文件存放的目录，zoo.cfg为核心的配置文件
clientPort：参数无默认值，必须配置，用于配置当前服务器对外的服务端口，客户端必须使用这端口才能进行连接
dataDir：用于存放内存数据库快照的文件夹，同时用于集群的myid文件也存在这个文件夹里（注意：一个配置文件只能包含一个dataDir字样，即使它被注释掉了。）
dataLogDir：用于单独设置transaction log的目录，transaction log分离可以避免和普通log还有快照的竞争
tickTime：心跳时间，为了确保连接存在的，以毫秒为单位，最小超时时间为两个心跳时间
initLimit：多少个心跳时间内，允许其他server连接并初始化数据，如果ZooKeeper管理的数据较大，则应相应增大这个值
syncLimit：多少个tickTime内，允许follower同步，如果follower落后太多，则会被丢弃。

注意：dataDir：新安装zk这文件夹里面是没有文件的，可以通过snapCount参数配置产生快照的时机


10，节点类型？
	1，Znode有两种类型：
		短暂（ephemeral）（create -e /app1/test1 “test1” 客户端断开连接zk删除ephemeral类型节点） 
		持久（persistent） （create -s /app1/test2 “test2” 客户端断开连接zk不删除persistent类型节点）

	2，Znode有四种形式的目录节点（默认是persistent ）：
		PERSISTENT 
		PERSISTENT_SEQUENTIAL（持久序列/test0000000019 ） 
		EPHEMERAL 
		EPHEMERAL_SEQUENTIAL

	3，创建znode时设置顺序标识，znode名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护 
	4，在分布式系统中，顺序号可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序


11，ACL保障数据的安全？
ACL机制，表示为scheme:id:permissions，第一个字段表示采用哪一种机制，第二个id表示用户，permissions表示相关权限（如只读，读写，管理等）。
zookeeper提供了如下几种机制（scheme）：
	world: 它下面只有一个id, 叫anyone, world:anyone代表任何人，zookeeper中对所有人有权限的结点就是属于world:anyone的
	auth: 它不需要id, 只要是通过authentication的user都有权限（zookeeper支持通过kerberos来进行authencation, 也支持username/password形式的authentication)
	digest: 它对应的id为username:BASE64(SHA1(password))，它需要先通过username:password形式的authentication
			密文密码可以通过 DigestAuthenticationProvider.generateDigest("username:passowrd")获取。
	ip: 它对应的id为客户机的IP地址，设置的时候可以设置一个ip段，比如ip:192.168.1.0/16, 表示匹配前16个bit的IP段

	Zookeeper的ACL(Access Control List)，分为三个维度：scheme、id、permission
		通常表示为：scheme:id:permission
			schema:代表授权策略
				world：
					默认方式，相当于全世界都能访问
				auth：
					代表已经认证通过的用户(可以通过addauth digest user:pwd 来添加授权用户)
				digest：
					即用户名:密码这种方式认证，这也是业务系统中最常用的
				ip：
					使用Ip地址认证

			id:代表用户
			permission:代表权限
				CREATE、READ、WRITE、DELETE、ADMIN也就是增、删、改、查、管理权限，这5种权限简写为crwda（即：每个单词的首字符缩写)
				CREATE(c)：创建子节点的权限 
				DELETE(d)：删除节点的权限 
				READ(r)：读取节点数据的权限 
				WRITE(w)：修改节点数据的权限 
				ADMIN(a)：设置子节点权限的权限


12，分布式事务的一致性算法（BASE理论的实现）？
2PC：2PC，二阶段提交协议，即将事务的提交过程分为两个阶段来进行处理：准备阶段和提交阶段。事务的发起者称协调者，事务的执行者称参与者。其实数据库的经常用到的TCC本身就是一种2PC。
	阶段1：准备阶段
　　1、协调者向所有参与者发送事务内容，询问是否可以提交事务，并等待所有参与者答复。
　　2、各参与者执行事务操作，将Undo和Redo信息记入事务日志中（但不提交事务）。
		Redo，顾名思义就，重做。以恢复操作为目的，重现操作。
		Undo，意为取消，以撤销操作为目的，返回上一个状态，类似备份。
　　3、如参与者执行成功，给协调者反馈YES，即可以提交；如执行失败，给协调者反馈NO，即不可提交。
 
　　阶段2：提交阶段
　　此阶段分两种情况：所有参与者均反馈YES、或任何一个参与者反馈NO。
　　所有参与者均反馈YES时，即提交事务。
　　任何一个参与者反馈NO时，即中断事务。
		　提交事务：（所有参与者均反馈YES）
		　　1、协调者向所有参与者发出正式提交事务的请求（即Commit请求）。
		　　2、参与者执行Commit请求，并释放整个事务期间占用的资源。
		　　3、各参与者向协调者反馈Ack完成的消息。
		　　4、协调者收到所有参与者反馈的Ack消息后，即完成事务提交。
		  中断事务：（任何一个参与者反馈NO）
		　　1、协调者向所有参与者发出回滚请求（即Rollback请求）。
		　　2、参与者使用阶段1中的Undo信息执行回滚操作，并释放整个事务期间占用的资源。
		　　3、各参与者向协调者反馈Ack完成的消息。
		　　4、协调者收到所有参与者反馈的Ack消息后，即完成事务中断。
	2PC的缺陷：
　　1、同步阻塞：最大的问题即同步阻塞，即：所有参与事务的逻辑均处于阻塞状态。
　　2、单点：协调者存在单点问题，如果协调者出现故障，参与者将一直处于锁定状态。
　　3、脑裂：在阶段2中，如果只有部分参与者接收并执行了Commit请求，会导致节点数据不一致。
　　由于2PC存在如上同步阻塞、单点、脑裂问题，因此又出现了2PC的改进方案，即3PC。

tcc：
	TCC将事务提交分为 Try - Confirm - Cancel 3个操作。
		Try：预留业务资源/数据效验
		Confirm：确认执行业务操作
		Cancel：取消执行业务操作
		TCC事务处理流程和 2PC 二阶段提交类似，不过 2PC通常都是在跨库的DB层面，而TCC本质就是一个应用层面的2PC。
	事务补偿型（TCC事务）：
		TCC型事务（Try/Confirm/Cancel）可以归为补偿型。
		补偿型的例子，在一个长事务（ long-running ）中 ，一个由两台服务器一起参与的事务，服务器A发起事务，服务器B参与事务，B的事务需要人工参与，所以处理时间可能很长。如果按照ACID的原则，要保持事务的隔离性、一致性，服务器A中发起的事务中使用到的事务资源将会被锁定，不允许其他应用访问到事务过程中的中间结果，直到整个事务被提交或者回滚。这就造成事务A中的资源被长时间锁定，系统的可用性将不可接受。
		WS-BusinessActivity提供了一种基于补偿的long-running的事务处理模型。还是上面的例子，服务器A的事务如果执行顺利，那么事务A就先行提交，如果事务B也执行顺利，则事务B也提交，整个事务就算完成。但是如果事务B执行失败，事务B本身回滚，这时事务A已经被提交，所以需要执行一个补偿操作，将已经提交的事务A执行的操作作反操作，恢复到未执行前事务A的状态。这样的SAGA事务模型，是牺牲了一定的隔离性和一致性的，但是提高了long-running事务的可用性。
	TCC优点：
		让应用自己定义数据库操作的粒度，使得降低锁冲突、提高吞吐量成为可能。
	TCC不足之处：
		对应用的侵入性强。业务逻辑的每个分支都需要实现try、confirm、cancel三个操作，应用侵入性较强，改造成本高。
		实现难度较大。需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。为了满足一致性的要求，confirm和cancel接口必须实现幂等。

tcc和2PC的区别：
TCC属于业务上的分段提交，Try，confirm，cancel都是对应的一段业务逻辑的操作，先预留资源，预留成功后进行确认，不成功就取消，例如转账先冻结资金，进行一系列的余额各方面的检查，发现符合条件就对账户对应的资金状态改为冻结，确认阶段修改状态为扣除，取消的话就把冻结的资金加回原账户，其对应的数据库的操作每段都是一个完整的事物；2PC是属于数据库层面的，先进行prepare，然后逐个进行commit或者rollback，不和具体业务逻辑挂钩，TCC的应用范围更广，不一定是事物关系数据库，也可能操作的KV数据库，文档数据库，粒度也可以随着具体业务灵活调整，性能更好。
	

3PC：3PC，三阶段提交协议，是2PC的改进版本，即将事务的提交过程分为CanCommit、PreCommit、doCommit三个阶段来进行处理。
	阶段1：CanCommit
　　1、协调者向所有参与者发出包含事务内容的CanCommit请求，询问是否可以提交事务，并等待所有参与者答复。
　　2、参与者收到CanCommit请求后，如果认为可以执行事务操作，则反馈YES并进入预备状态，否则反馈NO。
 
　　阶段2：PreCommit
　　此阶段分两种情况：
　　1、所有参与者均反馈YES，即执行事务预提交。
　　2、任何一个参与者反馈NO，或者等待超时后协调者尚无法收到所有参与者的反馈，即中断事务。
	　　事务预提交：（所有参与者均反馈YES时）
	　　1、协调者向所有参与者发出PreCommit请求，进入准备阶段。
	　　2、参与者收到PreCommit请求后，执行事务操作，将Undo和Redo信息记入事务日志中（但不提交事务）。
	　　3、各参与者向协调者反馈Ack响应或No响应，并等待最终指令。
	 
	　　中断事务：（任何一个参与者反馈NO，或者等待超时后协调者尚无法收到所有参与者的反馈时）
	　　1、协调者向所有参与者发出abort请求。
	　　2、无论收到协调者发出的abort请求，或者在等待协调者请求过程中出现超时，参与者均会中断事务。
 
　　阶段3：doCommit
　　此阶段也存在两种情况：
　　1、所有参与者均反馈Ack响应，即执行真正的事务提交。
　　2、任何一个参与者反馈NO，或者等待超时后协调者尚无法收到所有参与者的反馈，即中断事务。
	　　提交事务：（所有参与者均反馈Ack响应时）
	　　1、如果协调者处于工作状态，则向所有参与者发出do Commit请求。
	　　2、参与者收到do Commit请求后，会正式执行事务提交，并释放整个事务期间占用的资源。
	　　3、各参与者向协调者反馈Ack完成的消息。
	　　4、协调者收到所有参与者反馈的Ack消息后，即完成事务提交。
	 
	　　中断事务：（任何一个参与者反馈NO，或者等待超时后协调者尚无法收到所有参与者的反馈时）
	　　1、如果协调者处于工作状态，向所有参与者发出abort请求。
	　　2、参与者使用阶段1中的Undo信息执行回滚操作，并释放整个事务期间占用的资源。
	　　3、各参与者向协调者反馈Ack完成的消息。
	　　4、协调者收到所有参与者反馈的Ack消息后，即完成事务中断。
 
　　注意：进入阶段三后，无论协调者出现问题，或者协调者与参与者网络出现问题，都会导致参与者无法接收到协调者发出的doCommit请求或abort请求。此时，参与者都会在等待超时之后，继续执行事务提交。无论2PC或3PC，均无法彻底解决分布式一致性问题。解决一致性问题，唯有Paxos。

	3PC的优点和缺陷：
　　优点：降低了阻塞范围，在等待超时后协调者或参与者会中断事务。避免了协调者单点问题，阶段3中协调者出现问题时，参与者会继续提交事务。
　　缺陷：脑裂问题依然存在，即在参与者收到PreCommit请求后等待最终指令，如果此时协调者无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。



Paxos：
	在paxos算法中，分为4种角色：
		  Proposer ：提议者
		  Acceptor：决策者
		  Client：产生议题者
		  Learner：最终决策学习者
	提议者和决策者是很重要的，其他的2个角色在整个算法中应该算做打酱油的，Proposer就像Client的使者，由Proposer使者拿着Client的议题去向Acceptor提议，让Acceptor来决策。这里上面出现了个新名词：最终决策。现在来系统的介绍一下paxos算法中所有的行为：
			1，Proposer提出议题
			2，Acceptor初步接受 或者 Acceptor初步不接受
			3，如果上一步Acceptor初步接受则Proposer再次向Acceptor确认是否最终接受
			4，Acceptor 最终接受 或者Acceptor 最终不接受
			注意：Acceptor必须是最少大于等于3个，并且必须是奇数个，因为要形成多数派嘛，如果是偶数个，比如4个，2个接受2个不接受，各执己见，没法搞下去了。
	举例：
		阶段一：
			1.现在需要对一项议题来进行paxos过程，议题是“A项目我要中标！”，这里的“我”指每个带着他的秘书Proposer的Client老板。
			2.Proposer当然听老板的话了，赶紧带着议题和现金去找Acceptor政府官员。
			3.作为政府官员，当然想谁给的钱多就把项目给谁。
			4.Proposer-1小姐带着现金同时找到了Acceptor-1~Acceptor-3官员，1与2号官员分别收取了10比特币，找到第3号官员时，没想到遭到了3号官员的鄙视，3号官员告诉她，Proposer-2给了11比特币。不过没关系，Proposer-1已经得到了1,2两个官员的认可，形成了多数派(如果没有形成多数派，Proposer-1会去银行提款在来找官员们给每人20比特币，这个过程一直重复每次+10比特币，直到多数派的形成)，满意的找老板复命去了，但是此时Proposer-2保镖找到了1,2号官员，分别给了他们11比特币，1,2号官员的态度立刻转变，都说Proposer-2的老板懂事，这下子Proposer-2放心了，搞定了3个官员，找老板复命去了，当然这个过程是第一阶段提交，只是官员们初步接受贿赂而已。故事中的比特币是编号，议题是value。
		阶段二：
			5.　现在进入第二阶段提交，现在proposer-1小姐使用分身术(多线程并发)分了3个自己分别去找3位官员，最先找到了1号官员签合同，遭到了1号官员的鄙视，1号官员告诉他proposer-2先生给了他11比特币，因为上一条规则的性质proposer-1小姐知道proposer-2第一阶段在她之后又形成了多数派（至少有2位官员的赃款被更新了);此时她赶紧去提款准备重新贿赂这3个官员（重新进入第一阶段)，每人20比特币。刚给1号官员20比特币，1号官员很高兴初步接受了议题，还没来得及见到2,3号官员的时候
			这时proposer-2先生也使用分身术分别找3位官员(注意这里是proposer-2的第二阶段)，被第1号官员拒绝了告诉他收到了20比特币，第2,3号官员顺利签了合同，这时2，3号官员记录client-2老板用了11比特币中标，因为形成了多数派，所以最终接受了Client2老板中标这个议题，对于proposer-2先生已经出色的完成了工作；
			这时proposer-1小姐找到了2号官员，官员告诉她合同已经签了，将合同给她看，proposer-1小姐是一个没有什么职业操守的聪明人，觉得跟Client1老板混没什么前途，所以将自己的议题修改为“Client2老板中标”，并且给了2号官员20比特币，这样形成了一个多数派。顺利的再次进入第二阶段。由于此时没有人竞争了，顺利的找3位官员签合同，3位官员看到议题与上次一次的合同是一致的，所以最终接受了，形成了多数派，proposer-1小姐跳槽到Client2老板的公司去了。

			总结：Paxos过程结束了，这样，一致性得到了保证，算法运行到最后所有的proposer都投“client2中标”所有的acceptor都接受这个议题，也就是说在最初的第二阶段，议题是先入为主的，谁先占了先机，后面的proposer在第一阶段就会学习到这个议题而修改自己本身的议题，因为这样没职业操守，才能让一致性得到保证，这就是paxos算法的一个过程。原来paxos算法里的角色都是这样的不靠谱，不过没关系，结果靠谱就可以了。该算法就是为了追求结果的一致性。
	扩展：拜将庭问题。

	缺点：
		Paxos算法虽然通用，可靠，但终归效率太低。Paxos算法在出现竞争的情况下，其收敛速度很慢，甚至可能出现活锁的情况，例如当有三个及三个以上的proposer在发送prepare请求后，很难有一个proposer收到半数以上的回复而不断地执行第一阶段的协议。因此，为了避免竞争，加快收敛的速度，在算法中引入了一个Leader这个角色，在正常情况下同时应该最多只能有一个参与者扮演Leader角色，而其它的参与者则扮演Acceptor的角色。


zab：
	ZAB协议包括两种基本的模式：崩溃恢复和消息广播，可以解决脑裂。
    当整个服务框架在启动过程中，或是当Leader服务器出现网络中断崩溃退出与重启等异常情况时，ZAB就会进入恢复模式并选举产生新的Leader服务器。
    当选举产生了新的Leader服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出崩溃恢复模式，进入消息广播模式。
    当有新的服务器加入到集群中去，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加入的服务器会自动进入数据恢复模式，找到Leader服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。
    以上其实大致经历了三个步骤：
    1.崩溃恢复：主要就是Leader重新选举过程，注意这里是根据myid和ZXID（事务id）投票，优先投ZXID大的，因为ZXID大表示事务最近发				生，也能保证数据是最新的，保证数据的不丢失和一致性。
    2.数据同步：Leader服务器与其他服务器进行数据同步，并且询问是否可以提交事务。
    3.消息广播：Leader服务器将数据发送给其他follower服务器，并提交事务。


leader选举和master选举：
leader选举针对的是zk集群，解决的是分布式数据一致性问题，当主zk挂了，会中从zk集群中选举一个主zk。
master选举是日常开发中的业务问题用zk来解决，针对的是zk的节点，即是用zk的一个主节点和其他备用从节点来解决，从节点通过ping主节点或其他方式监听主节点是否存活，如果挂了，再从从节点中竞争选出一个主节点。但是可能会因为主节点出现假死状态，从节点以为主节点挂了，选出了新的节点，而原先那个主节点又活了，这时就有两个主节点，就发生了脑裂。
leader选举 也可以叫做master选举也可以叫做哨兵。他们从思维上差不多。只是ZK是使用ZAB实现这功能的，而其他第三方应用如果业务需要可以使用ZK实现这功能。


paxos和zab：
Paxos算法是分布式选举算法，Zookeeper使用的 ZAB协议（Zookeeper原子广播），二者有相同的地方，比如都有一个Leader，用来协调N个Follower的运行；Leader要等待超半数的Follower做出正确反馈之后才进行提案；二者都有一个值来代表Leader的周期。
不同的地方在于：
ZAB用来构建高可用的分布式数据主备系统（Zookeeper），Paxos是用来构建分布式一致性状态机系统。





13，分布式锁？
1，使用没有顺序的Lock节点实现。
	思路：
		1，创建一个Lock接口，定义获取锁和释放锁的方法，然后具体实现。
		2，获取锁的思路是，创建一个lock的节点，然后添加一个监听，监听当前节点是否被删除，如果存在当前节点，就证明有进程获取到了锁，其他进程需要等待，如果这个节点被删除了，就让其他进程竞争这把锁。
		3，释放锁即是删除这个lock节点。
	缺点：
		1，性能差，会出现频繁的创建和删除节点，适合于10个服务器集群之内。
		2，当出现大量进程竞争的时候，容易出现羊群效应，如果一旦同一时间有多个节点挂了，服务端就要给客户端发送大量通知，这样就是羊群效应。


2，使用有顺序的Lock节点实现。
	思路：
		1，创建一个Lock接口，定义获取锁和释放锁的方法，然后具体实现。
		2，获取锁的思路是，创建一个有顺序的lock的节点，获取所有节点并排序，判断当前节点是否是节点列表中的第一个，如果是就获取成功锁，如果不是，则添加一个监听，监听前一个节点是否被删除。
		3，释放锁即是删除这个前一个lock节点。
	注意：这种方式解决了上一种的羊群问题，当多个节点挂了的时候，只需要通知第二个节点即可。
	缺点：排队，效率低。


14，rpc的实现
	1，传统方式：
		使用jdk自带的RMI实现RPC，底层就是通过socket通信实现的。

	2，rpc的原理：
		1.服务端定义接口和服务实现类并且注册服务
		2.客户端查询出服务
		3.客户端使用动态代理调用服务(动态代理)，动态代理中增强，通过sokcet实现网络通讯
		4.客户端代理把调用对象、方法、参数序列化成数据
		5.客户端与服务端通过Socket通讯传输数据
		6.服务端反序列化数据成对象、方法、参数。
		7.服务端代理拿到这些对象和参数后通过反射的机制调用服务的实例。







---------------------------------------------------------------------------------------------------------------------------------------------------------------



二十二：dubbo


1，dubbo要解决的问题？
	1、rpc调用需要定制。额外的工作量 
	2、分布式服务中，服务动辄几十上百，相互之间的调用错综复杂，相互依赖严重 
	3、对集群性的服务，需要负载策略 
	4、对集群性的服务，能动态扩展节点 
	注意：dubbo的扩展性相当好，使用了spi机制，比如，负载策略只有5种，我们可以自定义一种，然后实现dubbo的对应的负载接口即可使用，而整个dubbo的设计理念都是这样的。


2，dubbo只能支持spring管理的服务。

3，Dubbo支持的协议
	Dubbo支持dubbo、rmi、hessian、http、webservice、thrift、redis等多种协议，但是Dubbo官网是推荐我们使用Dubbo协议的。dubbo的序列化协议默认使用hessian。
	dubbo协议：
		缺省协议，使用基于mina1.1.7+hessian3.2.1的tbremoting交互。 
		连接个数：单连接 
		连接方式：长连接 
		传输协议：TCP 
		传输方式：NIO异步传输 
		序列化：Hessian二进制序列化 
		适用范围：传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo协议传输大文件或超大字符串。 
		适用场景：常规远程服务方法调用
	注意：
	1、dubbo默认采用dubbo协议，dubbo协议采用单一长连接和NIO异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况 
	2、他不适合传送大数据量的服务，比如传文件，传视频等，除非请求量很低。 

	rmi协议：
		Java标准的远程调用协议。 
		连接个数：多连接 
		连接方式：短连接 
		传输协议：TCP 
		传输方式：同步传输 
		序列化：Java标准二进制序列化 
		适用范围：传入传出参数数据包大小混合，消费者与提供者个数差不多，可传文件。 
		适用场景：常规远程服务方法调用，与原生RMI服务互操作

	hessian协议：
		基于Hessian的远程调用协议。 
		连接个数：多连接 
		连接方式：短连接 
		传输协议：HTTP 
		传输方式：同步传输 
		序列化：表单序列化 
		适用范围：传入传出参数数据包大小混合，提供者比消费者个数多，可用浏览器查看，可用表单或URL传入参数，暂不支持传文件。 
		适用场景：需同时给应用程序和浏览器JS使用的服务。
		1、Hessian协议用于集成Hessian的服务，Hessian底层采用Http通讯，采用Servlet暴露服务，Dubbo缺省内嵌Jetty作为服务器实现。 
		2、Hessian是Caucho开源的一个RPC框架：http://hessian.caucho.com，其通讯效率高于WebService和Java自带的序列化。 


4，读取配置文件：
	DUBBO在读取配置的时候会先读取XML文件中的配置，如果没找到就会默认去读取resources目录下的dubbo.properties文件。如果你即配置了 XML 又配置了 properties 的内容，那么 DUBBO 读取时将直接读取 XML 中的配置，忽略 properties 里的配置。

5，配置文件：
	标签有个继承关系：
		1，下层会继承上层属性配置
		2，消费方，会继承服务方属性配置：服务只提供者自己知道，配什么属性最合适

6，Dubbo的执行流程： 
	项目一启动，加载配置文件的时候，就会初始化，并且每设置一个协议就会有一个中转对象，这个中转对象负责将注册的服务暴露出去，并且生成对外暴露的url，向注册中心注册自己提供的服务和对应的url，当消费者在启动时，代理对象就会向注册中心订阅自己所需要的服务，如果服务提供方有数据变更等，注册中心将基于长连接的形式推送变更数据给消费者，并且代理对象会去调用这些服务，这里是动态代理的方式。 

	Dubbo使用spring：
		1，Dubbo通过DubboNamespaceHandler类去继承spring的DubboNamespaceHandler这个抽象类，就可以在初始化的时候向spring容器中注册一些自定义的标签，比如application，service，protocol等。
		2，Dubbo的中转对象实现了spring的InitializingBean接口，在中转对象初始化工作完成之后，通过afterPropertiesSet()方法设置一些属性配置。
		3，Dubbo的中转对象还实现了spring的DisposableBean接口，然后另开了一个线程调用destroy用于监控bean被销毁后做的一些处理。

7，Dubbo的安全性如何得到保障： 
	a.在有注册中心的情况下,可以通过dubbbo admin中的路由规则，来指定固定ip的消费方来访问 
	b.在直连的情况下，通过在服务的提供方中设置密码(令牌)token，消费方需要在消费时也输入这 个密码，才能够正确使用。 
	Dubbo添加服务ip白名单，防止不法调用

8，Duubo中如何保证分布式事务？ 
	一般情况下，我们尽量将需要事务的方法放在一个service中，从而避开分步式事务。

9，Dubbo的心跳机制： 
	目的： 
	维持provider和consumer之间的长连接 
	实现： 
	dubbo心跳时间heartbeat默认是1s，超过heartbeat时间没有收到消息，就发送心跳消 息(provider，consumer一样),如果连着3次(heartbeatTimeout为heartbeat*3)没有收到心跳响应，provider会关闭channel，而consumer会进行重连;不论是provider还是consumer的心跳检测都是通过启动定时任务的方式实现；

10,Dubbo中zookeeper做注册中心，如果注册中心集群都挂掉，发布者和订阅者之间还能通信么？
	可以通信的，启动dubbo时，消费者会从zk拉取注册的生产者的地址接口等数据，缓存在本地。每次调用时，按照本地存储的地址进行调用；
	注册中心对等集群，任意一台宕机后，将会切换到另一台；注册中心全部宕机后，服务的提供者和消费者仍能通过本地缓存通讯。服务提供者无状态，任一台 宕机后，不影响使用；服务提供者全部宕机，服务消费者会无法使用，并无限次重连等待服务者恢复；

11，dubbo服务负载均衡策略？
	1，Random：按权重随机，根据weight值（服务方设置）来随机。
	2，Roundrobin：轮询访问。
	3，Leastactive：谁最轻松，访问谁，慢的机器，收到的请求少。
	4，ConsistentHash：一致性Hash，相同参数的请求总是发到同一提供者，当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。

12， dubbo连接注册中心和直连的区别：
	在开发及测试环境下，经常需要绕过注册中心，只测试指定服务提供者，这时候可能需要点对点直连，点对点直联方式，将以服务接口为单位，忽略注册中心的提供者列表，服务注册中心，动态的注册和发现服务，使服务的位置透明，并通过在消费方获取服务提供方地址列表，实现软负载均衡和Failover，注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
	服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，服务消费者向注册中心获取服务提供者地址列表，并根据负载算法直接调用提供者，注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外，注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者，注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表，注册中心和监控中心都是可选的，服务消费者可以直连服务提供者。

13，dubbo服务集群配置（集群容错模式）：
	1、 Failover ：当出现失败，重试其它服务器。 retries=“2” 来设置重试次数(不含第一次)。幂等性操作使用，如读操作。
					幂等操作：一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。
	2、 Failfast ：快速失败，只发起一次调用，失败立即报错，非幂等性操作，如写操作
	3、 Failsafe ：出现异常时，直接忽略，无关紧要的旁支操作，如打日志
	4、 Failback ：后台记录失败请求，定时重发，后续专业处理
	5、 Forking ：并行调用多个服务器，只要一个成功即返回，forks=“2” 来设置最大并行数
	注意：这里其实是dubbo的spi机制，其实和策略模式相近。


14，dubbo通信协议dubbo协议为什么要消费者比提供者个数多：
	因dubbo协议采用单一长连接，假设网络为千兆网卡(1024Mbit=128MByte），根据测试经验数据每条连接最多只能压满7MByte（不同的环境可能不一样，供参考)，理论上1个服务提供者需要20个服务消费者才能压满网卡。

15，dubbo通信协议dubbo协议为什么不能传大包：
	因dubbo协议采用单一长连接，如果每次请求的数据包大小为500KByte，假设网络为千兆网卡(1024Mbit=128MByte)，每条连接最大7MByte(不同的环境可能不一样，供参考），单个服务提供者的TPS（每秒处理事务数）最大为：128MByte/500KByte=262。单个消费者调用单个服务提供者的TPS(每秒处理事务数)最大为：7MByte / 500KByte = 14。如果能接受，可以考虑使用，否则网络将成为瓶颈。

16，声明式缓存：
	lru：最少使用原则删除缓存（此参数长期未调，就不缓存了）
	threadlocal：对调用者缓存（下次还是你调用，就返回缓存的数据）

17，dubbo的一些功能：
	1，异步调用
		1，Future方式，先异步执行再总的通过get方法接收结果。
		2，回调方式

	2，回声测试
		检测提供方的接口是否正常，所有服务接口都实现了EchoService，获取成功就表示正常，失败就不正常

	3，泛化调用
		就是在消费方需要调用服务方的接口，但是再公共代理接口模块中没有这个接口，可以通过generic="true"，利用反射通过类路径得到这个接口。


18，dubbo的spi机制：
	使用：只要是dubbo里面标注了@SPI注解的接口，均对外扩展，例如扩展负载功能。
		1，实现LoadBalance接口，重写负载算法。
		2，在resource路径下的META-INF下建dubbo文件夹，然后在这个路径下建接口的全路径名的文件com.alibaba.dubbo.rpc.cluster.LoadBalance，在文件里面以key=value的形式指定自定义的负载器即可。
	ExtensionLoader：
		是整个SPI的核心，创建对应扩展接口的适配对象。

	原理（以protocol为例），也是dubbo的亮点：
		1，dubbo启动加载实现类时，以key-value实例方式map缓存各个实现类。
		2，通过ExtensionLoader创建一个protocol的类加载器。
		3，类加载器再创建一个protocol的适配对象（首先会去缓存中取，没有就创建）。
			注意：这个适配对象的创建是通过代码编写类源码，然后编译生成的一个实例，类似于mybatis的逆向工程，适配类生成源码的逻辑中，只生成protocol接口中标注了@Adaptive的方法。
		4，通过适配对象去从URL总线中找到key，然后根据key调用对应的实现类。
		好处：大大增加了扩展性，对于向其他的loadbalance，cache等之类的功能都用一个ExtensionLoader来管理扩展，省去了很多重复的代码。

19，dubbo集成zk原理：
	1，dubbo消费端启动过程中，第一次在serviceconfig中执行refprotocol.refer,此时对应的url是registryUrl，根据registryUrl中的re	gistry这个key得到registryProtocol。
	2，根据registryProtocol执行监听器，利用ZookeeperRegistry进行zk注册
	3，注册完毕之后，利用监听器进行消息通知，通知所有模块url的变化（即是注册在zk上的url），刷新缓存
	4，监听器最后，调用toInvokers方法，将新注册的url转为invokers对象，此处url转为invokers的过程，交由dubboprotocol来完成，即	：protocol.refer的url在此时是dubbo协议（SPI机制）
	5，将这个invokers对象交给中转对象，暴露出去

